\documentclass[10pt,a4paper]{report}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{hyperref}

\usepackage{multicol}
\usepackage{fancyhdr}
\usepackage[inline]{enumitem}
\usepackage{tikz}
\usepackage{tikz-cd}
\usetikzlibrary{calc}
\usetikzlibrary{shapes.geometric}
\usepackage[margin=0.5in]{geometry}
\usepackage{xcolor}

\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
    pdftitle={Tensors},
    pdfpagemode=FullScreen,
    }

%\urlstyle{same}

\newcommand{\CLASSNAME}{Math 5411 -- Mathematical Statistics I}
\newcommand{\PROFESSOR}{Nezamoddini-Kachouie}
\newcommand{\STUDENTNAME}{Paul Carmody}
\newcommand{\ASSIGNMENT}{Cheatsheet for Midterm }
\newcommand{\DUEDATE}{October 21, 2024}
\newcommand{\SEMESTER}{Fall 2024}
\newcommand{\SCHEDULE}{MW 5:30 -- 6:45}
\newcommand{\ROOM}{Remote}

\pagestyle{fancy}
\fancyhf{}
\chead{ \fancyplain{}{\CLASSNAME} }
%\chead{ \fancyplain{}{\STUDENTNAME} }
\rhead{\thepage}
\input{../MyMacros}

\newcommand{\RED}[1]{\textcolor{red}{#1}}
\newcommand{\BLUE}[1]{\textcolor{blue}{#1}}

\begin{document}

\begin{center}
	\Large{\CLASSNAME -- \SEMESTER} \\
	\large{w/\PROFESSOR}
\end{center}
\begin{center}
	\STUDENTNAME \\
	\ASSIGNMENT -- \DUEDATE\\
\end{center}

\begin{description}
\item \textbf{Terms \& Symbols:}
	\begin{description}
		\item $X$ is the set values that can be attained by some random variable $x$.
		\item \DEFINE{Sample Space} $\Omega$ the values that are attained by the random variable.
		\item \DEFINE{Discrete Random Variable} a data point that can take specific list of values.  That is, there is a one-to-one correspondence between elements of $X$ and $\N$ and it is finite.
		\item \DEFINE{Continuous Random Variable} a data point that comes from a range of values.
		\item \DEFINE{Probability, $p$,} of a random variable $x$ is $p: X \to [0,1]$ and indicates the likelihood of $x$ appearing in $X$.  In the discrete case: 
		\begin{align*}
			p(X=x) = \frac{\BARS{\{y\in X: y=x\}}}{|\Omega|}
		\end{align*}
		\item \DEFINE{Probability Mass Function, PMF} a function $p: X \to [0,1]$ indicating the values of the probabilities by element for a discrete random variable.
		\item \DEFINE{Cumulative Mass Function, CMF}, $F(x) = p(X\le x)$ for a discrete random variable.
		\item \DEFINE{Probability Density Function, PDF} $f: (-\infty,\infty) \to [0,1]$ whose area under the graph is the probability by range for a continuous random variable.
		\begin{align*}
			p(a < x < b) &= \int_a^b f(x)dx
		\end{align*}
		\item \DEFINE{Cumulative Density Function, CDF} $F: (-\infty,\infty) \to [0,1]$ which the cumulative probability up to the point $x$ for a continuous random variable.  That is
		\begin{align*}
			F(x) = p(X< x) &= \int_{-\infty}^x f(t) dt
		\end{align*}
		
		\item A \DEFINE{Permutation} of a discrete set, $X$, is a one-to-one correspondence of all elements in $X$.  If $n$ is the index of the elements in $X$ then the permutation $P(n)$ is a different complete ordering of $X$ (i.e., no replacement).
		\item A \DEFINE{Combination} is a subset of the elements of $X$ in a specific order (i.e., no replacement).
		\item \DEFINE{Conditional Probability, $P(A|B)$}, read "the probability of event $A$ given first event $B$" has occurred.
		\begin{align*}
			P(A|B) &= P(A \cap B)P(B) & P(B) \ne 0\\
			P(B|A) &= P(A \cap B)P(A) & P(A) \ne 0
		\end{align*}
		
		\item Events $A$ and $B$ are said to be \DEFINE{independent} if $P(A\cap B) = P(A)P(B)$.  Also, typically, $P(A \cup B) = P(A)+P(B)-P(A\cap B)$.
	\end{description}	
	
\item \textbf{Counting}

	\begin{align*}
		|\Omega| &= p^n & \text{with replacement, e.g., flip a coin $n$ times}\\
		|\Omega| &= n! & \text{without replacement}\\
		\binom{n}{r} &= \frac{n!}{r!(n-r)!} & \text{$n$ choose $r$ unordered} \\
		2^n &= \sum_{i=0}^n \binom{n}{i} \\
		\binom{n}{k_1\dots k_i} &= \frac{n!}{k_1!\cdots k_i!} & \text{$k_i$ form a partition on n}
	\end{align*}
\item \textbf{Random Variable Types:}
\begin{description}
	\item \textbf{Bernouli:} $p:\{0,1\}\to [0,1]$, $p(x)=\BINDEF{1 & x=1}{0 & x=0}$
	\item \textbf{Uniform:} $p:[a,b] \to [0,1]$, $p(x) = \BINDEF{\frac{1}{b-a} & a \le x \le b}{0 & \text{otherwise}}$
	\item \textbf{Binomial$(n,p)$} indicates $n$ trials with probability of success for each trial of $p$.  Thus, the probability of $k$ success in $n$ trials is
	\begin{align*}
		p(X=k) &= \binom{n}{k}p^k(1-p)^{n-k}
	\end{align*}
	\item \textbf{Negative Binomial and Geometric:} first execute $r$ successes then determine the probability of $k$ failures.
	\begin{align*}
		P(X=k) &= \binom{k-1}{r-1}p^r(1-p)^{k-r} & \text{$r$ successes}\\ 
		P(X=k) &= p(1-p)^k & \text{$r=1$ implies geometric}
	\end{align*}
	\item \textbf{Hypergeometric:} urn contains $n$ balls $r$ of them are black $n-r$ are not.  Draw $m$ balls with $k$ the number of black balls drawn.
	\begin{align*}
		P(X=k) &= \frac{\binom{r}{k}\binom{n-r}{m-k}}{\binom{n}{k}}
	\end{align*}
	\item \textbf{Poisson:} $\lambda$ is the parameterized count per unit time, $k$ is the count per unit time. \textit{(this can be used in place of Binomial if $n$ is very high and $p$ is very low, $\lambda = nxp$)}.
	\begin{align*}
		P(X=k) &= \frac{\lambda^k}{k!}e^{-\lambda}
	\end{align*}
	
	\item \textbf{Exponential Decay: }
	\begin{align*}
		f(x) &= \BINDEF{\lambda e^{-\lambda} & x \ge 0}{0 & \text{otherwise}}
	\end{align*}
	
	\item \textbf{Gamma Distribution: }$\alpha$ shape parameter $\lambda$ scale parameter.  $\beta = 1/\lambda$ is the rate parameter
	\begin{align*}
		g(t) &= \frac{\lambda^\alpha}{\Gamma(\alpha)}t^{\alpha-1}e^{-\lambda t} = \frac{1}{\beta^\alpha\Gamma(\alpha)}t^{\alpha-1}e^{\beta t} \\
		\Gamma(t) &= \int_0^\infty u^{x-1}e^{-u} du,\, x >0 \\
		\Gamma(n+1) &= n!
	\end{align*}
	
	\item \textbf{Normal Distributions:} $\mu$ mean, $\sigma$ standard deviation, \DEFINE{Standard Normal Distribution} is $\mu=0, \sigma = 1$.
	\begin{align*}
		f(x) &= \frac{1}{\sigma\sqrt{2}}e^{-(x-\mu)^2/2\sigma^2} \\
		f(x) &= \frac{1}{\sqrt{2}}e^{-x^2/2} & \text{Standard Normal Distribution}
	\end{align*}
\end{description}
\item \textbf{Expected Values and Variance:}
	\begin{description}
		\item Expected and Variance:
		\begin{align*}
			\mu = E[X] &= \sum_i x_ip(x_i) \AND E[X] = \int_{-\infty}^\infty xf(x)dx \\
			\sigma^2 = V[X] &= E[X^2]-(E(X])^2\\
			&= \sum_i x_i^2p(x_i) - \PAREN{\sum_i x_ip(x_i)}^2 \AND V[X] = \int_{-\infty}^\infty x^2f(x)dx - \PAREN{\int_{-\infty}^\infty xf(x)dx}^2
		\end{align*}
		\item Moment Generating Function (MFG):
		\begin{align*}
			M(t) &= \sum_x e^{tx} p(x) \AND M(t)=\int_{-\infty}^\infty e^{tx}f(x)dx & \text{raw}\\
			M^{(r)}(0) &= E[X^r] & \text{center} \\
			E[X] &= M'(0)\\
			V[X] &= M''(0) - (M'(0))^2
		\end{align*}
	\end{description}

\item \textbf{Samples and Estimators}

	\begin{align*}
		\theta &\in \{ p, \mu, \sigma_X^2, \sigma _X\} & \text{actual from population}\\
		\hat{\theta} &\in \{ \hat{p}=X/N,\, \hat{\mu}=\bar{X}=\frac{\sum X_i}{N},\, \sigma_{\hat{\theta}}^2 = S^2 = E[(\bar{X}-X_i)^2],\, \sigma_{\hat{\theta}}=S \} &\text{from sample}\\
		E[X] &= \mu 
	\end{align*}

\item \textbf{Confidence Intervals}
	\begin{align*}
		z_\theta &= \frac{\theta-\mu_\theta}{\sigma_\theta}	\\
		z_{0.05} &= 1.644,\, z_{0.025} = 1.96,\, z_{0.01} = 2.32 \\
		CI &= \mu \pm z_{\alpha/2}\sigma
	\end{align*}		
\item \textbf{Two Sample Confidence Intevals}
	\begin{align*}
		& \BINDEF{ H_0 : \hat{\theta_1} - \hat{\theta_2} = 0 & \text{ no difference }}
			{H_a: | \hat{\theta_1} - \hat{\theta_2} | > 0	 & \text{ one is larger than the other } } \\
		X &= \mu_1 - \mu_2 \\
		\sigma &= \sqrt{\frac{p_1p_2}{n_1}+\frac{p_1p_2}{n_2}}
	\end{align*}
	
\item \textbf{Mean Squared Variance}
	\begin{align*}
		\text{Var}(X-x_0) &= E[(X-x_0)^2]- [E[(x-x_0)]^2 \\
		MSE &= E[(X-x_0)^2] = \text{Var}(X-x_0) + [E[(x-x_0)]^2 \\
		&= \sigma^2 + \beta^2 & \text{variance plus the bias}
	\end{align*}
	
\item \textbf{Covariance and Correlation}
\begin{align*}
	\text{Cov}(X,Y) &= E[(X-\mu_x)(Y-\mu_y)]\\
	\text{Cov}(V,V) &= \text{Var}(V) \\
	\text{Var}(U, V) &= \sum_{i=1}^n\sum_{j=1}^m b_id_j\text{Cov}(X_i, Y_j) \\
	\rho &= \frac{\text{Cov}(X,Y)}{\sqrt{\text{Var}(X)\text{Var}(Y)}} & \text{correlation coefficient}
\end{align*}

\item \textbf{Two Sample Proportion}
\begin{align*}
	\hat{p} &= \frac{x_1+x_2}{n_1+n_2} = \frac{\hat{p_1}n_i+\hat{p_2}n_2}{n_1+n_2}\\
	\hat{q} &= 1-\hat{p} \\
	\hat{p_1}&=\frac{x_1}{n_1},\, \hat{p_2} = \frac{x_2}{n_2} \\
	z &= \frac{(\hat{p_1}-\hat{p_2})-(p_1-p_2)}{\sqrt{\frac{\hat{p}\hat{q}}{n_1}+\frac{\hat{p}\hat{q}}{n_2}}}
\end{align*}
\end{description}


\end{document}