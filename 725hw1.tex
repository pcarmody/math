\documentclass[11pt]{amsart}

\usepackage{amsthm, amssymb,amsmath}
\usepackage{graphicx}

\theoremstyle{definition}  % Heading is bold, text is roman
\newtheorem{theorem}{Theorem}
\newtheorem{definition}{Definition}
\newtheorem{example}{Example}

\newcommand{\ojo}[1]{{\sffamily\bfseries\boldmath[#1]}}

\newcommand{\Z}{\mathbb{Z}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}


\oddsidemargin 0pt
\evensidemargin 0pt
\marginparwidth 0pt
\marginparsep 10pt
\topmargin -10pt
\headsep 10pt
\textheight 8.4in
\textwidth 7in

%\input{../header}


\begin{document}

%\homework{}{Homework I}
\begin{center}
\Large{Math 725 -- Advanced Linear Algebra}\\
\large{Paul Carmody}\\
Assignment \#1 -- Due 8/30/23
\end{center}

\vskip 0.25cm
\noindent
{\bf 1.} 
Show that the {\it positive} quadrant 
$$ Q \, = \, \{ \, (x,y) \, :  x,y > 0\}$$
forms a vector space over $\R$  if we define addition by $(x_1,y_1) + (x_2, y_2) = (x_1x_2, y_1y_2)$ and scalar multiplication by $c (x,y) = (x^c, y^c)$.  \\
\\
Is it closed under addition?  Given any two points $(x_1,y_1),(x_2, y_2)$  we have $(x_1,y_1) + (x_2, y_2) = (x_1x_2, y_1y_2)$ is clearly in $Q$ (the only way that it could be in another quadrant would be if one of the elements $x_1,x_2, y_1,y_2$ is less than zero which isn't possible).  Yes, it is closed under addition.\\
\\
Is it closed under scalar multiplication?  Given any $(x,y) \in Q$ and $c \in \R$ we can see $c(x,y)=(x^c, y^c)$. We know that $f(x)=c^x$ is positive definite for all $c>0$, therefore it is closed under scalar multplication.
\\ \\
======

\vskip 0.1cm
\noindent
{\bf 2.} Let $E$ be a field and $F$ be a subfield of $E$ (this means that $F$ 
is a field on its own right where the addition and multiplication operations of $F$ are inherited from those of $E$). 
Explain the following: $E$ is a vector space over $F$. Also, give an example with concrete fields $E$ and $F$.\\ 
\\
Looking closely at the Definition 1.19 on page 12 of the text, please note that the field $F$ only applies to the scalars in scalar multiplciation.  Thus, when we say "a set $V$ is vector space over a field $W$", the scalars come from $W$.  Thus, "$E$ is a vector space over $F$" means to use any elements of $E$ as vectors and limit the scalar values to elements of $F$.\\
\\
An example is $\Q \subset \R$.  That is, the set of real numbers is a subspace over the set of rational numbers.  Given any $x,y \in \R$ and $q,r \in \Q$ we know that $qx+ry \in \R$.\\
\\
======
\vskip 0.1cm
\noindent
{\bf 3.} Let $V$ and $W$ be two vector spaces over the same field $F$. Explain how you can 
make the cartesian product $V \times W = \{(v,w) \, : \, v \in V, \,\, w \in W\}$ a vector space over $F$. \\
\\
Define addition of $V \times W$ as follows.  Let $(v_1,w_1)$ and $(v_2, w_2)$ members of $V \times W$ with $v_1,v_2 \in V$ and $w_1,w_2 \in W$.  Then $(v_1,w_1)+(v_2,w_2)=(v_1+v_2,w_1+w_2)$.  Clearly, $v_1+v_2\in V$ and $w_1+w_2 \in W$ as they are both vector spaces over $F$.  Therefore $V\times W$ is closed under addition.\\
\\
Define scalar multiplication as $c(v,w)=(cv,cw)$ where $c \in F$.  Clearly $cv\in V$ and $cw\in W$ because both of these are closed under scalar multiplication.  Hence, $V\times W$ is closed under scalar multiplication.\\
\\
Defined in this way, $V \times W$ is a vector space over $F$.\\
\\
======
\newpage
\vskip 0.1cm
\noindent
{\bf 4.} Let $\mathbb{H}^n(\C) \subset M_{n \times n}(\C)$ be the subset of {\it Hermitian} matrices:  a square matrix $A$ with complex coefficients
is Hermitian if $A_{ij} = \overline{A_{ji}}$ for all $1 \leq i,j \leq n$ where $\overline{z}$ is the complex conjugate of $z$. Is $\mathbb{H}^n(\C)$
a $\C$-subspace of $M_{n \times n}(\C)$. Give a proof or a counterexample. Is it an $\R$-subspace of $M_{n \times n}(\C)$ ? \\
\\
First, No, not a $\C$-subspace.  Quite simply.
\begin{align*}
	\text{Let } A &= \left ( \begin{array}{cc}
		1 & 0 \\
		0 & 1
\end{array}	 \right ) \in \mathbb{H}^n(\C) \\
	\text{then } (1+i)A &= (1+i)\left ( \begin{array}{cc}
		1 & 0 \\
		0 & 1
\end{array}	 \right ) = \left ( \begin{array}{cc}
		1+i & 0 \\
		0 & 1+i
\end{array}	 \right ) \not \in \mathbb{H}^n(\C)
\end{align*}
\\
However, as an $\R$-subspace we can see that complex conjugation is closed under addition.  That is 
\begin{align*}
	\overline{(a+ib)+(c+id)} &= \overline{(a+c)+i(b+d)} \\
	&= (a+c)-i(b+d) \\
	&= (a-ib)+(c-id) \\
	&= \overline{a+ib}+\overline{c+id}
\end{align*}.  Therefore, given any $A,B \in \mathbb{H}^n(\C)$ then $\overline{(A+B)_{ij}}= \overline{A_{ij}+B_{ij}} = \overline{A_{ij}}+\overline{B_{ij}} = A_{ji}+B_{ji} = (A+B)_{ji}$ hence $A+B \in \mathbb{H}^n(\C)$
\\ \\
When we limit $c \in \R$, we can see that complex conjugation is closed under scalar multiplication by real values.  That is $\overline{c(a+ib)} = \overline{ca+icb} = ca-icb = c\overline{(a-ib)}$.  Consequently, given any $A \in \mathbb{H}^n(\C), \overline{cA_{ij}}= c\overline{A_{ij}}=cA_{ji}$ hence $cA \in \mathbb{H}^n(\C)$ and therefore closed.\\
\\
======
\vskip 0.1cm
\noindent
{\bf 5.} Let $F$ be a field. Show that in $F^2$ there are only three types of subspaces: $\{0\}$, line generated by a nonzero vector $v \in F^2$, and $F^2$. \\
\\
Let $V$ be a set of vectors in $\R^2$ that forms a vector space and such that $V \ne \{0\}$ and $V\ne \R^2$.  WLOC, let $x, y \in V$ and that they are linearly independent, i.e., not colinear.   Thus, when $\theta x + \phi y = 0$ then $\theta = \phi = 0$ for scalars $\theta$ and $\phi$.  However, given any $r \in \R^2$ we can find scalars $\theta, \phi$ such that $\theta x + \phi y = r$.  That is, any $r \in \R^2$ can be represented by a linear combination of $x$ and $y$. Hence, span$ \{x,y\} = \R^2$ and since $V \subseteq \R^2$ then $V = \R^2$ which is a contradiction.  Therefore, $x,y$ must be linearly dependent implying that alll points in $V$ are linearly dependent and hence a line through the origin.\\
\\
======
\newpage
\vskip 0.1cm
\noindent
{\bf 6.} Let $V$ be a vector space, and let $W$ be a subspace of $V$. For a fixed vector $v \in V$, the set $v + W := \{v + w \, : \, w \in W\}$
is known as an {\it affine subspace} of $V$. \\
\\
{\bf a)} Under what condition(s) is an affine subspace of $V$ a subspace of $V$ ? \\
\\
When the zero vector is a member of $v+W$ namely when $-v \in W$.
\\
\\
{\bf b)} Draw the affine subspace of $\R^2$ when $W$ is the $x$-axis and $v = (2,1)$. \\
\\
This is quite easily the horizontal line that goes through $(2,1)$ or $y=1$\\\includegraphics[scale=0.1]{../../Downloads/desmos-graph.png} 
\\
{\bf c)} Argue that  the plane $x - 2y + 3z = 1$ is an affine subspace of $\R^3$. \\
\\
We know that when $y=z=0$ then $x=1$ which is a point in the plane.  Thus, given any point in this plane if we subtract the point $(1,0,0)$, i.e., let $w$ be a solution to $x-2y+3z=1$ subtracting $(1,0,0)$ from this solution will bring a point in the plane $-2y+3z=0$ passing through the origin which is a subspace of $\R^3$.  Hence, $x-2y+3z=1$ is an affine subspace of $\R^3$. \\
\\
{\bf d)} Show that any two affine subspaces of the form $v + W$ and $u + W$ are either equal or disjoint. \\
\\
If $a \in u+W$ then there exists $x\in W$ such that $a=u+x$. Similarly, if $a \in v+W$ then there exists $y \in W$ such that $a=v+y$.  Thus if $a \in (v+W) \cap (u+W)$ then $u+x=v+y$ and hence $u= v+y-x \in v +W$.  Thus $u+W \subseteq v+W$ and visa versa. This also shows that if $(v+W)\cap(u+W) \ne \emptyset$ then they must be equal hence if $(v+W)\cap(u+W) = \emptyset$ they are by definition disjoint.\\
\\
{\bf e)} Let $v_1, \ldots, v_m$ be vectors in $V$. An {\it affine linear combination} of these vectors is a linear combination of them where
the coefficients of the linear combination add up to $1$: $c_1 v_1 + \ldots + c_m v_m$ where $c_1 + \ldots + c_m =1$. Let 
$\mathrm{affine}\{v_1, \ldots, v_m\}$ be the set of all affine linear combinations of $v_1, \ldots, v_m$. 
Show that $\mathrm{affine}\{v_1, \ldots, v_m\}$ is an affine subspace of $V$.  \\
\\
Let $n$ be the highest number of linearly dependent vectors from $\{v_1, \dots, v_m\}$ and reorder this list so that these vectors are listed first.  We know that $c_1+\cdots+c_m=1$.  We can make a new list $d_1,\dots,d_{m-1}$ with one less element such that $d_i=c_i+\frac{c_m}{m-1}$ whose sum is still 1.  Now we have a linear combination of $m-1$ elements.  We repeat this process, generating a new set of elements with each iteration with one less element until we have $n$ elements. Let's call these elements $e_1,\dots,e_n$.  Let $W=\mathrm{span}\{v_{n+1}, \dots, v_m\}$ which we know is a vector space as they are linearly independent.  Let $u=e_1v_1+\cdots+e_nv_n$, thus $\mathrm{affine}\{v_1,\dots,v_m\} = u+W$.

\end{document}