\documentclass[10pt,a4paper]{report}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{hyperref}

\usepackage{multicol}
\usepackage{fancyhdr}
\usepackage[inline]{enumitem}
\usepackage{tikz}
\usepackage{tikz-cd}
\usetikzlibrary{calc}
\usetikzlibrary{shapes.geometric}
\usepackage[margin=0.5in]{geometry}
\usepackage{xcolor}

\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
    pdftitle={Tensors},
    pdfpagemode=FullScreen,
    }

%\urlstyle{same}

\newcommand{\CLASSNAME}{Math 5301 -- Numerical Analysis}
\newcommand{\STUDENTNAME}{Paul Carmody}
\newcommand{\ASSIGNMENT}{Notes }
\newcommand{\DUEDATE}{Febrauary 14, 2025}
\newcommand{\SEMESTER}{Spring 2025}
\newcommand{\SCHEDULE}{MW 2:00 to 3:15}
\newcommand{\ROOM}{Crawford 330}

\newcommand{\MMN}{M_{m\times n}}
\newcommand{\FF}{\mathcal{F}}

\pagestyle{fancy}
\fancyhf{}
\chead{ \fancyplain{}{\CLASSNAME} }
%\chead{ \fancyplain{}{\STUDENTNAME} }
\rhead{\thepage}
\input{../MyMacros}

\newcommand{\RED}[1]{\textcolor{red}{#1}}

\begin{document}

\begin{center}
	\Large{\CLASSNAME -- \SEMESTER} \\
	\large{ w/Professor Du}
\end{center}
\begin{center}
	\STUDENTNAME \\
	\ASSIGNMENT -- \DUEDATE\\
\end{center} 

April 1, 2025

\textbf{A-Conjugage Gradient Method}

\begin{description}
	\item By Theorem 4.1  of \textit{Finite Difference Methods for Ordinary Differential Equations} page 88.  We have that ... The vectors generated in the CG Algorithm have properties provided $r_k \ne 0$ (if $r_k=0$ then we have converged).
	\begin{enumerate}
		\item $p_k$ is $A$-conjugate to all previous search directions, i.e., $p_k^T Ap_j =0$ for all $j=1,\dots,k-1$.
		\item The residual $r_k$ is orthogonal to all previous residuals $r_k^Tr_j=0$ for $j=0,\dots, k-1$.
		\item The following three subspaces are identical
		\begin{description}
			\item $\SPAN(p_0,p_1,p_2, \dots, p_{k-1})$,
			\item $\SPAN(r_0, Ar_0, A^2r_0, \dots, A^{k-1}r_0)$.
			\item $\SPAN(Ae_0, A^2e_0, \dots, A^ke_0)$.
		\end{description}
	\end{enumerate}
	
	\item Vectors from this/these subspaces take on the linear combination of basis vectors that extrapolates to a polynomial.
	\begin{align*}
		\mathcal{K}_k &=  \SPAN(r_0, Ar_0, A^2r_0, \dots, A^{k-1}r_0)
	\end{align*}and is referred to as the \DEFINE{Krylov Space.}  These take the form of a polynomiald
	\begin{align*}
		P_k(A) &= a_0r_0+a_1Ar_0+a_2A^2r_0+\cdots+a_{k-1}A^{k-1}r_0 \\
		P_k(\lambda_{\max}) &= a_0r_0+a_1\lambda_{\max}r_0+a_2\lambda_{\max}^2r_0+\cdots+a_{k-1}\lambda_{\max}^{k-1}r_0 
	\end{align*}Where $\lambda_{\max}$ is the largest eigenvalue of $A$.
	
	\item the CG algorithm converges to at most $n$ iterations.  Keep in mind that $n$ can be very large ($>> 1000$).
	
\end{description}
\end{document}
