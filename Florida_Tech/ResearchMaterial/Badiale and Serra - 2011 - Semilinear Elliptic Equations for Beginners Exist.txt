Universitext

For other titles in this series, go to
www.springer.com/series/223

Marino Badiale  Enrico Serra

Semilinear
Elliptic Equations
for Beginners
Existence Results via
the Variational Approach

Marino Badiale
Dipartimento di Matematica
Università di Torino
Torino, Italy
marino.badiale@unito.it

Enrico Serra
Dipartimento di Matematica
Università di Torino
Torino, Italy
enrico.serra@polito.it

Editorial board:
Sheldon Axler, San Francisco State University, San Francisco, CA, USA
Vincenzo Capasso, Università degli Studi di Milano, Milan, Italy
Carles Casacuberta, Universitat de Barcelona, Barcelona, Spain
Angus J. Macintyre, Queen Mary, University of London, London, UK
Kenneth Ribet, University of California, Berkeley, CA, USA
Claude Sabbah, CNRS, École Polytechnique, Palaiseau, France
Endre Süli, University of Oxford, Oxford, UK
Wojbor Woyczynski, Case Western Reserve University, Cleveland, OH, USA

ISBN 978-0-85729-226-1
e-ISBN 978-0-85729-227-8
DOI 10.1007/978-0-85729-227-8
Springer London Dordrecht Heidelberg New York
British Library Cataloguing in Publication Data
A catalogue record for this book is available from the British Library
Mathematics Subject Classification (2000): 35-01, 35A15, 35B38, 35J15, 35J20, 35J25, 35J60, 35J61,
35J92
© Springer-Verlag London Limited 2011
Apart from any fair dealing for the purposes of research or private study, or criticism or review, as permitted under the Copyright, Designs and Patents Act 1988, this publication may only be reproduced,
stored or transmitted, in any form or by any means, with the prior permission in writing of the publishers, or in the case of reprographic reproduction in accordance with the terms of licenses issued by the
Copyright Licensing Agency. Enquiries concerning reproduction outside those terms should be sent to
the publishers.
The use of registered names, trademarks, etc., in this publication does not imply, even in the absence of a
specific statement, that such names are exempt from the relevant laws and regulations and therefore free
for general use.
The publisher makes no representation, express or implied, with regard to the accuracy of the information
contained in this book and cannot accept any legal responsibility or liability for any errors or omissions
that may be made.
Cover design: deblik
Printed on acid-free paper
Springer is part of Springer Science+Business Media (www.springer.com)

Preface

This book is an introduction to the study of a wide class of partial differential equations, namely semilinear elliptic problems, through the application of variational
methods and critical point theory. Semilinear elliptic equations arise in a variety of
contexts in geometry, physics, mechanics, engineering and, more recently, in life
sciences. None of these fields can be investigated without taking into account nonlinear phenomena, and variational methods, as a branch or an evolution of the Calculus of Variations, are almost entirely concerned with nonlinearity. The theory has
attained a spectacular success in the last thirty-or-so years, reaching a high level of
complexity and refinement, and its applications are scattered throughout thousands
of research papers. Furthermore, some of the simplest methods within the variational approach are nowadays classical tools in the field of nonlinear differential
equations as fixed point and monotonicity methods are. They have become, in other
words, part of the toolbox that any researcher in the field is supposed to have at
hand.
This poses a stimulating problem: how to teach variational methods and semilinear elliptic equations to upcoming generations of students. In our teaching experience, we have noticed a recurrent phenomenon. Up to a certain grade, students
possess a rather general knowledge of basic principles, for instance in Functional
Analysis. At the next step however they are often confronted with problems taken
from real research. This creates a gap that students generally fill in by themselves,
following a path of hard work that requires a great deal of commitment and selfdiscipline.
Both of us have been teaching courses on the topics collected in this book for a
number of years in various Italian universities, and the didactic demand that we encountered was almost always located in the gap described above. We found that the
many excellent existing books on variational methods and critical point theory (e.g.
[2, 18, 26, 35, 43, 45, 48]), all of them deservedly well-known internationally, are
sometimes problematic for classroom use, precisely because they are too complete,
or too long, or too advanced.
Hence, the purpose of this book, derived directly from classroom experience, is
that of providing a support to the students and the teacher engaged in a first course
in semilinear elliptic equations. We have tried to write a textbook that matches what
v

vi

Preface

we normally write on the blackboard in class. This is why the topics are introduced
gradually, and in certain cases some redundancy is purposely added, to stress the
fundamental steps in the building of the theory. As a consequence, in this book the
reader will not find any sophisticated results, or fancy applications, or fashionable
examples, but rather a first overview on the subject, in a sort of “elliptic equations for
the layman”, where all the details are written down. Every abstract result is immediately put into action to show how it works to solve an elliptic problem, reflecting
the fact that the theory was developed with the intent of treating ever larger classes
of equations. We believe that in this way the reader will be able not only to have the
tools at hand, but also to see how they really act when applied to concrete problems.
In the applications, we limited ourselves to the discussion of Dirichlet boundary
value problems. While this is certainly reductive, it provides nonetheless a unified
thread throughout the book, and has the advantage of introducing the student to the
most common type of boundary conditions. Other types of problems can then be
understood with a minimal effort, and the existing literature provides extensions of
all sorts for the interested reader.
The contents of this book require a general preparation in analysis, including
some notions of Functional Analysis, and some knowledge of the most common
function spaces, such as Lebesgue and Sobolev spaces. These are all notions usually
taught in undergraduate courses throughout the world. In any case, whenever we
quote a result without proving it, we provide precise references for consultation.
These notes are to be used by two possibly distinct categories of students: those
who need to know how some types of nonlinear problems can be handled, and who
need the basic working tools from the variational approach and critical point theory,
as well as students who are oriented towards research in the field of nonlinear differential equations. Clearly if for the former this book may be the last they read on
the subject, for the latter it should be just the first. We set the level of these notes
between a graduate course and a first year PhD course. Mathematicians, physicists
and engineers are the natural audience this book is addressed to.
The material is divided into four chapters. The first one is an introduction, and
contains a review of differential calculus for functionals, with many examples, and
a few basic facts from the linear theory that will be used throughout the book. Convexity arguments complete the discussion providing the first examples of existence
theorems.
Chapter 2 introduces the fundamentals of minimization techniques, for it is wellknown that the simplest way to obtain a critical point of a functional is to look for
a global extremum, which in most of the cases is a global minimum. However, for
indefinite (unbounded) functionals, although global minimum points cannot exist,
minimization techniques can still be profitably used by constraining the functional
on a set where it is bounded from below. Typical examples of such sets are spheres
or the Nehari manifold. The unifying feature of this chapter is the fact that all problems share some compactness properties that simplify the convergence arguments.
A final section contains some examples of quasilinear problems, to show how the
methods constructed for semilinear equations can be easily applied to more difficult
problems.

Preface

vii

On the contrary, Chapter 3 is still devoted to minimization techniques, but this
time the examples are all taken from problems that lack compactness. Typically
this may happen when the domain on which the equation is studied is not bounded
or when the growth of the nonlinearity reaches a critical threshold. The chapter
discusses some of the most common ways to overcome these problems, that are
often very hard to solve. Of course only some prototype cases are presented, which
is in the spirit of these notes.
Chapter 4 introduces the reader to the more refined variational methods, where
minimization is replaced by minimax procedures. The methods are first introduced
in an abstract setting, so that the reader can dispose of a general principle that is
suited to handling more sophisticated procedures, beyond the scope of this book.
Then we concentrate on the two most popular and widespread results: the Mountain
Pass Theorem and the Saddle Point Theorem, each discussed with applications to
the specific problems that motivated them.
Each chapter is accompanied by a selection of exercises, some of them guided,
to test the reader’s ability to refine and put into action the techniques just discussed.
A short bibliographical note closes each chapter: the interested reader can find
there suggestions for further reading, mainly taken from more advanced books or
from the celebrated papers that first solved the problems discussed in the text.
Torino, Italy

Marino Badiale
Enrico Serra

Contents

1

Introduction and Basic Results . . . . . . . . . . . . . . . . . . . . .
1.1 Motivations and Brief Historical Notes . . . . . . . . . . . . . . .
1.2 Notation and Preliminaries . . . . . . . . . . . . . . . . . . . . .
1.2.1 Function Spaces . . . . . . . . . . . . . . . . . . . . . . .
1.2.2 Embeddings . . . . . . . . . . . . . . . . . . . . . . . . .
1.2.3 Elliptic Equations . . . . . . . . . . . . . . . . . . . . . .
1.2.4 Frequently Used Results . . . . . . . . . . . . . . . . . . .
1.3 A Review of Differential Calculus for Real Functionals . . . . . .
1.3.1 Examples in Abstract Spaces . . . . . . . . . . . . . . . .
1.3.2 Examples in Concrete Spaces . . . . . . . . . . . . . . . .
1.4 Weak Solutions and Critical Points . . . . . . . . . . . . . . . . .
1.5 Convex Functionals . . . . . . . . . . . . . . . . . . . . . . . . .
1.6 A Few Examples . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.7 Some Spectral Properties of Elliptic Operators . . . . . . . . . . .
1.8 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.9 Bibliographical Notes . . . . . . . . . . . . . . . . . . . . . . . .

1
1
5
5
7
8
9
11
15
16
22
25
28
31
35
37

2

Minimization Techniques: Compact Problems . . . . . . . . . . . . .
2.1 Coercive Problems . . . . . . . . . . . . . . . . . . . . . . . . . .
2.2 A min–max Theorem . . . . . . . . . . . . . . . . . . . . . . . .
2.3 Superlinear Problems and Constrained Minimization . . . . . . . .
2.3.1 Minimization on Spheres . . . . . . . . . . . . . . . . . .
2.3.2 Minimization on the Nehari Manifold . . . . . . . . . . . .
2.4 A Perturbed Problem . . . . . . . . . . . . . . . . . . . . . . . . .
2.5 Nonhomogeneous Nonlinearities . . . . . . . . . . . . . . . . . .
2.6 The p-Laplacian . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.6.1 Basic Theory . . . . . . . . . . . . . . . . . . . . . . . . .
2.6.2 Two Applications . . . . . . . . . . . . . . . . . . . . . .
2.7 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.8 Bibliographical Notes . . . . . . . . . . . . . . . . . . . . . . . .

39
39
46
55
56
59
63
74
86
87
91
93
95
ix

x

Contents

3

Minimization Techniques: Lack of Compactness . . . . . . . . . . . 97
3.1 A Radial Problem in RN . . . . . . . . . . . . . . . . . . . . . . . 97
3.2 A Problem with Unbounded Potential . . . . . . . . . . . . . . . . 104
3.3 A Serious Loss of Compactness . . . . . . . . . . . . . . . . . . . 107
3.4 Problems with Critical Exponent . . . . . . . . . . . . . . . . . . 119
3.4.1 The Prototype Problem . . . . . . . . . . . . . . . . . . . 120
3.4.2 A Problem with a Radial Coefficient . . . . . . . . . . . . 129
3.4.3 A Nonexistence Result . . . . . . . . . . . . . . . . . . . 136
3.5 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 140
3.6 Bibliographical Notes . . . . . . . . . . . . . . . . . . . . . . . . 143

4

Introduction to Minimax Methods . . . . . . . . . . . . . . . . . . . 145
4.1 Deformations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 146
4.2 The Minimax Principle . . . . . . . . . . . . . . . . . . . . . . . 153
4.3 Two Classical Theorems . . . . . . . . . . . . . . . . . . . . . . . 155
4.4 Some Applications . . . . . . . . . . . . . . . . . . . . . . . . . . 160
4.4.1 Superlinear Problems . . . . . . . . . . . . . . . . . . . . 160
4.4.2 Asymptotically Linear Problems . . . . . . . . . . . . . . 167
4.4.3 A Problem at Resonance . . . . . . . . . . . . . . . . . . . 171
4.5 Problems with a Parameter . . . . . . . . . . . . . . . . . . . . . 178
4.6 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 186
4.7 Bibliographical Notes . . . . . . . . . . . . . . . . . . . . . . . . 188

Index of the Main Assumptions . . . . . . . . . . . . . . . . . . . . . . . . 191
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 193
Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 197

Chapter 1

Introduction and Basic Results

In this chapter, after a short historical overview, we introduce the fundamental notions to be used later and the first existence results, based on convexity arguments.

1.1 Motivations and Brief Historical Notes
Semilinear elliptic equations are the first nonlinear generalization of linear elliptic
partial differential equations. It is well known that linear elliptic equations, like the
ubiquitous Laplace and Poisson equations, represent models for wide classes of
physical problems. This is the reason why they have been studied for more than two
hundred years and continue to attract researchers even today. One example is that the
solutions of the Laplace and Poisson equations can represent the stationary solutions
(i.e. the state of a system when equilibrium is reached) of evolution equations of the
utmost physical importance, such as heat and wave equations. Solutions of these
equations also represent or describe the potential of force fields, in a variety of
physical contexts, like electromagnetism, gravitation, fluid dynamics and so on.
It is also noted that the linear equations commonly used in mathematical physics
are very often just a first approximation, valid within the range of certain assumptions, of more complex equations modelling phenomena of a nonlinear nature. Under slightly less restrictive assumptions one is frequently led from linear to semilinear equations, namely equations where the nonlinearity involves the unknown function, but not its derivatives. In addition, we recall that semilinear elliptic equations
manifest themselves even in quantum physics, despite the fact that the fundamental
structure of quantum physics is of a linear nature.
Some examples of semilinear elliptic equations include
−u = f (x, u),
representing the stationary states of nonlinear heat equations like
ut − u = f (x, u),
or nonlinear wave equations, such as
utt − u = f (x, u).
M. Badiale, E. Serra, Semilinear Elliptic Equations for Beginners, Universitext,
DOI 10.1007/978-0-85729-227-8_1, © Springer-Verlag London Limited 2011

1

2

1

Introduction and Basic Results

In all these examples u is the unknown, f is a (nonlinear) function, and  is the
Laplace operator.
In optics and in the theory of water waves one encounters the nonlinear
Schrödinger equations,
iut + u = κ|u|p u,
and again the stationary solutions solve the corresponding semilinear equation.
The elliptic sine-Gordon equation
−u + sin u = 0
appears in geometry, in the study of surfaces of constant negative curvature, and,
again in geometry, important semilinear equations are related to classical problems,
such as prescribing the scalar curvature on a manifold (the Yamabe problem).
The theory of Bose–Einstein condensates uses the time-independent Gross–
Pitaevskii equation
−u + q(x)u + a|u|2 u = λu.
The scalar field equations in classical or quantum physics are noteworthy; they have
the form
−u = f (u),
for example
−u = u3 − u.
These are just a few examples of semilinear elliptic equations, which illustrate their
frequent appearance in various areas of science.
The next step towards more complex nonlinear equations is given by quasilinear
equations, where the nonlinear dependence involves not only the unknown function,
but also all of its derivatives except those of the highest order. A very common class
of quasilinear equations is given by the so-called p-Laplace equations, where the
Laplacian is replaced by the operator


div |∇u|p−2 ∇u ,
which reduces to the usual Laplacian when p = 2.
The highest degree of nonlinearity is reached with fully nonlinear equations, in
which the unknown function and all its derivatives are combined nonlinearly, as in
the Monge–Ampère equations


det D 2 u = f (x, u, ∇u).
As a general principle, the more nonlinear the equation is, the more difficult it is.
In this book we concentrate on some types of semilinear elliptic equations, with
some excursions into the realm of p-Laplace equations, confining ourselves to the
cases where the theory developed for semilinear equations extends easily to the
quasilinear context.

1.1 Motivations and Brief Historical Notes

3

Of course elliptic equations can be studied with an astonishing variety of methods
and techniques. In this book we present the variational approach, which is relatively
simple, elegant and successful with large classes of problems.
Variational methods have a long history, which probably originated from the brachistochrone problem posed in 1696 and solved by Newton, Leibniz, Jakob and
Johann Bernoulli, as well as de L’Hôpital, although the problem of surfaces of
revolution in a resisting medium studied by Newton dates back even further. Major
contributions were also given by Euler, who published the first monograph on the
Calculus of Variations in 1744, and by Lagrange who introduced formalisms and
techniques essentially still in use today. The Maupertuis least action principle was
another of the first variational frameworks to be set.
The “classical” example for the problems studied in this book is the Dirichlet
Principle, namely the fact that the solution of a differential equation (of elliptic type)
coupled with a boundary condition can be obtained as a minimizer of an appropriate
functional. In one of the most classical cases, an open set  in the plane or in the
space is given, along with a real function f defined on the boundary of . The
problem consists in finding a function u :  → R satisfying the boundary value
problem

u = 0 in ,
(1.1)
u=f
on ∂.
Under suitable assumptions, the (unique) solution of (1.1) is characterized as being
the absolute minimum of the functional

I (u) = |∇u|2 dx


among all u’s taking the value f on ∂ and belonging to a convenient function
space.
Riemann introduced this point of view in 1851, and gave the name of Dirichlet
Principle to the process of solving (1.1) by minimizing I . Although the Dirichlet
Principle is elegant and can be applied to wide classes of problems other than (1.1),
the proof supplied by Riemann cannot be considered correct, as was duly pointed out
by Weierstrass. The problem lies in the fact that when working in function spaces,
and hence in infinite dimensional vector spaces, the familiar compactness properties
from finite dimension are no longer true, and the schemes of proof of existence of
extrema, largely based on compactness arguments, break down. These facts had not
yet been fully recognized at the time of Riemann.
The theoretical settlement of these kinds of difficulties required and stimulated
the extraordinary development of functional analysis, measure theory and integration that exploded during the twentieth century, with the accurate study of topological and metric properties of infinite dimensional vector spaces, the Lebesgue theory
of integration, and many other theoretical cornerstones.
The fundamental idea behind the Dirichlet Principle is the interpretation of a
differential problem, written abstractly as F (u) = 0, as
I  (u) = 0,

4

1

Introduction and Basic Results

where I is a suitable functional defined on a set of functions, and I  the differential
of I in a sense to be made precise. In other words, zeros of F are seen as critical
points (not necessarily minima) of I . The equation I  (u) = 0 is the Euler, or Euler–
Lagrange equation associated with I .
Many times, it turns out that it is much easier to find a critical point of I than to
work directly on the equation F (u) = 0. Furthermore, in countless applications the
functional I has a fundamental physical meaning. Often I is an energy of some sort,
written as the integral of a Lagrangian, and hence finding a minimum point means
not only solving the differential equation, but finding the solution of minimal energy,
frequently of particular relevance in concrete problems. The interpretation of I as an
energy is so frequent that the functionals associated with differential problems are
normally called energy functionals, even when the problem has no direct physical
applications.
Of course not all differential problems can be written in the form I  (u) = 0.
When this is possible, one says that the problem is variational, or has a variational
structure, and these are the only type of problems that we address in these notes.
In the course of the twentieth century, after the settlement of functional analysis, the study of function spaces, the extension of differential calculus to normed
spaces, variational methods have never ceased to be developed. On the one hand,
minimization techniques have evolved to a very high level of efficiency, and have
been applied to an enormous number of problems from all fields of pure and applied
science. The body of methods concerned with minimization of functionals goes under the name of direct methods of the Calculus of Variations. On the other hand,
the procedures aimed at the search for critical points of functionals that need not be
minimum points have given rise to a branch of nonlinear analysis known as Critical
Point Theory. Among the precursors of this theory are Ljusternik and Schnirelman,
with their celebrated 1929 work on the existence of closed geodesics, and Morse,
who laid the foundations of global analysis.
One of the most fruitful ideas that came out of this early research is the notion that the existence of critical points is very intimately related to the topological
properties of the sublevel sets of the functional, in the sense that a change in the
topological type of sublevels reveals the existence of a critical point, provided some
compactness properties are satisfied. The systematization of the required compactness properties in the infinite dimensional setting is due to Palais and Smale, who
introduced a compactness condition that bears their name and is nowadays accepted
as the most functional notion.
The two factors—change of topology and compactness—have been later encompassed in specific, ready-to-use results for the researcher working in semilinear elliptic equations. The two most famous such results are the 1973 Mountain Pass
Theorem by Ambrosetti and Rabinowitz, and the 1978 Saddle Point Theorem by
Rabinowitz. This is where the “elementary” variational methods end, and make
space for the most recent and sophisticated techniques, starting from linking theorems, index theories to prove the existence of multiple critical points, and onwards
to the borders of current research.

1.2 Notation and Preliminaries

5

1.2 Notation and Preliminaries
The notation we use throughout this book is standard. For convenience we list below
the main symbols and notions that the reader is supposed to know. Proofs can be
found in any text in Functional Analysis, such as [11], or [17].
The symbol  will always stand for an open subset of RN . The space RN is
endowed with the Lebesgue measure dx, and all integrals are to be considered in
the sense of Lebesgue. The measure of a set E ⊂ RN is denoted by |E|. We say that
a property holds almost everywhere (shortly: a.e.) in  if there exists a set E ⊂ 
of measure zero such that the property holds at every point of  \ E.
The scalar product of two vectors x, y in RN is denoted by a dot: x · y, while the
scalar product of two vectors u, v in a Hilbert space H is denoted by the symbol
(u | v).
If u :  → R is differentiable, the gradient of u at x = (x1 , . . . , xN ) is the vector
∂u
∂u
∇u(x) = ( ∂x
(x), . . . , ∂x
(x)).
N
1
The letter C denotes a positive constant that can change from line to line. Finally,
when taking limits, the symbol o(1) stands for any quantity that tends to zero.

1.2.1 Function Spaces
• C k (), for k = 1, 2, . . . is the space of functions u :  → R that are k times
differentiable in  and whose k-th derivatives are continuous in .
• C ∞ () is the space of functions u :  → R that are infinitely many times differentiable in .
• C0∞ () is the subspace of C ∞ () consisting of functions with compact support
in ; the support of a (continuous) function u :  → R, denoted by spt u is the
closure (in RN ) of the set {x ∈  | u(x) = 0}. Likewise, C0k () is the subset of
C k () containing only functions with compact support.
• Lp (), for p ∈ [1, +∞), is the Lebesgue
 space of measurable functions
(Lebesgue measure) u :  → R such that  |u(x)|p dx < +∞, while L∞ ()
is the space of measurable functions such that ess supx∈ |u(x)| < +∞. We recall that
ess sup |u(x)| = inf{C > 0 | |u(x)| ≤ C a.e. in }.
The norms that make Lp () Banach spaces are, respectively,

1/p
p
|u(x)| dx
and |u|∞ = ess sup |u(x)|.
|u|p =


p
• Lloc () is the space of measurable functions u :  → R such that for every compact set K ⊂ , |u|Lp (K) < +∞.
• H 1 () is the Sobolev space defined by


H 1 () = u ∈ L2 ()

∂u
∈ L2 (), i = 1, . . . , N ,
∂xi

6

1

Introduction and Basic Results

∂u
where the derivative ∂x
is in the sense of distributions. It is a Hilbert space, when
i
endowed with the scalar product given by


(u | v) = ∇u · ∇v dx + uv dx.




The corresponding norm is therefore

1/2

2
2
u = (u | u) =
|∇u| dx + u dx
.




• H01 () is the closure of C0∞ () in H 1 (). The norm in H 1 () and in H01 ()
will always be denoted by u .
Functions in H01 () are to be thought of as functions that vanish on ∂. This
is a delicate notion, since ∂ has measure zero, and a complete justification of
the preceding sentence can only be carried out by means of the theory of traces
(see e.g. [18]). However, as soon as u is regular enough to allow classical restrictions, there is a complete equivalence, in the following sense. Assume that ∂ is
smooth, and that u ∈ H 1 () ∩ C(). Then u ∈ H01 () if and only if u = 0 on
∂ (see [11]).
A useful extension property of H01 () is the following. Let u ∈ H01 (), and
let  be an open set such that  ⊂  . If one extends u to  by setting

u(x) if ∈ ,
ũ(x) =
0
if x ∈  \ ,
then ũ ∈ H01 ( ).
The space H01 (RN ) coincides with H 1 (RN ).
Finally, we recall (see [18]) that if u ∈ H 1 (), then |u| ∈ H 1 (); therefore if
we set
u+ (x) = max(u(x), 0)

and u− (x) = − min(u(x), 0),

then u+ , u− ∈ H 1 (), since u+ = 12 (u + |u|) and u− = 12 (|u| − u).
Also,


2
∇|u| dx = |∇u|2 dx




for every u ∈ H 1 ().

• D 1,2 (RN ), for N ≥ 3, is the space defined as follows: let 2∗ = N2N
−2 (see the next
subsection for a short description of the role of this number); then

∂u
∗
∈ L2 (RN ), i = 1, 2, . . . , N .
D 1,2 (RN ) = u ∈ L2 (RN )
∂xi
This space has a Hilbert structure when endowed with the scalar product

∇u · ∇v dx,
(u | v) =
RN

1.2 Notation and Preliminaries

7

so that the corresponding norm is
u =

(u | u) =



1/2
RN

|∇u|2 dx

.

The space C0∞ (RN ) is dense in D 1,2 (RN ).
Of course H 1 (RN ) ⊂ D 1,2 (RN ), but there are functions, such as
1
u(x) =
,
(1 + |x|)N/2
that are in D 1,2 (RN ) but not in L2 (RN ), and hence not in H 1 (RN ).

1.2.2 Embeddings
We recall that a Banach space X is embedded continuously in a Banach space Y
(X → Y ) if
1. X ⊆ Y ;
2. the canonical injection j : X → Y is a continuous (linear) operator. This means
that there exists a constant C > 0 such that j (u) Y ≤ C u X , which one writes
u Y ≤ C u X , for every u ∈ X.
A Banach space X is embedded compactly in a Banach space Y if X is embedded
continuously in Y and the canonical injection j is a compact operator.
The following results are the particular cases of the Sobolev and Rellich Embedding theorems that we need in this book. First we deal with functions defined on
bounded sets.
Theorem 1.2.1 Let  ⊂ RN be an open and bounded subset of RN , with N ≥ 3.
Then
2N
.
H01 () → Lq () for every q ∈ 1,
N −2
The embedding is compact if and only if q ∈ [1, N2N
−2 ).
∗
The number N2N
−2 is denoted by 2 and is called the critical Sobolev exponent
1
q
for the embedding of H0 into L . The term “critical” refers to the fact that the
embedding of the preceding theorem fails for q > 2∗ .
For functions defined on general, unbounded domains, in view of our applications we limit ourselves to the case  = RN .

Theorem 1.2.2 Let N ≥ 3. Then
• H 1 (RN ) → Lq (RN ) for every q ∈ [2, N2N
−2 ];
∗
1,2
N
2
N
• D (R ) → L (R ).
These embeddings are never compact.

8

1

Introduction and Basic Results

We point out that the continuity of the above embeddings is expressed explicitly
by inequalities of the form
|u|q ≤ C u

∀u ∈ H01 (),

where C does not depend on u. Inequalities of this type are often referred to as
Sobolev inequalities.

1.2.3 Elliptic Equations
This book is devoted to elliptic differential equations of the second order. We recall
the definition of elliptic differential operator.
Let  be an open subset of RN , with N ≥ 2. A second order linear differential
operator L with nonconstant coefficients acting on functions u :  → R has the
general form
Lu = −

N

i,j =1


∂ 2u
∂u
+
bi (x)
+ q(x)u,
∂xi ∂xj
∂xi
N

aij (x)

(1.2)

i=1

where the coefficients aij , bi and q are functions defined on  satisfying some regularity requirement, such as continuity, boundedness, measurability, or other assumptions that depend on the problem one is interested in.
The operator L is said to be in divergence form if

 
N
N

∂
∂u
∂u
Lu = −
aij (x)
+
bi (x)
+ q(x)u.
(1.3)
∂xi
∂xj
∂xi
i,j =1

i=1

Every operator in the form (1.2) can be put in divergence form, and conversely, every
operator in divergence form can be written as in (1.2), provided the coefficients aij
are smooth enough (say differentiable). Passing from one form to the other alters the
coefficients of the first order terms, but nothing else. Hence, for smooth coefficients,
the two forms can be considered equivalent.
The name “divergence form” has the following explanation. Define a function A
from  to the set of N × N matrices by
A(x) = (aij (x))ij .
Then the principal part of the operator (namely the part containing the second order
derivatives) is exactly
− div (A(x)∇u) .
Definition 1.2.3 A second order linear differential operator L given by (1.2) or
(1.3) is called uniformly elliptic on  if there exists λ > 0 such that
N

i,j =1

aij (x)ξi ξj ≥ λ|ξ |2

∀ξ ∈ RN and for a.e. x ∈ .

1.2 Notation and Preliminaries

9

In other words, L is (uniformly) elliptic if the quadratic form ξ → A(x)ξ · ξ is
(uniformly) positive definite in .
Uniformly elliptic operators tend to behave all in the same way for many questions. However, for the variational approach, which is the object of this book, the
first order terms have to be neglected. Therefore we will always consider operators
in divergence form without first order terms, namely
Lu = − div (A(x)∇u) + q(x)u,
and we will always assume L to be uniformly elliptic. Since under reasonable assumptions on the matrix A these operators really behave in the same way, it is customary to develop the theory for the model case, in which A is the identity matrix I .
In this case,
Lu = − div (A(x)∇u) = − div (I ∇u) =

N

∂ 2u
i=1

∂xi2

=: −u.

(1.4)

The operator  is called the Laplace operator, or the Laplacian.
Remark 1.2.4 The reader may perhaps wonder why the differential operators are
written with a “minus” sign in front of them. The reason will be clear in Sect. 1.4:
in the definition of weak solution the minus sign disappears, and it is preferable to
write it in the equation than to have it the definition of weak solution or in other
quantities of common use.

1.2.4 Frequently Used Results
As a fast reference for the reader we state some classical results that we will use
freely in the sequel.
Theorem 1.2.5 (Green’s formula) Let  ⊂ RN be open, bounded and smooth. Let
u ∈ C 2 () and v ∈ C 1 (). Then



∂u
v dσ − ∇u · ∇v dx,
(u) v dx =
(1.5)

∂ ∂ν

where ν = ν(x) is the outward normal to ∂ at x, ∂u
∂ν (x) = ∇u(x) · ν(x) and σ is
the surface measure on ∂.
Theorem 1.2.6 (Lebesgue, or dominated convergence) Let  ⊂ RN be open and
let {uk }k ⊂ L1 () be a sequence such that
1. uk (x) → u(x) a.e. in  as k → ∞;
2. there exists v ∈ L1 () such that for all k, |uk (x)| ≤ v(x) a.e. in .

Then u ∈ L1 () and uk → u in the L1 () norm, namely  |uk − u| dx → 0.

10

1

Introduction and Basic Results

Theorem 1.2.7 Let  ⊂ RN be open and let {uk }k ⊂ Lp (), p ∈ [1, +∞], be a
sequence such that uk → u in Lp () as k → ∞. Then there exist a subsequence
{ukj }j and a function v ∈ Lp () such that
1. ukj (x) → u(x) a.e. in  as j → ∞;
2. for all j , |ukj (x)| ≤ v(x) a.e. in .
Theorem 1.2.8 (Poincaré inequality) Let  ⊂ RN be open and bounded. Then
there exists a constant C > 0, depending only on , such that


u2 dx ≤ C |∇u|2 dx ∀u ∈ H01 ().





1
As a consequence, the quantity (  |∇u|2 dx) 2 is a norm on H01 (), equivalent
to the standard one.
Theorem 1.2.9 (Riesz) Let H be a Hilbert space, and let H  be its topological
dual. Then for every f ∈ H  there exists a unique uf ∈ H such that
f (v) = (uf | v)

∀v ∈ H.

Moreover, uf H = f H  . The linear application R : H  → H that sends f to uf
is called the Riesz isomorphism.
Theorem 1.2.10 (Banach–Alaoglu) Let X be a reflexive Banach space. If B ⊂ X
is bounded, then B is relatively compact in the weak topology of X.
In a Banach space X with dual X  , we write uk → u when the sequence {uk }k
converges strongly to u, that is, in the strong topology of X, which means that
u if uk converges weakly to u, i.e. in the
uk − u X → 0 as k → ∞; we write uk
weak topology of X, which means that
f (uk ) → f (u)

as k → ∞ ∀f ∈ X  .

Example 1.2.11 The following chain of arguments is used very frequently, often
in an automatic way. Let  ⊂ RN be open and bounded. Suppose that a sequence
{uk }k ⊂ H01 () satisfies

|∇uk |2 dx ≤ C


for all k, for some C > 0 independent of k. By Theorem 1.2.8, the sequence uk is
bounded in H01 (). The space H01 (), being a Hilbert space, is reflexive. Therefore by the Banach–Alaoglu Theorem the sequence is relatively compact in H01 ()

1.3 A Review of Differential Calculus for Real Functionals

11

endowed with the weak topology. This means that there exist u ∈ H01 () and a
subsequence that we call again uk , such that
uk

u

in H01 ().

By Theorem 1.2.1, the embedding of H01 () into Lp () is compact for every
p ∈ [1, N2N
−2 ). Then we can say that

2N
p
uk → u in L () for every p ∈ 1,
.
N −2
By Theorem 1.2.7 there exists another subsequence, still denoted uk , such that also
uk (x) → u(x)

a.e. in .


Summing up, whenever a sequence {uk }k ⊂ H01 () satisfies supk  |∇uk |2 dx <
+∞, we can deduce that there exists u ∈ H01 () such that, up to subsequences,
• uk
u in H01 ();
• uk → u in Lp (), ∀p ∈ [1, N2N
−2 );
• uk (x) → u(x) a.e. in ;
moreover, again by Theorem 1.2.7, there exists w ∈ Lp () such that |uk (x)| ≤ w(x)
a.e. in  and for all k.

1.3 A Review of Differential Calculus for Real Functionals
We present a short review of the main definitions and results concerning the differential calculus for real functionals defined on a Banach space. A complete discussion
of this subject, and more generally of differential calculus in normed spaces can be
found for example in [4].
Whenever X is a Banach space, we denote by X  its (topological) dual, namely
the space of continuous linear functionals from X to R. We recall that X  is a Banach
space endowed with the norm
A = sup |A(u)|.
u∈X

u =1

If X is a Banach space and U ⊂ X, a functional I on U is an application I : U → R.
The elements of X  are particular cases of functionals (they are linear and continuous). In this book the attention is devoted to general, nonlinear functionals.
We present the two principal definitions of differentiability and their main properties. Examples will be given next.
Definition 1.3.1 Let X be a Banach space, U an open subset of X and let I : U → R
be a functional. We say that I is (Fréchet) differentiable at u ∈ U if there exists
A ∈ X  such that
I (u + v) − I (u) − Av
= 0.
(1.6)
lim
v →0
v

12

1

Introduction and Basic Results

Thus, for a differentiable functional I , we have
I (u + v) − I (u) = Av + o( v )
as v → 0 for some A ∈ X  , namely the increment I (u + v) − I (u) is linear in v,
up to a higher order quantity. This of course implies that if I is differentiable at u,
then I is continuous at u.
Remark 1.3.2 If a functional I is differentiable at u, there is a unique A ∈ X  satisfying Definition 1.3.1. Indeed, if A and B are two elements of X  that satisfy (1.6),
then plainly
lim

v →0

(A − B)v
= 0,
v

so that, if u ∈ X and u = 1,
(A − B)u = lim

t→0+

(A − B)(tu)
= 0,
t

which means A = B.
Definition 1.3.3 Let I : U → R be differentiable at u ∈ U . The unique element of
X  such that (1.6) holds is called the (Fréchet) differential of I at u, and is denoted
by I  (u) or by dI (u). We thus have
I (u + v) = I (u) + I  (u)v + o( v )

(1.7)

as v → 0.
Notice that I  (u) is defined on X, even if I is defined only in U .
In the literature the terms differentiability and Fréchet differentiability are commonly interchanged. We will also do so, unless we deal with more than one notion
of differentiability at the same time.
Definition 1.3.4 Let U ⊆ X be an open set. If the functional I is differentiable at
every u ∈ U , we say that I is differentiable on U . The map I  : U → X  that sends
u ∈ U to I  (u) ∈ X  is called the (Fréchet) derivative of I . Note that I  is in general
a nonlinear map. If the derivative I  is continuous from U to X  we say that I is of
class C 1 on U and we write I ∈ C 1 (U ).
A particular but very important case is that of real functionals defined on a Hilbert
space H with scalar product (·|·). Indeed since H  and H can be identified via the
Riesz isomorphism R : H  → H (see Theorem 1.2.9), the linear functionals on H
can be represented by the scalar product in H , in the sense that for every A ∈ H 
there exists a unique RA ∈ H such that
A(u) = (RA|u)

for every u ∈ H .

1.3 A Review of Differential Calculus for Real Functionals

13

Definition 1.3.5 Let H be a Hilbert space, U ⊆ H an open set and let R : H  → H
be the Riesz isomorphism. Assume that the functional I : U → R is differentiable
at u. The element RI  (u) ∈ H is called the gradient of I at u and is denoted by
∇I (u); therefore
I  (u)v = (∇I (u)|v)

for every v ∈ H .

The following proposition collects the properties of differentiable functionals
that we will use repeatedly.
Proposition 1.3.6 Assume that I and J are differentiable at u ∈ U ⊆ X . Then the
following properties hold:
1. if a and b are real numbers, aI + bJ is differentiable at u and
(aI + bJ ) (u) = aI  (u) + bJ  (u);
2. the product I J is differentiable at u and
(I J ) (u) = J (u)I  (u) + I (u)J  (u);
3. if γ : R → U is differentiable at t0 and u = γ (t0 ), then the composition
η : R → R defined by η(t) = I (γ (t)) is differentiable at t0 and
η (t0 ) = I  (u)γ  (t0 );
4. if A ⊆ R is an open set, f : A → R is differentiable at I (u) ∈ A, then the composition K(u) = f (I (u)) is defined in an open neighborhood V of u, is differentiable at u and
K  (u) = f  (I (u))I  (u).
Proof The first statement is trivial. As to the second, when v → 0 in X, we have



I (u + v)J (u + v) = I (u) + I  (u)v + o( v ) J (u) + J  (u)v + o( v )
= I (u)J (u) + J (u)I  (u)v + I (u)J  (u)v
+ I  (u)vJ  (u)v + o( v )


× I (u) + I  (u)v + J (u) + J  (u)v + o( v ) .
Since the last line is o( v ), we obtain



I (u + v)J (u + v) = I (u)J (u) + J (u)I  (u) + I (u)J  (u) v + o( v ),

as we wanted to prove.
In a similar way, as h → 0,
η(t0 + h) = I (γ (t0 + h)) = I (γ (t0 ) + γ  (t0 )h + o(h))
= I (u) + I  (u)(γ  (t0 )h + o(h)) + o( γ  (t0 )h + o(h) )
= η(t0 ) + I  (u)γ  (t0 )h + I  (u)o(h) + o( γ  (t0 )h + o(h) ).

14

1

Introduction and Basic Results

Since the last two terms are o(|h|), we obtain
η(t0 + h) = η(t0 ) + (I  (u)γ  (t0 ))h + o(|h|),
namely η is differentiable at t0 and η (t0 ) = I  (u)γ  (t0 ).
Finally, when v → 0 in X, one easily checks that
K(u + v) = f (I (u + v)) = f (I (u) + I  (u)v + o( v ))
= f (I (u)) + f  (I (u))(I  (u)v + o( v )) + o(I  (u)v + o( v ))
= f (I (u)) + f  (I (u))I  (u)v + o( v ),
so that also the fourth statement follows.



We now introduce a second, weaker notion of differentiability. This is often simpler to check in concrete cases than (Fréchet) differentiability.
Definition 1.3.7 Let X be a Banach space, U ⊆ X an open set and let I : U → R be
a functional. We say that I is Gâteaux differentiable at u ∈ U if there exists A ∈ X 
such that, for all v ∈ X,
I (u + tv) − I (u)
= Av.
t→0
t
lim

(1.8)

If I is Gâteaux differentiable at u, there is only one linear functional A ∈ X  satisfying (1.8). It is called the Gâteaux differential of I at u and is denoted by IG (u).
By the very definition of Fréchet differentiability, it is obvious that if I is differentiable at u, then it is also Gâteaux differentiable and I  (u) = IG (u). It is not true
that Gâteaux differentiability implies differentiability, exactly as in RN directional
differentiability does not imply differentiability. However, Proposition 1.3.8 below
gives a relevant result in this direction.
As for the notion of differentiability, if the functional I is Gâteaux differentiable
at every u of an open set U ⊂ X, we say that I is Gâteaux differentiable on U . The
(generally nonlinear) map IG : U → X  that sends u ∈ U to IG (u) ∈ X  is called the
Gâteaux derivative of I .
We have the following classical result; for the proof see e.g. [4].
Proposition 1.3.8 Assume that U ⊆ X is an open set, that I is Gâteaux differentiable on U and that IG is continuous at u ∈ U . Then I is also differentiable at u,
and of course IG (u) = I  (u).
Remark 1.3.9 The importance of this proposition lies in the fact that it is often technically easier to compute the Gâteaux derivative and then prove that it is continuous,
rather than proving directly the (Fréchet) differentiability.
We conclude with the definitions of critical points and critical levels, which will
be one of the main concerns of this book.

1.3 A Review of Differential Calculus for Real Functionals

15

Definition 1.3.10 Let X be a Banach space, U ⊆ X an open set and assume that
I : U → R is differentiable. A critical point of I is a point u ∈ U such that
I  (u) = 0.
As I  (u) is an element of the dual space X  , this means of course I  (u)v = 0 for all
v ∈ X.
If I  (u) = 0 and I (u) = c, we say that u is a critical point for I at level c. If for
some c ∈ R the set I −1 (c) ⊂ X contains at least a critical point, we say that c is a
critical level for I .
The equation I  (u) = 0 is called the Euler, or Euler–Lagrange equation associated to the functional I .

1.3.1 Examples in Abstract Spaces
We begin with some abstract examples of differentiable functionals.
Example 1.3.11 The simplest example of differentiable functional is given by
a constant functional, which is everywhere differentiable with differential equal
to zero. Another trivial example is given by a linear and continuous functional
A : X → R, namely A ∈ X  . The functional A is everywhere differentiable and the
differential at any point is A itself, that is
A (u) = A
for every u ∈ X.
Example 1.3.12 A more interesting case is the following. Let X be a Banach space
and let
a:X×X→R
be a continuous bilinear form. Denote by J : X → R the associated quadratic form
given by
J (u) = a(u, u).
Then J is differentiable on X and
J  (u)v = a(u, v) + a(v, u),

or J  (u) = a(u, ·) + a(·, u)

for all u, v ∈ X. Indeed by linearity
J (u + v) − J (u) = a(u + v, u + v) − a(u, u) = a(u, v) + a(v, u) + a(v, v);
by continuity, a(v, v) = o( v ), and the claim follows.
Of course, if a is also symmetric, then
J  (u)v = 2a(u, v).

16

1

Introduction and Basic Results

Example 1.3.13 A particular case occurs with a continuous bilinear form
a:H ×H →R
where H is a Hilbert space. Setting again J (u) = a(u, u), the results described in
the previous example apply. In particular, if a is symmetric, then J  (u) = 2a(u, ·).
Taking as a the scalar product, we have that
J (u) = (u|u) = u 2 .
We obtain that on a Hilbert space, the square of the norm is everywhere differentiable and
J  (u) = 2(u|·).
Since H is Hilbert, we can identify continuous linear functionals on H with elements of the space H itself, as we have already recalled. In this case therefore we
can compute the gradient of J , which takes the particularly simple form
∇J (u) = 2u.
Example 1.3.14 Still on a Hilbert space H , one can easily prove that the functional
J (u) = u is differentiable at every u = 0, with


u
u

· , or ∇J (u) =
.
J (u) =
u
u
One can also prove that J is not differentiable at zero (see e.g. [4]).
Remark 1.3.15 The question of the differentiability of u in absence of the Hilbert
structure is much more delicate and depends in general on finer properties of the
space, such as uniform convexity, reflexivity and so on. We will see some examples
of differentiable norms in Sect. 2.6.
Example 1.3.16 We will sometimes deal with “quotient” functionals constructed
in the following way: assume that I and J are two differentiable functionals on a
Banach space X and define
I (u)
Q(u) =
.
J (u)
Of course Q is defined on U = {u ∈ X | J (u) = 0}. By Proposition 1.3.6 we have
that Q is differentiable on U and

J (u)I  (u)v − I (u)J  (u)v
1  
I (u)v − Q(u)J  (u)v .
Q (u)v =
=
J (u)
J (u)2

1.3.2 Examples in Concrete Spaces
The examples collected in this section will all be used in later chapters since they
present the differentiability properties of functionals associated to elliptic equations.
We begin with a direct application of the “abstract” examples.

1.3 A Review of Differential Calculus for Real Functionals

17

Example 1.3.17 Let  ⊂ RN , N ≥ 1, be a bounded open set. We define the functionals

I : L2 () → R
as I (u) =
u(x)2 dx,



J : H01 () → R

as J (u) =

|∇u(x)|2 dx,



K : H 1 () → R as K(u) =

|∇u(x)|2 dx,


L : H 1 () → R



as L(u) =


|∇u(x)|2 dx +



u(x)2 dx.


The functionals I, J , K and L are all quadratic forms associated to symmetric continuous bilinear forms. By the discussion in Example 1.3.13 they are differentiable
at every point.
The functional I is the square of the norm in L2 () and L is the square of the
norm in H 1 (); thus


I (u)v = 2(u|v)L2 () = 2 u(x)v(x) dx and ∇I (u) = 2u.



L (u)v = 2(u|v)H 1 () = 2 ∇u(x) · ∇v(x) dx + 2 u(x)v(x) dx and


∇L(u) = 2u.



The functional J is again the square of the norm, provided one uses in H01 ()
the norm J (u)1/2 , equivalent to the one induced by H 1 () (see Theorem 1.2.8).
Accordingly,

J  (u)v = 2(u|v)H 1 () = 2 ∇u(x) · ∇v(x) dx and ∇J (u) = 2u.
0



The functional K is not the square of the norm in H 1 (); therefore

K  (u)v = 2 ∇u(x) · ∇v(x) dx,


but we cannot say that ∇K(u) = 2u.
Since H01 () and H 1 () are both embedded continuously in L2 (), quantities
that are o(|v|2 ) as v → 0 in L2 () are also o( v H 1 () ) or o( v H 1 () ) as v → 0 in
0

the respective topologies. Therefore I is also differentiable at every point of H01 ()
or of H 1 (). The expression of I  (u) of course is unchanged.
Example 1.3.18 A slightly more general situation is the following: consider functions aij ∈ L∞ () for i, j ∈ {1, . . . , N}, and define the N × N matrix A(x) =
(aij (x))ij . Take a function q ∈ L∞ () and define a map a : H 1 () × H 1 () → R
as


a(u, v) =
q(x)u(x)v(x) dx.
(A(x)∇u(x)) · ∇v(x) dx +




18

1

Introduction and Basic Results

It is easy to see that a is a continuous bilinear form and that if A(x) is a symmetric
matrix, then a is also symmetric. Hence if we define


J (u) = a(u, u) =
q(x)u2 dx,
(A(x)∇u(x)) · ∇u(x) dx +




then J is differentiable on H 1 () and




J (u)v = 2a(u, v) = 2



(A(x)∇u(x)) · ∇v(x) dx + 2


q(x)u(x)v(x) dx.


Example 1.3.19 With the same assumptions and notation as in the previous example, define Q : H 1 () \ {0} → R as


(A(x)∇u) · ∇u dx +  q(x)u2 dx
J (u)


=
.
Q(u) =  2
2
 u dx
 u dx
Then, as in Example 1.3.16, Q is differentiable on H 1 () \ {0} and there results




1

q(x)uv dx − Q(u) uv dx .
Q (u)v =  2
(A(x)∇u) · ∇v dx +



 u dx
We now turn to the differentiability properties of integral functionals like
u →  F (u) dx. In dealing with these functionals we will make great use of the
elementary inequality


∀q > 0 ∃Cq such that |a + b|q ≤ Cq |a|q + |b|q , ∀a, b ∈ R.
Example 1.3.20 Let  ⊂ RN , N ≥ 3, be a bounded open set (with smooth boundary). Let f : R → R be a continuous function, and assume that there exist a, b > 0
such that
∗

|f (t)| ≤ a + b|t|2 −1

(1.9)

for all t ∈ R. Recall that 2∗ = N2N
−2 is the critical exponent for the embedding of
H 1 () into Lp (). Define
 t
f (s) ds
F (t) =
0

and consider the functional J : H 1 () → R given by

J (u) =
F (u(x)) dx.


Then J is differentiable on H 1 () and

f (u(x))v(x) dx
J  (u)v =

for all u, v ∈ H 1 ().



The functional J can also be considered on H01 (), without any regularity assumption on ∂, and the same result holds.

1.3 A Review of Differential Calculus for Real Functionals

19

To check this we use a common procedure in this kind of questions: first we
prove that J is Gâteaux differentiable, and then we show that JG is continuous, so
that we can invoke Proposition 1.3.8.
From the growth assumption (1.9) one easily derives that J (u) is well defined
via the Sobolev inequalities (Theorem 1.2.1). We now check that J is Gâteaux differentiable. We have to prove that for fixed u, v ∈ H 1 (),


F (u + tv) − F (u)
dx =
f (u)v dx.
lim
t→0 
t

It is obvious that, for almost every x ∈ ,
lim

t→0

F (u(x) + tv(x)) − F (u(x))
= f (u(x))v(x).
t

By the Lagrange Theorem there exists a real number θ such that |θ | ≤ |t| and
F (u(x) + tv(x)) − F (u(x))
= f (u(x) + θ v(x))v(x)
t


∗
≤ a + b|u(x) + θ v(x)|2 −1 |v(x)|


∗
∗
≤ C |v(x)| + |u(x)|2 −1 |v(x)| + |v(x)|2 .
∗

∗

As the function |v| + |u|2 −1 |v| + |v|2 is in L1 (), by dominated convergence we
have


F (u + tv) − F (u)
dx =
lim
f (u)v dx.
t→0 
t

Since the right-hand side, as a function of v, is a continuous linear functional on
H 1 (), it is the Gâteaux differential of J .
We complete the proof by checking that the function JG : H 1 () → [H 1 ()]
is continuous. To this aim, take a sequence {uk }k in H 1 () such that uk → u in
H 1 (). Up to a subsequence, we may assume that
∗

• uk → u in L2 () as k → ∞;
• uk (x) → u(x) a.e. in  as k → ∞;
∗
• there is w ∈ L2 () such that |uk (x)| ≤ w(x) a.e. in  and for all k ∈ N.
We have, by the Hölder inequality,

 


JG (uk ) − JG (u) v ≤
|f (uk ) − f (u)||v| dx



|f (uk ) − f (u)|

≤

2∗
2∗ −1


 2∗ −1
∗
2

dx



Since limk→+∞ |f (uk (x)) − f (u(x))| = 0 a.e. in  and



2∗

|v| dx

1/2∗
.

20

1
2∗
2∗ −1

|f (uk ) − f (u)|

Introduction and Basic Results

 2∗

2∗ −1
2∗ −1 2∗ −1
≤ C 1 + |uk |
+ |u|
 ∗2∗

∗
∗
2 −1
≤ C 1 + |w|2 −1 + |u|2 −1


∗
∗
≤ C 1 + |w|2 + |u|2 ∈ L1 (),

then by dominated convergence,

2∗
lim
|f (uk ) − f (u)| 2∗ −1 dx = 0,
k→+∞ 

so that



JG (uk ) − JG (u) = sup |(JG (uk ) − JG (u))v| v ∈ H 1 (), v = 1

≤C

|f (uk ) − f (u)|

2∗
2∗ −1

 2∗ −1
∗
2

dx

→0



as k → +∞. Recall that we are working with a subsequence of the original sequence uk . Hence, what we have really proved is that for every sequence uk → u
there is a subsequence {ukj }j such that JG (ukj ) → JG (u) in [H 1 ()] ; from this it
1

is an elementary exercise to conclude that JG (uk ) → JG (u) in
 [H ()] . By Propo
sition 1.3.8 we deduce that J is differentiable and J (u)v =  f (u)v dx.
Example 1.3.21 If we drop the hypothesis that  is bounded we have to impose
stronger conditions on f . So, let  ⊆ RN , N ≥ 3, be a general open set (with smooth
boundary). Let f : R → R be a continuous function, and assume that there exist
a, b > 0 such that
∗

|f (t)| ≤ a|t| + b|t|2 −1

(1.10)

for all t ∈ R. Note that this assumption
forces f (0) = 0.
t
Define, as above, F (t) = 0 f (s) ds and consider the same functional as in the
preceding example, namely

F (u) dx.
J (u) =


Then J is differentiable on H 1 () and
J  (u)v =



f (u)v dx

for all u, v ∈ H 1 ().



As in the previous example, if we consider J on H01 (), without any regularity
assumption on ∂, then the same result holds. As before, let us first prove that J is
Gâteaux differentiable. We have, for a.e. x ∈ ,
F (u(x) + tv(x)) − F (u(x))
= f (u(x))v(x).
t→0
t
By the Lagrange Theorem, there exists a real number θ such that |θ | ≤ |t| and
lim

1.3 A Review of Differential Calculus for Real Functionals

21

F (u(x) + tv(x)) − F (u(x))
= f (u + θ v)v
t


∗
≤ C |u + θ v| + |u + θ v|2 −1 |v|


∗
∗
≤ C |u||v| + |v|2 + |u|2 −1 |v| + |v|2 ∈ L1 (),
so we apply the dominated convergence theorem and we conclude
as in the previous

example that J is Gâteaux differentiable with JG (u)v =  f (u)v dx.
Again we assume that {uk }k is a sequence in H 1 () and uk → u in H 1 ().
Passing to a subsequence, we have that
∗

• uk → u in L2 () and in L2 ();
• uk (x) → u(x) a.e. in ;
∗
• There exist w1 ∈ L2 () and w2 ∈ L2 () such that |uk (x)| ≤ wi (x) a.e. in  and
for all k ∈ N.
Let us now fix ε > 0 and take Rε > 0 such that, setting ε = {x ∈  | |x| > Rε }, we
have
∗

∗

2 −1
2 −1
|u|L2 (ε ) + |u|L
2∗ ( ) + |w1 |L2∗ ( ) + |w2 |L2 (ε ) ≤ ε.
ε

ε

Now,

 

JG (uk ) − JG (u) v ≤
|f (uk ) − f (u)||v| dx






=

|f (uk ) − f (u)||v| dx +
∩BRε

|f (uk ) − f (u)||v| dx;
ε

on ε we have

|f (uk ) − f (u)||v| dx
ε





≤C


∗
∗
|uk | + |u| + |uk |2 −1 + |u|2 −1 |v| dx

ε


≤C


|w2 ||v| dx +

ε



∗

|w1 |2 −1 |v| dx +

|u||v| dx +
ε

ε



∗

|u|2 −1 |v| dx



ε



2∗ −1
2∗ −1
≤ C v |w2 |L2 (ε ) + |u|L2 (ε ) + |w1 |L
2∗ ( ) + |u|L2∗ ( ) + ≤ C v ε.
ε

On the set  ∩ BRε we have


|f (uk ) − f (u)||v| dx ≤ C
∩BRε

ε

|f (uk ) − f (u)|

2∗
2∗ −1

 2∗ −1
∗
2

dx

v ,

∩BRε

and since from the assumption on f it readily follows that there is C > 0 such that
∗
|f (t)| ≤ C(1 + |t|2 −1 ) for all t, we then obtain as in the preceding example that

2∗
|f (uk ) − f (u)| 2∗ −1 dx → 0
∩BRε

22

1

Introduction and Basic Results

as k → ∞. Thus



JG (uk ) − JG (u) = sup (JG (uk ) − JG (u))v v ∈ H 1 (), v = 1

 2∗ −1
2∗
2∗
≤C
|f (uk ) − f (u)| 2∗ −1 dx
+ Cε = o(1) + Cε
∩BRε

as k → ∞. This means that
lim sup JG (uk ) − JG (u) ≤ Cε.
k→+∞

Since this happens for all ε > 0, so we deduce
lim sup JG (uk ) − JG (u) = 0.
k→+∞

This argument holds for a subsequence of the original sequence {uk }k ; we conclude
the as in the previous case.

1.4 Weak Solutions and Critical Points
The variational approach to semilinear elliptic equations is based on the notion of
weak solution.
For a general discussion on the importance of weakening the notion of solution
in many areas of differential equations, we refer the reader to [18]. Here, we limit
ourselves to the description of the ideas involved around this notion for the specific
equations we deal with.
It is important that the reader bears in mind this fact: to each differential equation
one can associate a notion of weak solution, or even more than one, depending on
what one is interested in. Of course, there are classes of differential equations that
share the same definition of weak solution, such as almost all the problems treated
in this book.
It is customary to start with a simple linear problem that serves as an example
and a guideline for more sophisticated cases.
Let  be a bounded open set in RN , and let q, h ∈ C().
Suppose we want to find a function u :  → R such that

−u + q(x)u = h(x) in ,
(1.11)
u=0
on ∂,
where  is the Laplace operator, defined in (1.4).
This problem is called the homogeneous Dirichlet problem. Generally speaking,
the Dirichlet problem consists in coupling a differential equation with a boundary
condition that specifies the values of the unknown function on the boundary of ;
one says that the Dirichlet condition is homogeneous if the unknown is required to
be zero on ∂. The homogeneous Dirichlet problem is the prototype of all boundary
value problems, and this is why in this book we only consider this type of boundary
conditions.

1.4 Weak Solutions and Critical Points

23

A classical solution of (1.11) is a function u ∈ C 2 () that satisfies (1.11) for
every x ∈ . We now make the following experiment: we take v ∈ C01 (), we multiply the equation in (1.11) by v and we integrate over . By the Green’s formula
(1.5) (notice that the boundary integral vanishes, since v has compact support) we
obtain that if u is a classical solution, then



∇u · ∇v dx + q(x)uv dx = h(x)v dx, ∀v ∈ C01 ().
(1.12)






Now this formula makes sense even if u is not C 2 ; for example u ∈ C 1 suffices.
On a closer inspection, one realizes that the regularity requirements on u and v
can still be weakened very much. Indeed for the integrals to be finite it is enough
∂u
∂v
and ∂x
, for every i. Having observed this, it is
that u, v ∈ L2 () and so do ∂x
i
i
even no longer necessary for q and h to be continuous: one can merely require that
q ∈ L∞ (), and h ∈ L2 ().
This motivates the following fundamental definition.
Definition 1.4.1 Let q ∈ L∞ () and h ∈ L2 (). A weak solution of problem (1.11)
is a function u ∈ H01 () such that



∇u · ∇v dx + q(x)uv dx = h(x)v dx, ∀v ∈ H01 ().
(1.13)






A few comments are in order. If one wants to extend the notion of solution, one
would like, to say the least, that classical solutions be weak solutions as well. This
is indeed true in the present case, as we now show. Let u be a classical solution of
(1.11). In particular, u ∈ C 2 (), so that u ∈ H 1 (). Since u is continuous on  and
u = 0 on ∂, then u ∈ H01 (), see the definition of H01 () in Sect. 1.2.1. Hence u
is in the right function space. Next, we know that (1.12) holds, and since C01 () is
dense in H01 (), for any fixed v ∈ H01 () we can take a sequence {vn }n ⊂ C01 ()
such that vn → v in the H01 topology. Letting n → ∞, we obtain that (1.12) holds
for every v ∈ H01 (). This is exactly (1.13), and hence u is a weak solution.
Notice that, apparently, in the above definition there is no specification of boundary conditions. Actually the homogeneous boundary condition is hidden, or better, englobed in the functional setting of the problem: all functions in H01 () satisfy u = 0 on ∂, in an appropriate sense (see again the definition of H01 () in
Sect. 1.2.1). This is one of the useful features of the notion of weak solution.
Now suppose we have found a weak solution u of (1.11), so that u satisfies the
integral relation (1.13). Is there any chance that u be a classical solution? Of course
if we are interested in classical solutions we suppose from the beginning that q and
h are continuous. A very important aspect in the definition of weak solution is the
fact that the answer to this question only depends on the regularity of u. Indeed it
is easy to prove that if u is a weak solution and u is in C 2 (), then u is a classical
solution. To see this notice first of all that u ∈ H01 () ∩ C 2 () implies u = 0 on ∂
in the classical sense. Next, one can take v ∈ C01 () in (1.13), obtaining that (1.12)

24

1

Introduction and Basic Results

holds. Then one can use the Green’s formula as above, but in the opposite direction,
to show that



− u + q(x)u − h(x) v dx = 0, ∀v ∈ C01 ().
(1.14)


Since C01 () is dense in L2 (), we see that


−u + q(x)u = h(x)

a.e. in ,

u=0

on ∂,

(1.15)

but since u is C 2 , the equation holds at every point. Hence u is a classical solution.
The preceding discussion highlights a further fundamental feature of the weak
solution approach: existence is completely separated from regularity. One can concentrate on existence results (and this is what this book is all about) and only later
be concerned about regularity of weak solutions. When everything works one finds
a classical solution of the problem. The trick is that regularity theory for weak solutions of partial differential equations is a quite hard and technical issue. However
there are now precise results that one can invoke in the majority of situations. We
do not discuss these items here, and we refer the reader to [11, 18, 22, 24, 45] for
precise regularity results.
We now close the circle by showing how weak solutions are related to critical
points of functionals, still for problem (1.11).
Define a functional J : H01 () → R by



1
1
J (u) =
|∇u|2 dx +
q(x)u2 dx − h(x)u dx.
(1.16)
2 
2 

This functional is often called the energy functional associated to problem (1.11).
The term is borrowed from the applications, where J is likely to represent an energy
of some sort. Notice that the first two terms are quadratic in u, while the third is
linear. By the results of Sect. 1.3, and in particular of Example 1.3.17, the functional
J is differentiable on H01 (), and




J (u)v = ∇u · ∇v dx + q(x)uv dx − h(x)v dx, ∀v ∈ H01 (). (1.17)






Now the connection between weak solutions and critical points is evident: comparing Definition 1.4.1 and (1.17), one sees that u is a weak solution of problem (1.11)
if and only if u is a critical point of the functional J .
Thus we have here a concrete example of the Euler–Lagrange equation associated
to the functional J , see Definition 1.3.10.
The correspondence between weak solutions and critical point of functionals outlined above is valid of course for more general nonlinear problems. The procedure
to define the notion of weak solution for certain nonlinear equations follows exactly
the same steps as in the linear case: one “tests” the equation with a smooth function
vanishing on the boundary of , integrates by parts by means of the Green’s formula, reduces the regularity requirement on the functions, and tries to interpret the
integral equality as the vanishing of the differential of a suitable functional.

1.5 Convex Functionals

25

We now give a fundamental example by means of the results obtained in Sect. 1.3.
Let  ⊂ RN , with N ≥ 3, be open and bounded. Assume that q ∈ L∞ () and
let f : R → R be a continuous function that satisfies the growth condition (1.9):
∗

|f (t)| ≤ a + b|t|2 −1
for all t ∈ R and for some constants a, b. Recall that 2∗ = N2N
−2 . Consider the problem

−u + q(x)u = f (u) in ,
(1.18)
u=0
on ∂.
The procedure described for the linear case leads to the following definition.
Definition 1.4.2 A weak solution of problem (1.18) is a function u ∈ H01 () such
that



∇u · ∇v dx + q(x)uv dx = f (u)v dx, ∀v ∈ H01 ().
(1.19)






Now we construct the energy functional associated to this problem. Let
 t
F (t) =
f (s) ds
0

and consider the functional J : H01 () → R defined by
J (u) =




1
1
|∇u|2 dx +
q(x)u2 dx − F (u) dx.
2 
2 


By the results of Sect. 1.3, J is differentiable on H01 (), and




J (u)v = ∇u · ∇v dx + q(x)uv dx − f (u)v dx,






∀v ∈ H01 ().

Therefore weak solutions of (1.18) correspond to critical points of J .
Remark 1.4.3 The growth condition (1.9) is essential to have that the energy func∗
tional is well-defined on H01 (). Indeed, if f (t) grows faster that |t|2 −1 , then F (t)
∗
grows faster than |t|2 ; since H01 () is not embedded in Lp () when p > 2∗ , the
integral of F (u) in the functional J might diverge for some u ∈ H01 ().

1.5 Convex Functionals
Let us begin with a heuristic “principle”. The typical functionals I (u) whose critical
points give rise to weak solutions of differential equations are integral functionals
that normally contain a term involving the gradient of u, in many cases the integral of some power of |∇u|. In a physical or mechanical context this term often
represents an energy of some sort. This type of term is bounded below because it is

26

1

Introduction and Basic Results

nonnegative, but in general it is not bounded above (energies can be made arbitrarily
high). Thus if a functional contains such a term, it may be perhaps minimized, but
probably not maximized.
This is why the most “natural” critical points of differentiable integral functionals
are often its global minima.
Remark 1.5.1 A (local) point of minimum of a differentiable functional is of course
a critical point. Indeed, if I : X → R is a differentiable functional on a Banach space
X and
I (u) = min I (v),
v∈X

then, for every fixed v ∈ X, we can consider the differentiable function φ : R → R
defined by φ(t) = I (u + tv). The function φ has a (local) minimum at t = 0 and is
differentiable. Therefore
0 = φ  (0) = I  (u)v.
This holds for every v ∈ X, and hence u is a critical point for I .
In the search for global minima a relevant concept is convexity.
Definition 1.5.2 A functional I : X → R on a vector space X is called convex if for
every u, v ∈ X and every real t ∈ [0, 1] there results
I (tu + (1 − t)v) ≤ tI (u) + (1 − t)I (v).
The functional is called strictly convex if for every u, v ∈ X, u = v, and every real
t ∈ (0, 1) there results
I (tu + (1 − t)v) < tI (u) + (1 − t)I (v).
Finally, we say that I is (strictly) concave if −I is (strictly) convex.
The main result for our purposes is the following classical theorem (see [11]).
Theorem 1.5.3 Let I : X → R be a continuous convex functional on a Banach
space X. Then I is weakly lower semicontinuous. In particular, for every sequence
{uk }k∈N ⊂ X converging weakly to u ∈ X, we have
I (u) ≤ lim inf I (uk ).
k→∞

Remark 1.5.4 On a Banach space X the norm is an example of a continuous convex
functional. Therefore the preceding result can be applied, obtaining the following
fact that we will use repeatedly in the sequel: if uk
u in X, then
u ≤ lim inf uk .
k→∞

1.5 Convex Functionals

27

A continuous convex functional need not have a minimum, even if it is bounded
below, and even in finite dimension: think for example of the function ex . The problem is that minimizing sequences may “escape to infinity”. The missing ingredient
is given by the following notion.
Definition 1.5.5 A functional I : X → R on a Banach space X is called coercive if,
for every sequence {uk }k∈N ⊂ X,
uk → +∞

implies I (uk ) → +∞.

A functional I is called anticoercive if −I is coercive.
The following result is of fundamental importance.
Theorem 1.5.6 Let X be a reflexive Banach space and let I : X → R be a continuous, convex and coercive functional. Then I has a global minimum point.
Proof Define m = infu∈X I (u). Let {uk }k∈N ⊂ X be a minimizing sequence. Coercivity implies that {uk }k∈N is bounded. Since X is reflexive, by the Banach–Alaoglu
Theorem we can extract from {uk }k∈N a subsequence, still denoted uk , such that uk
converges weakly to some u ∈ X. By Theorem 1.5.3 we then obtain
I (u) ≤ lim inf I (uk ) = m.
k→∞

Therefore I (u) = m and u is a global minimum for I .



Remark 1.5.7 In the previous statement the convexity assumption is only used to
deduce weak lower semicontinuity from continuity (via Theorem 1.5.3). A more
general statement is thus the following version of the Weierstrass Theorem: let X
be a reflexive Banach space and let I : X → R be weakly lower semicontinuous
and coercive. Then I has a global minimum point. This is the starting point of the
so-called direct methods of the Calculus of Variations.
Convexity is also strongly related to uniqueness properties. We present two results in this direction.
Theorem 1.5.8 Let I : X → R be strictly convex. Then I has at most one minimum
point in X.
Proof Assume that I has two different global minima u1 and u2 in X. By strict
convexity,


1
u1 + u2
1
1
1
min I (u) ≤ I
< I (u1 ) + I (u2 ) = min I (u) + min I (u)
u∈X
2
2
2
2 u∈X
2 u∈X
= min I (u),
u∈X

a contradiction.



28

1

Introduction and Basic Results

Theorem 1.5.9 Let I : X → R be strictly convex and differentiable. Then I has at
most one critical point in X.
Proof The claim is obvious if X = R, that is, if I is a differentiable real function
of one real variable. Indeed, in this case strict convexity implies that I  is strictly
increasing, and hence there is at most one t ∈ R such that I  (t) = 0. In the general
case, assume that u is a critical point for I , fix any v ∈ X and define γ : R → R
by γ (t) = I (u + tv). The function γ is differentiable, and it is easy to see that it is
strictly convex and that γ  (0) = 0. Therefore γ  (t) = 0 for all t = 0, which means
I  (u + tv)v = 0, and hence I  (u + tv) = 0 for all t = 0. As this holds for every
v ∈ X, the result follows.

We conclude with a useful criterion to detect convexity.
Proposition 1.5.10 Let X be a Banach space and let I : X → R be a differentiable
functional. Assume that for all u, v ∈ X,
(I  (u) − I  (v))(u − v) ≥ 0.
Then I is convex. If the strict inequality holds when u = v, then I is strictly convex.
Proof Fix u, v ∈ X and define a function ψ : R → R as
ψ(t) = I (u + t (v − u)).
The function ψ is differentiable and ψ  (t) = I  (u + t (v − u))(v − u). Fix now s < t.
We have


ψ  (t) − ψ  (s) = I  (u + t (v − u)) − I  (u + s(v − u)) (v − u)
=


1  
I (u + t (v − u)) − I  (u + s(v − u))
t −s


× (u + t (v − u)) − (u + s(v − u)) ≥ 0.

Hence ψ  is a nondecreasing function, so ψ is convex, and in particular
ψ(t) = ψ(1t + 0(1 − t)) ≤ tψ(1) + (1 − t)ψ(0),
which means I (tv + (1 − t)u) ≤ tI (v) + (1 − t)I (u).
If in the assumption the strict inequality holds, then we get that ψ  is strictly
increasing, and hence ψ is strictly convex, implying the same for I .


1.6 A Few Examples
Let us now apply the abstract results of the previous sections to some concrete differential problems.

1.6 A Few Examples

29

Theorem 1.6.1 Let  ⊂ RN be a bounded open set and let A(x) be a symmetric
N ×N matrix-valued function with entries in L∞ (). Assume that there exists λ > 0
such that (A(x)y)y ≥ λ|y|2 for a.e. x ∈  and for all y ∈ RN . Let q ∈ L∞ ()
satisfy q(x) ≥ 0 a.e. in . Then for every h ∈ L2 () the problem



− div A(x)∇u + q(x)u = h(x) in ,
(1.20)
u=0
on ∂
has a unique (weak) solution.
Remark 1.6.2 The condition (A(x)y)y ≥ λ|y|2 for a.e. x ∈  and for all y ∈ RN
states that the matrix A(x) is (uniformly) positive definite on . This, by Definition 1.2.3, says that the differential operator − div(A(x)∇u) is uniformly elliptic
on .
Proof Consider the functional J : H01 () → R defined as



1
1
J (u) =
(A(x)∇u) · ∇u dx +
q(x)u2 dx −
hu dx.
2 
2 

We have seen that J is differentiable on H01 () and that



J  (u)v = (A(x)∇u) · ∇v dx +
q(x)uv dx −
hv dx.






Thus a critical point of J is a weak solution of problem (1.20).
Since for u = v,



(J  (u) − J  (v)) (u − v) =
A(x)(∇u − ∇v) · (∇u − ∇v) dx


+
q(x)(u − v)2 dx


≥ λ |∇(u − v)|2 dx > 0,


J is strictly convex in view of Proposition 1.5.10.
As  is bounded, thanks to the Poincaré and Sobolev inequalities, we have

λ
J (u) ≥
|∇u|2 dx − |h|2 |u|2 ≥ C u 2 − C u ,
2 
and J is also coercive. By Theorems 1.5.6 and 1.5.8, J has a global minimum which
is its only critical point. Therefore Problem (1.20) has a unique solution.

In this result the sign condition on q is not necessary to obtain the desired properties. Indeed, the same conclusion holds provided q is “not too negative”, for instance
in the following sense.
∗
Let S be the best Sobolev constant for the embedding of H01 () into L2 (),
that is, the largest positive constant S such that
S|u|22∗ ≤ u 2

for every u ∈ H01 ().

(1.21)

30

1

Introduction and Basic Results

Assume that q ∈ LN/2 () satisfies
|q|N/2 < λS.
Then the conclusion of the previous theorem holds. Indeed we note that by the
Hölder inequality, for every w ∈ H01 (),

 2 
 N−2

N
N
2N
N
q(x)w 2 dx ≤
|q| 2 dx
|w| N−2 dx






1
= |q|N/2 |w|22∗ ≤ |q|N/2

w 2.
S
Then we have, with the same argument as above,


1


(J (u) − J (v)) (u − v) ≥ λ − |q|N/2 u − v 2 > 0,
S
which proves (strict) convexity, and

1
λ
|q|N/2 u 2 − |h|2 |u|2
|∇u|2 dx −
J (u) ≥
2 
2S


1
1
λ − |q|N/2 u 2 − C u ,
≥
2
S
which proves coercivity. Since under the weakened condition on q the functional
J is still differentiable, as it is easy to check, we again obtain the existence of a
solution to Problem (1.20).
A particular but significant case of the preceding theorem is worth to be stated
separately.
Corollary 1.6.3 Let  ⊂ RN be a bounded open set. For every h ∈ L2 () the
problem

−u = h(x) in ,
(1.22)
u=0
on ∂.
has a unique (weak) solution.
Similarly, with the same arguments of Theorem 1.6.1, one can prove a version
for a problem on RN .
Corollary 1.6.4 For every h ∈ L2 (RN ) the problem

−u + u = h(x) in RN ,
u ∈ H 1 (RN )

(1.23)

has a unique (weak) solution.
Remark 1.6.5 The solutions mentioned in these two corollaries are of course obtained as the unique global minima of the functionals J : H01 () → R defined by



1
1
2
2
|∇u| dx − hu dx = u − hu dx
J (u) =
2 
2



1.7 Some Spectral Properties of Elliptic Operators

31

and I : H 1 (RN ) → R defined by




1
1
1
I (u) =
|∇u|2 dx +
u2 dx −
hu dx = u 2 −
hu dx.
2 RN
2 RN
2
RN
RN
This procedure is called the Dirichlet principle.
We now give a first example of a nonlinear problem which can easily solved with
the same techniques.
Theorem 1.6.6 Let  ⊂ RN , with N ≥ 3, be open and bounded. Assume that
q ∈ L∞ () satisfies q ≥ 0 a.e. in , and let f : R → R be a continuous function
such that (1.9) holds. If
f (t)t ≤ 0 and (f (t) − f (s))(t − s) ≤ 0
then, for every h ∈ L2 (), the problem

−u + q(x)u = f (u) + h(x)
u=0

∀t, s ∈ R,

in ,
on ∂

(1.24)

(1.25)

has exactly one solution.
t
Proof Let F (t) = 0 f (s) ds and define a differentiable functional J : H01 () → R
by




1
1
J (u) =
|∇u|2 dx +
q(x)u2 dx −
F (u) dx −
hu dx.
2 
2 


Critical points of J are weak solutions of (1.25). We have, for all u, v ∈ H01 (),



2
(J (u) − J (v))(u − v) = u − v − (f (u) − f (v)(u − v) dx ≥ u − v 2 ,


so that J is strictly convex. Furthermore it is easy to see that F (t) ≤ 0 for all t, and
hence

1
1
2
F (u) dx − |h|2 |u|2 ≥ u 2 − C u ,
J (u) ≥ u −
2
2

by the Poincaré and Sobolev inequalities. This shows that J is also coercive. As
the functional is coercive, convex and continuous, it has a global minimum point,
which is a critical point. Since J is strictly convex, this is the only critical point, by
Proposition 1.5.9.

As obvious examples of functions f satisfying the assumption of the previous
theorem, one can take any f (t) = −|t|p−2 t with p ∈ (1, 2∗ ], or f (t) = − arctan t.

1.7 Some Spectral Properties of Elliptic Operators
We now recall some well-known spectral properties of elliptic operators; for the sake
of simplicity and in view of later applications we state the results for an operator
of the form − + q(x), the prototype of all (uniformly) elliptic operators. The

32

1

Introduction and Basic Results

results can be extended with minor modifications to cases where e.g. the Laplacian
is replaced by the operator − div(A(x)∇), under suitable natural assumptions on the
matrix A.
Let  be a bounded open subset of RN , and let q ∈ L∞ ().
Definition 1.7.1 We say that λ ∈ R is an eigenvalue of the operator − + q(x)
under Dirichlet boundary conditions if there exists ϕ ∈ H01 () \ {0} such that

−ϕ + q(x)ϕ = λϕ in ,
(1.26)
ϕ=0
on ∂.
The function ϕ is called an eigenfunction associated to λ.
Remark 1.7.2 Problem (1.26) is to be interpreted in the weak sense, namely ϕ solves
it provided



∇ϕ · ∇v dx + q(x)ϕv dx = λ ϕv dx for all v ∈ H01 ().






If q ≡ 0, the corresponding numbers λ are simply called the eigenvalues of the
Laplacian (often even omitting “under Dirichlet boundary conditions”).
The next theorem collects the basic properties of eigenvalues and eigenfunctions;
for its proof, see [18]. Since we present the theory for the Dirichlet problem only,
when we talk about eigenvalues we always mean that Dirichlet boundary conditions
are imposed.
Theorem 1.7.3 Let  ⊂ RN be bounded and open and let q ∈ L∞ (). Then there
exist sequences {λk }k ⊂ R and {ϕk }k ⊂ H01 () such that
1. each λk is an eigenvalue of − + q(x) and each ϕk is an eigenfunction corresponding to λk ;
2. λk → +∞ as k → ∞;
3. {ϕk }k is an orthonormal basis of L2 ();
4. for every k, ϕk ∈ L∞ () and ϕk (x) = 0 a.e. in .
Remark 1.7.4 It is customary to list the eigenvalues in an infinite increasing sequence λ1 ≤ λ2 ≤ · · ·; thus eigenvalues are repeated according to their (finite) multiplicity. Two eigenfunctions ϕi and ϕj are always different for i = j (they are orthogonal in L2 ), even if they correspond to the same eigenvalue.
Notation For a fixed operator on a fixed domain, eigenvalues are denoted by λk .
If one wants to stress the dependence of λk on the operator or on the domain one
writes λk (− + q) or λk ().
Remark 1.7.5 When λ1 (− + q) > 0 (this happens certainly if q(x) ≥ 0 a.e. in ,
by the characterization of λ1 in Theorem 1.7.6 below), it is easy to see that the
quantity


(u|v) = ∇u · ∇v dx + q(x)uv dx




1.7 Some Spectral Properties of Elliptic Operators

33

defines a scalar product on H01 () that induces a norm · equivalent to the usual
one. One checks immediately that the set { √ϕλk }k is an orthonormal basis of H01 ()
k
with respect to the scalar product defined above.
For future reference we notice that we can write
u=

∞


αk ϕk

in L2 ()

and |u|22 =

k=1

∞


αk2 ,

k=1



with αk =  uϕk dx, or
u=

∞


ϕk
βk √
λk
k=1

in H01 ()

and

u 2=

∞


βk2 ,

k=1

with βk = (u| √ϕλk ). The numbers αk and βk are the Fourier coefficients of u in
k
√
L2 () and in H01 () respectively. Of course, βk = λk αk .
Eigenvalues and eigenfunctions play a very relevant role in nonlinear elliptic
problems. For this reason we add some more information.
The most “important” eigenvalue is the smallest, λ1 , also called the first eigenvalue or the principal eigenvalue. It enjoys a number of special features, some of
which we list in the next result.
Theorem 1.7.6 (Variational characterization of the first eigenvalue) Let  be
an open and bounded subset of RN and let q ∈ L∞ (). Define a functional
Q : H01 () \ {0} →  as


2
+  q(x)u2 dx
 |∇u| dx

.
Q(u) =
2
 u dx
This functional is called the Rayleigh quotient. Then
1. minu∈H 1 ()\{0} Q(u) = λ1 ;
0
2. Q(u) = λ1 if and only if u is a (weak) solution of

−u + q(x)u = λ1 u in ,
u=0
on ∂;

(1.27)

3. every non identically zero solution of (1.27) has constant sign in  (in particular,
is a.e. different from zero in );
4. the set of solutions of (1.27) has dimension one; one says that λ1 is simple.
The fact that the first eigenvalue is simple is normally expressed by writing the
sequence of eigenvalues as λ1 < λ2 ≤ λ3 ≤ · · ·, with the strict inequality between
the first two terms. Since the eigenfunctions associated to λ1 are all of the form

34

1

Introduction and Basic Results

θ ϕ1 , for θ ∈ R and for some ϕ1 ∈ H01 (), it is customary to say that ϕ1 is the first
eigenfunction, in the sense that there exists a unique ϕ1 ∈ H01 () such that
⎧
−ϕ1 + q(x)ϕ1 = λ1 ϕ1 in ,
⎪
⎪
⎨
on ∂,
ϕ1 = 0
(1.28)
>
0
in ,
ϕ
⎪
1
⎪
⎩
normalized.
ϕ1
The normalization can be expressed by ϕ1 = 1, or |ϕ1 |2 = 1 or by other similar
statements, depending on the convenience of the moment.
Remark 1.7.7 All eigenfunctions but ϕ1 change sign. Indeed, since they form an
orthonormal basis of L2 (), they satisfy in particular  ϕ1 ϕk dx = 0 for k = 1. As
ϕ1 is positive, ϕk must change sign.
The role of eigenvalues is of fundamental importance for the solvability of linear
problems. We give the main result, that can be seen as a direct application of the
Fredholm alternative in Functional Analysis (see [11, 18]).
Theorem 1.7.8 Let  be a bounded open subset of RN . Assume that q ∈ L∞ ()
and that h ∈ L2 (). Consider the problem

−u + q(x)u = λu + h in ,
(1.29)
u=0
on ∂.
Then
1. Problem (1.29) has a unique (weak) solution for every h ∈ L2 () if and only if
λ is not an eigenvalue of − + q(x).
2. If λ is an eigenvalue, then problem (1.29) has a solution if and only if h is orthogonal in L2 () to ker(− + q(x) − λ).
In this case, the general solution of (1.29) is of the form u = u0 + ϕ, where u0 is a
fixed solution of (1.29) and ϕ is any function in ker(− + q(x) − λ).
As an application of the spectral properties discussed so far, we state a very
useful property that allows one to prove easily that solutions of certain equations are
nonnegative. This is quite important in many problems where by physical reasons,
for example, one is only interested in positive solutions.
We are talking about a version of the maximum principle, a fundamental tool in
the study of differential equations. For a complete discussion of this principle, we
refer the reader to [18] or [41].
Proposition 1.7.9 Let  ⊂ RN be open and bounded, and let q ∈ L∞ (). Assume
that u ∈ H01 () satisfies
−u + q(x)u ≥ 0 in 

1.8 Exercises

35

in the weak sense, that is,


∇u · ∇ϕ dx + q(x)uϕ dx ≥ 0 ∀ϕ ∈ H01 (), ϕ(x) ≥ 0 a.e. in .(1.30)




If λ1 (− + q) > 0, then u(x) ≥ 0 almost everywhere in .
Example 1.7.10 A typical use of the preceding proposition goes as follows. Suppose
that the function f :  × R → R is continuous and satisfies f (x, t) ≥ 0 for t ≥ 0
and f (x, 0) = 0 (for every x ∈ ). We are interested in nonnegative solutions of

−u + q(x)u = f (x, u) in ,
(1.31)
u=0
on ∂.
We define


g(x, t) =

f (x, t)
0

if t ≥ 0,
if t < 0.

Of course g is continuous. Then we solve (if possible) Problem (1.31) with f replaced by g. We obtain in this way a function u ∈ H01 () that satisfies
−u + q(x)u = g(x, u) ≥ 0
at least in the weak sense. If λ1 (− + q) > 0, then by Proposition 1.7.9 we obtain
that u(x) ≥ 0 a.e. in . But then, for almost every x in , g(x, u(x)) = f (x, u(x)),
so that actually u (is nonnegative) and solves (1.31).
Remark 1.7.11 Under regularity conditions, it is possible to prove that nonnegative
solutions are actually everywhere positive in . This is the content of the strong
maximum principle, which is beyond the aims of this book. We refer the interested
reader to [18, 41].

1.8 Exercises
1. Let  ⊂ RN be open and bounded. Consider the problem

−u = 1 in ,
u=0
on ∂.

(1.32)

(a) Define the notion of weak solution for this problem, and find a functional
on H01 () whose critical points correspond to weak solutions of (1.32).
(b) Show that (1.32) has exactly one solution.
(c) Find this solution when  is a ball of radius R centered at zero. (Hint: write
the equation in polar coordinates and look for a radial solution.)
2. Let  ⊂ RN , with N ≥ 3 be open and bounded. Take q ∈ L∞ () and let A(x)
be an N × N matrix with continuous entries (on ).
For p ∈ (2, 2∗ ], consider the problem

− div(A(x)∇u) + q(x)u = |u|p−2 u in ,
(1.33)
u=0
on ∂.

36

1

Introduction and Basic Results

Define the notion of weak solution for this problem, and find a functional on
H01 () whose critical points correspond to weak solutions of (1.33).
3. Let f : R → R be a continuous function satisfying (1.10) and (1.24). Assume
that a ∈ L∞ (RN ) is such that
a(x) ≥ c > 0
for a.e. x ∈ Rn . Prove that for every h ∈ L2 (RN ), the problem

−u + u = a(x)f (u) + h(x),
u ∈ H 1 (RN )
has exactly one solution.
4. Let  be an open subset of RN , N ≥ 3, and take a function q ∈ LN/2 (). Prove
that the function a : H01 () × H01 () → R defined by

a(u, v) =
quv dx


is bilinear and continuous. Deduce that the functional J : H01 () → R defined
by

J (u) =
q u2 dx


is differentiable and compute J  .
5. (Best constant in the Poincaré inequality.) Let  ⊂ RN be open and bounded.
Prove that


1
u2 dx ≤
|∇u|2 dx for all u ∈ H01 ()
λ1 

and the constant 1/λ1 is the best (i.e., smallest) possible.
6. (Dependence of λ1 on the domain.) For every  ⊂ RN open and bounded, denote by λ1 () the first eigenvalue of the Laplacian on H01 (). Prove that λ1 ()
is strictly decreasing with respect to inclusion, in the sense that
 ⊂ 

implies λ1 () > λ1 ( ).

7. (Dependence of λ1 on q.) Let  be open and bounded. Prove that
(a) λ1 (− + q(x)) is a nondecreasing function of q, in the sense that
p, q ∈ L∞ () and p(x) ≤ q(x) a.e.

imply λ1 (− + p) ≤ λ1 (− + q);

(b) λ1 is a continuous function of q, in the sense that
|λ1 (− + q) − λ1 (− + p)| ≤ q − p L∞ () .
8. Let  be open and bounded. For h ∈ L2 () and λ ∈ R, define I : H01 () → R
by



λ
1
2
2
|∇u| dx −
u dx − hu dx.
I (u) =
2 
2 

Prove that I is coercive on H01 () if and only if λ < λ1 .

1.9 Bibliographical Notes

37

9. More generally, assume that  and h are in the previous exercise, let q ∈
L∞ (), and define J : H01 () → R by



1
1
J (u) =
|∇u|2 dx +
q(x)u2 dx − hu dx.
2 
2 

(a) Prove that if λ1 (− + q(x)) > 0, then the expression


(u, v) = ∇u∇v dx + q(x)uv dx




defines on H01 () a scalar product that induces a norm equivalent to the
standard one.
(b) Prove that J is coercive on H01 () if and only if λ1 (− + q(x)) > 0.
(c) Deduce the result of the preceding exercise from this.
10. Prove Proposition 1.7.9. (Hint: test (1.30) with u− and use the variational characterization of λ1 .)

1.9 Bibliographical Notes
• Section 1.1: A very gentle introduction to the Calculus of Variations is the book
by Hildebrandt and Tromba [25]. For a history of the early Calculus of Variations,
see Goldstine [23].
• Section 1.2: Proofs, details, and general theory can be found in almost any
book in Functional Analysis. A good reference is Brezis [11], which is PDEoriented. Topics more strictly related to differential equations can also be found
in Evans [18].
• Section 1.3: The reader who wishes to see a more systematic treatment of differential calculus in normed space is referred to Ambrosetti and Prodi [4].
• Section 1.4: For a more complete discussion on weak solutions, and particularly
for the extension of the definitions in this section to nonhomogeneous Dirichlet
problems and Neumann problems, see Chap. IX of [11].
• Section 1.5: The development of the results and techniques outlined in this section, namely minimization of functionals under coercivity, convexity or semicontinuity properties is the Calculus of Variations, and particularly the so-called
direct methods in the Calculus of Variations. This is a very wide topic that has
reached a high degree of complexity, matched by outstanding success in solving
huge classes of problems taken from everywhere in science. The readers interested in these methods can consult Giusti [21], especially the first chapter.
• Section 1.7: The missing proofs in this section can be found in [11, 18].

Chapter 2

Minimization Techniques: Compact Problems

Throughout this chapter we show how techniques based on minimization arguments
can be used to establish existence results for various types of problems.
Our aim is not to describe the most general results, but to give a series of examples, and to show how simple techniques can be refined to treat more complex
cases.

2.1 Coercive Problems
We begin with the following problem, that will provide our guideline through the
whole chapter. We want to find a (weak) solution to

−u + q(x)u = f (u) + h(x) in ,
(2.1)
u=0
on ∂.
In this section, the general framework is specified by the assumptions
(h1 )  ⊂ RN is bounded and open, q ∈ L∞ () and q(x) ≥ 0 a.e. in .
(h2 ) h ∈ L2 ().
We equip H01 () with the scalar product


(u|v) =
∇u · ∇v dx +
q(x)uv dx,


(2.2)



and we denote by · the induced norm, equivalent to the standard one.
Remark 2.1.1 In assumption (h1 ), the requirement q(x) ≥ 0 a.e. is used only to
obtain λ1 (− + q(x)) > 0, which guarantees that (2.2) is indeed a scalar product
and that the induced norm is equivalent to the standard norm of H01 (), see Remark 1.7.5 and Exercise 9 in Chap. 1. Therefore in all the results of this chapter, and
similarly in all the subsequent chapters, the assumption q ≥ 0 could be replaced be
the “abstract” condition
λ1 (− + q(x)) > 0,
M. Badiale, E. Serra, Semilinear Elliptic Equations for Beginners, Universitext,
DOI 10.1007/978-0-85729-227-8_2, © Springer-Verlag London Limited 2011

(2.3)
39

40

2

Minimization Techniques: Compact Problems

and everything would work perfectly well with no changes in the proofs. The point
is, precisely, that (2.3) is abstract, and nobody knows for which general q’s it is satisfied. We prefer, in this book, to assume an explicit sign condition on q, rather than
an indirect one on λ1 . The reader should however keep in mind this clarification.
We begin by assuming the following hypothesis on the nonlinearity f .
(h3 ) f : R → R is continuous and bounded.
t
Setting F (t) = 0 f (s) ds, the computations carried out in Example 1.3.20 show
that the functional I : H01 () → R defined by




1
1
I (u) =
|∇u|2 dx +
q(x)u2 dx − F (u) dx − hu dx
2 
2 




1
= u 2 − F (u) dx − hu dx
2


is differentiable on H01 (). Its critical points are the weak solutions of (2.1).
Note that unless F is concave, which we do not assume, the functional I needs
not be convex.
Theorem 2.1.2 Under the assumptions (h1 )–(h3 ), Problem (2.1) admits at least
one solution.
Remark 2.1.3 The leading idea of the proof is that since f is bounded, the term
 F (u) dx should grow at most linearly with respect to u , as well as the last
term. If this is true, the functional I can be seen as an “at most linear” perturbation
of the quadratic term u 2 . This suggests the existence of a global minimum. Let us
see how all this really works.
Proof We break it into two steps. We make repeated use of Hölder and Sobolev
inequalities.
Step 1. The functional I is coercive. Note first that since f is bounded, then
|F (t)| ≤ M|t|
for some M > 0 and all t ∈ R. Hence


F (u) dx ≤ M
|u| dx ≤ C u ,




where the last inequality comes from the continuity of the embedding of H01 ()
into L1 (). This confirms the idea of the linear growth as in the preceding remark.
Thus


1
1
I (u) = u 2 −
F (u) dx −
hu dx ≥ u 2 − C u − |h|2 |u|2
2
2


1
≥ u 2−C u ,
2
which shows that I is coercive.

2.1 Coercive Problems

41

Step 2. The infimum of I is attained. Set
m=

inf

u∈H01 ()

I (u).

Step 1 shows that m > −∞, although one does not really need this: it will follow
automatically from the fact that it is attained.
Let {uk }k ⊂ H01 () be a minimizing sequence for I ; from Step 1 we immediately
see that {uk }k is bounded in H01 (), and therefore we can assume that there is a
subsequence, still denoted uk , such that
• uk
u in H01 ();
• uk → u in L2 ();
• uk (x) → u(x) a.e. in ;
• there exists w ∈ L2 () such that |uk (x)| ≤ w(x) a.e. in  and for all k.
Notice now that since F is continuous we have F (uk (x)) → F (u(x)) a.e. in ,
and due to the growth properties of F , we also have
|F (uk (x))| ≤ M |uk (x)| ≤ M w(x)
a.e. in  and for all k. Since  is bounded, w ∈ L1 (), and by dominated convergence we obtain F (uk ) → F (u) in L1 (); in particular,


F (uk ) dx →
F (u) dx.




We also have, of course,


huk dx →
hu dx




and

u 2 ≤ lim inf uk ,
k

by weak lower semicontinuity of the norm. Thus


1
I (u) = u 2 −
F (u) dx −
hu dx
2

 

1
2
≤ lim inf uk − lim F (uk ) dx − lim huk dx
k
k
k
2



 

1
2
uk −
= lim inf
F (uk ) dx −
h uk dx = lim inf I (uk ) = m.
k
k
2


But u ∈ H01 (), so that I (u) ≥ m, which shows that I (u) = m. Therefore u is a
global minimum for I , and hence it is a critical point, namely a solution to (2.1). 
Remark 2.1.4 Analyzing the preceding proof one sees that what we actually did is
to show that I is coercive and weakly lower semicontinuous on H01 (). These are
exactly the assumptions that one needs in the (generalized) Weierstrass Theorem to
deduce the existence of a global minimum, see Remark 1.5.7.
The boundedness
of f in the previous result has been used to show that the

nonlinear term  F (u) dx does not destroy the growth properties of I inherited by

42

2

Minimization Techniques: Compact Problems

the term u 2 . This occurred because, as we have seen, the nonlinear term grows at
most linearly. Now this is not really necessary: it is enough that this term grows less
than quadratically. Let us see what kind of assumptions we can use in this sense in
the next two results.
We begin by replacing the boundedness condition (h3 ) by the growth assumption
(h4 ) f : R → R is continuous and there exist σ ∈ (0, 1) and a, b > 0 such that
|f (t)| ≤ a + b|t|σ

∀t ∈ R.

Thus f is no longer bounded, but is allowed to grow sublinearly (σ < 1). It follows
that F grows at most subquadratically, in the sense that for some a1 , b1 > 0,
|F (t)| ≤ a1 + b1 |t|σ +1

∀t ∈ R,

(2.4)

with σ + 1 < 2.
Theorem 2.1.5 Under the assumptions (h1 ), (h2 ) and (h4 ), Problem (2.1) admits
at least one solution.
Proof Working as in the preceding proof we first show that I is coercive. Using the
fact that σ + 1 < 2 we have


F (u) dx ≤ a1 || + b1 |u|σ +1 dx ≤ C1 + C2 u 1+σ ,




thanks to the continuity of the embedding H01 () → Lσ +1 (). Then


1
1
I (u) = u 2 −
F (u) dx −
hu dx ≥ u 2 − C1 − C2 u σ +1 − |h|2 |u|2
2
2


1
≥ u 2 − C2 u σ +1 − C3 u − C1 ,
2
and coercivity follows.
Let now {uk }k ⊂ H01 () be a minimizing sequence for I . As in the proof of Theorem 2.1.2 above, {uk }k is bounded and therefore, up to subsequences, it converges
weakly to some u ∈ H01 () and satisfies the same properties as in the preceding
case. Then, reasoning as we did above, we obtain again


F (uk ) dx →
F (u) dx,




so that





1
I (u) ≤ lim inf
uk 2 −
F (uk ) dx −
h uk dx = lim inf I (uk ) = inf I.
k
k
2
H01 ()



The function u is a global minimum, hence a critical point of I , and we have found
a solution of (2.1).

In our quest for more general assumptions we now try to go one step further: precisely, can we allow a linear growth for f , and then a quadratic growth for F ? The

2.1 Coercive Problems

43

answer is in the affirmative, provided we supply a quantitative control of the linear
growth. This control is formulated in terms of the first eigenvalue λ1 = λ1 (− + q)
in the following assumption.
(h5 ) f : R → R is continuous and there exist a > 0 and b ∈ (0, λ1 ) such that
|f (t)| ≤ a + b|t|

∀t ∈ R.

Integrating, it follows immediately that
b
|F (t)| ≤ a|t| + |t|2 ∀t ∈ R.
2
Notice the difference with respect to (1.9): this is because we now want to keep the
coefficient in front of |t|2 as small as possible.
Theorem 2.1.6 Under the assumptions (h1 ), (h2 ) and (h5 ), Problem (2.1) admits
at least one solution.

Proof To control the term  F (u) dx we use the characterization of the first eigenvalue, Theorem 1.7.6. We have



b
b
F (u) dx ≤ a |u| dx +
|u|2 dx ≤ C u +
u 2,
2 
2λ1


so that


1
1
1 b
I (u) = u 2 −
F (u) dx −
hu dx ≥ u 2 − C u −
u 2 − |h|2 |u|2
2
2
2 λ1




b
1
u 2 − C1 u .
1−
≥
2
λ1
Since b < λ1 , the functional is coercive.
The remaining part of the proof works exactly as in the preceding theorems. 
Remark 2.1.7 In the literature, the growth conditions contained in assumptions (h4 )
and (h5 ) are often written
|f (t)|
|f (t)|
< λ1
< +∞ and lim sup
lim sup
σ
|t|
t→±∞ |t|
t→±∞
respectively.
Remark 2.1.8 It is interesting to inspect what happens if we allow b ≥ λ1 in (h5 ). In
this case the functional I is no longer coercive and may be unbounded from below.
In some cases, as for example if we take f (t) = λk t (k ≥ 1), Problem (2.1) has
no solution for some h (see Theorem 1.7.8). Later we will see how to deal with
nonlinearities that grow more than quadratically.
We now examine a variant of Problem (2.1), with the aim of showing how the
variational information can be of help in establishing existence results. Consider

−u + q(x)u = f (u) in ,
(2.5)
u=0
on ∂.

44

2

Minimization Techniques: Compact Problems

If f (0) = 0, a frequent case in the applications, then the problem admits u ≡ 0 as a
solution (called the trivial solution).
Without further assumptions, it may very well be that the trivial solution is the
only solution. For example, if f (t)t ≤ 0 for all t, then any weak solution satisfies

u 2 = f (u)u dx ≤ 0,


and hence u ≡ 0.
In the next result we show a condition that prevents this fact.
Theorem 2.1.9 Let (h1 ) hold. Assume moreover that f : R → R is continuous and
satisfies
|f (t)|
< λ1 .
|t|
t→±∞

f (0) = 0 and

lim sup

Then Problem (2.5) admits at least one solution (which may be trivial).
If in addition f also satisfies
lim inf
t→0+

f (t)
> λ1 ,
t

(2.6)

then Problem (2.5) admits at least one nontrivial solution.
Proof The first part is a special case of Theorem 2.1.6. We now show that under
condition (2.6) the solution found in the first part is not identically zero. We use a
level argument, as follows.
First notice that by (2.6), there exists β > λ1 and δ > 0 such that
f (t) ≥ βt

∀t ∈ [0, δ],

which implies that
1
F (t) ≥ βt 2 ∀t ∈ [0, δ].
2
Let ϕ1 > 0 be the first eigenfunction of − + q(x), and take ε > 0 so small that
εϕ1 (x) < δ for almost every x; this is possible because ϕ1 ∈ L∞ (), see Theorem 1.7.3.
Then
1
F (εϕ1 (x)) ≥ βε 2 ϕ12 (x)
2
a.e. in . This implies that


1
1
1
I (εϕ1 ) = εϕ1 2 − F (εϕ1 ) dx ≤ ε 2 ϕ1 2 − βε 2 ϕ12 dx
2
2
2





2
1
1
ε
= ε 2 λ1 ϕ12 dx − βε 2 ϕ12 dx = (λ1 − β) ϕ12 dx < 0,
2
2
2




2.1 Coercive Problems

45

since β > λ1 . Let u be the solution that minimizes I . Then
I (u) = min I (v) ≤ I (εϕ1 ) < 0.
v∈H01 ()

As I (0) = 0, u cannot be the trivial solution.



Remark 2.1.10 It is possible to show that the preceding problem admits a nonnegative solution. Indeed it is enough to proceed as in Example 1.7.10.
Since (h3 ) implies (h4 ) that implies (h5 ), it is clear Theorem 2.1.6 implies Theorem 2.1.5 that in turn implies Theorem 2.1.2. As a further example we examine now
another case in which we can apply the scheme of the previous results and that leads
to a theorem that is independent of the preceding ones. Consider the assumption
(h6 ) f : R → R is continuous and there exist a, b > 0 such that
∗

|f (t)| ≤ a + b|t|2 −1

∀t ∈ R.

Moreover
f (t)t ≤ 0 ∀t ∈ R.
By integration one easily sees that there exist a1 , b1 > 0 such that
∗

|F (t)| ≤ a1 + b1 |t|2

∀t ∈ R

and that
F (t) ≤ 0 ∀t ∈ R
Notice that −F is allowed to have critical growth, but F is not. Moreover the sign
condition f (t)t ≤ 0 prevents, as we have seen, the existence of nontrivial solutions
when h ≡ 0. In spite of this, Problem (2.1) is solvable.
Theorem 2.1.11 Under the assumptions (h1 ), (h2 ) and (h6 ), Problem (2.1) admits
at least one solution.
Proof By Example 1.3.20, the usual functional I is differentiable on H01 (). Coercivity is simple consequence of the sign of F :


1
1
1
F (u) dx −
hu dx ≥ u 2 − |h|2 |u|2 ≥ u 2 − C u .
I (u) = u 2 −
2
2
2


The proof then proceeds exactly as in the previous theorems.

Remark 2.1.12 This last existence result is similar to the one obtained in Theorem 1.6.6. However here we do not assume the monotonicity of f , so that the functional needs not be convex. This implies that we have to prove the weakly lower
semicontinuity, as in the other theorems of this section, and we do not have a uniqueness result.
Remark 2.1.13 If |F | grows more than critically, the functional I is no longer well
defined on H01 (), because a function in H01 () need not be in Lp () if p > 2∗ .
This means that the integral of F (u) may be divergent for some u.

46

2

Minimization Techniques: Compact Problems

2.2 A min–max Theorem
In this section we deal with a much more complex result than those treated so far;
the proof of the main theorem is quite long and can be omitted upon a first reading.
First, a heuristic motivation. The results in the previous section show, very
roughly speaking, that if the nonlinearity f “does not interact” with the spectrum of
the differential operator, then the procedure used for the linear problem (minimization) still works in the nonlinear case: the functional is coercive, bounded below,
and has a global minimum.
Let us see what we mean by “does not interact”, at least in a simplified setting.
Suppose that f is differentiable on R and that
sup |f  (t)| < λ1 .
t∈R

This assumption implies (h5 ) and in particular implies that the closure of the range
of f  is contained in (−λ1 , λ1 ). This is the property that makes the functional coercive (actually, as we have seen, it is enough that the property holds for large t; one
can also check that supt∈R f  (t) < λ1 works as well).
The situation changes dramatically, even in the linear case, if we allow that f  (t)
lies (for t large) between some eigenvalues of the differential operator. For example, if we take f (t) = λt with λ > λ1 , then the associated functional is no longer
coercive, and it is unbounded below. Thus no minimization is possible.
In some cases however, certain ideas used in the previous section can be modified
to obtain again an existence result. We now describe one of these cases, returning
to an assumption that does not require f to be differentiable. We assume that f is
defined on R and
(h7 ) There exist an integer ν ≥ 1 and α, β ∈ R such that
λν < α ≤

f (s) − f (t)
≤ β < λν+1
s −t

∀s, t ∈ R.

Remark 2.2.1 Clearly (h7 ) implies that f is globally Lipschitz continuous. Of
course if f is differentiable, then (h7 ) is equivalent to
λν < α ≤ f  (t) ≤ β < λν+1

(2.7)

for all t ∈ R: the closure of the range of f  lies between two eigenvalues.
Remark 2.2.2 We notice for further use that by direct integration we obtain the
following growth properties for f and for its primitive F : there exist constants c ∈ R
such that
• αt + c ≤ f (t) ≤ βt + c ∀t ≥ 0,
• βt + c ≤ f (t) ≤ αt + c ∀t ≤ 0,
• 12 αt 2 + ct ≤ F (t) ≤ 12 βt 2 + ct ∀t ∈ R.
We are going to prove the following result.

2.2 A min–max Theorem

47

Theorem 2.2.3 Under the assumptions (h1 ), (h2 ) and (h7 ), Problem (2.1), namely

−u + q(x)u = f (u) + h(x) in ,
u=0
on ∂,
admits exactly one solution.
We will prove this result through a series of lemmas, where we always assume
(h1 ), (h2 ) and (h7 ). The point is to study the properties of the functional


1
2
I (u) = u −
F (u) dx −
hu dx,
2


which is defined and differentiable on H01 () in view of the growth conditions on f
(Example 1.3.20).
The space H01 () is endowed with the scalar product (2.2) and the corresponding
norm. We denote
X1 = span{ϕ1 , . . . , ϕν },

and X2 = X1⊥ = cl{span{ϕk | k ≥ ν + 1}}, (2.8)

where ϕk is the eigenfunction associated to λk and “cl” denotes closure in H01 ().
By definition the subspaces X1 and X2 are orthogonal and H01 () = X1 ⊕ X2 .
Remark 2.2.4 In the following, with a slight abuse of notation, we will write any
w ∈ H01 () indifferently as w = u + v or w = (u, v), with u ∈ X1 and v ∈ X2 . This
simplifies the notation at various stages.
Lemma 2.2.5 We have



1
u 2
λν

∀u ∈ X1 ,

(2.9)

1
v 2
λν+1

∀v ∈ X2 .

(2.10)

u2 dx ≥


and


v 2 dx ≤


Proof With the notation of Remark 1.7.5, if u ∈ X1 then

ν
ν
ν


βk2
1  2
1
u2 dx =
αk2 =
≥
βk =
u 2,
λk
λν
λν

k=1

k=1

k=1

while if v ∈ X2 , then

ν
∞
∞


βk2
1  2
1
v 2 dx =
αk2 =
≤
βk =
v 2.
λk
λν+1
λν+1

k=ν+1

k=ν+1

k=1



This lemma contains the relevant information to deduce the coercivity properties
of the functional I . Of course we do not expect coercivity on the subspace X1 , and
indeed on X1 we have the opposite behavior. The next lemma clarifies this.
We define a functional J : X1 × X2 → R by
J (u, v) = I (u + v).

48

2

Minimization Techniques: Compact Problems

Lemma 2.2.6 For every v ∈ X2 , the functional J (·, v) : X1 → R is anticoercive
(recall that this means that −J (·, v) is coercive). For every u ∈ X1 , the functional
J (u, ·) : X2 → R is coercive.
Proof By the growth properties listed in Remark 2.2.2 we have, for every fixed
v ∈ X2 ,


1
2
F (u + v) dx −
h (u + v) dx
J (u, v) = I (u + v) = u + v −
2



1
1
1
≤ u 2+ v 2−
α(u + v)2 dx
2
2
2 


− c (u + v) dx −
h(u + v) dx



α
1
u2 dx + c1 u + c2 ,
≤ u 2−
2
2 
where the ci ’s are constants that depend on v, f, h but not on u. Since u ∈ X1 , from
Lemma 2.2.5 we obtain


α
1
1 α
1
2
2
u 2 + c1 u + c2 .
1−
J (u, v) ≤ u −
u + c1 u + c2 =
2
2 λν
2
λν
As α > λν , this proves the first part.
With the same argument, for every fixed u ∈ X1 we have



1
1
1
J (u, v) ≥ u 2 + v 2 −
β(u + v)2 − c (u + v) dx −
h(u + v) dx
2
2
2 



β
1
v 2 dx + c3 v + c4 ,
≥ v 2−
2
2 
and applying Lemma 2.2.5 we conclude that
1
1 β
v 2−
v 2 + c3 v + c4
2
2 λν+1


β
1
1−
v 2 + c3 v + c4 ,
≥
2
λν+1

J (u, v) ≥

where the constants do not depend on v. Since β < λν+1 , also the second part is
proved.

The next property is crucial.
Lemma 2.2.7 For every u ∈ X1 , the functional J (u, ·) : X2 → R is strictly convex
and for every v ∈ X2 , the functional J (·, v) : X1 → R is strictly concave.
Proof We are going to check the convexity properties through Proposition 1.5.10.
Fix u ∈ X1 and consider the functional v → J (u, v) = I (u + v). This functional is

2.2 A min–max Theorem

49

differentiable, and, denoting by ∂2 J (u, v) its differential at v ∈ X2 , we have for all
w ∈ X2 ,



∂2 J (u, v)w = I (u + v)w = (v|w) −
f (u + v)w dx −
h w dx.




Therefore, for every v1 , v2 ∈ X2 ,
[∂2 J (u, v1 ) − ∂2 J (u, v2 )] (v1 − v2 )


= (v1 |v1 − v2 ) −
f (u + v1 )(v1 − v2 ) dx −
h (v1 − v2 ) dx




f (u + v2 )(v1 − v2 ) dx +
h (v1 − v2 ) dx
− (v2 |v1 − v2 ) +



= v1 − v2 2 − (f (u + v1 ) − f (u + v2 )) (v1 − v2 ) dx.


Now the assumption
f (t) − f (s)
≤β
t −s
implies that for all t, s ∈ R there results
(f (t) − f (s))(t − s) ≤ β(t − s)2 ,
so that

(f (u + v1 ) − f (u + v2 ))(v1 − v2 ) dx


= (f (u + v1 ) − f (u + v2 ))((u + v1 ) − (u + v2 )) dx



β
v1 − v2 2 ,
≤ β ((u + v1 ) − (u + v2 ))2 dx = β (v1 − v2 )2 dx ≤
λν+1


by Lemma 2.2.5. Thus we obtain



β
v1 − v2 2 > 0 (2.11)
[∂2 J (u, v1 ) − ∂2 J (u, v2 )] (v1 − v2 ) ≥ 1 −
λν+1

for all v1 = v2 , because β < λν+1 .
Proposition 1.5.10 applies to show that for every u ∈ X1 the functional J (u, ·) is
strictly convex.
The argument to prove the concavity of J (·, v) is essentially the same. Fix v ∈ X2
and denote by ∂1 J (u, v) the differential of the functional u → J (u, v) at u. As above
we obtain, for all z ∈ X1 ,


∂1 J (u, v)z = (u|z) −
f (u + v)z dx −
hz dx,


so that



50

2

Minimization Techniques: Compact Problems

[∂1 J (u1 , v) − ∂2 J (u2 , v)] (u1 − u2 )


= (u1 |u1 − u2 ) −
f (u1 + v)(u1 − u2 ) dx −
h(u1 − u2 ) dx




− (u2 |u1 − u2 ) +
f (u2 + v)(u1 − u2 ) dx +
h(u1 − u2 ) dx



= u1 − u2 2 −
(f (u1 + v) − f (u2 + v)) (u1 − u2 ) dx.


Thus, by Lemma 2.2.5,


α
α(u1 − u2 )2 dx ≥
u1 − u2 2 ,
(f (u1 + v) − f (u2 + v)) (u1 − u2 ) dx ≥
λ
ν


and then



α
[∂1 J (u1 , v) − ∂1 J (u2 , v)] (u1 − u2 ) ≤ 1 −
λν


u1 − u2 2 < 0

for all u1 = u2 , because α > λν . This shows that the functional u → J (u, v) is
strictly concave.

The preceding lemmas allow us to minimize J over X2 .
Lemma 2.2.8 For every u ∈ X1 there exists a unique w = w(u) ∈ X2 such that
J (u, w) = min J (u, v).
v∈X2

Proof The function v → J (u, v) is continuous, coercive and strictly convex. By
Theorems 1.5.6 and 1.5.8, it has a unique global minimum.

This results makes it possible to define a functional G : X1 → R by
G(u) = min J (u, v) = J (u, w(u))
v∈X2

that we are now going to study.
Lemma 2.2.9 The functional G is bounded above, namely
sup G(u) < +∞.
u∈X1

Proof If supu∈X1 G(u) = +∞, there exists a sequence {uk }k∈N ⊂ X1 such that
G(uk ) → +∞ as k → +∞. By the growth properties of F , for every u ∈ X1 , we
have


1
2
G(u) ≤ J (u, 0) ≤ |J (u, 0)| ≤ u +
|F (u)| dx +
|h u| dx
2


≤ c5 u 2 + c 6 u ,

2.2 A min–max Theorem

51

for some positive constants c5 , c6 . Since G(uk ) → +∞, this shows that uk → ∞.
But J is anticoercive on X1 , and then
G(uk ) ≤ J (uk , 0) → −∞,
contradicting the choice of the sequence {uk }.



Lemma 2.2.10 The number
s = sup G(u)
u∈X1

is attained in X1 , namely there exists u∗ ∈ X1 such that G(u∗ ) = s.
Proof Let {uk }k∈N ⊂ X1 be a maximizing sequence for G on X1 , so that
G(uk ) → s. The argument in the preceding proof shows that {uk } is bounded in X1 .
Since X1 has finite dimension, there exists u∗ ∈ X1 such that, up to subsequences,
uk → u∗ in X1 , and then also in H01 () (all norms are equivalent on X1 ).
Thus, for every fixed v ∈ X2 , we obtain, as k → ∞,
•  uk + v 2 → u∗ + v 2 ,
•  F (uk + v) dx →  F (u∗ + v),


•  h(uk + v) dx →  h(u∗ + v) dx,
and therefore
J (uk , v) → J (u∗ , v).
On the other hand, J (uk , v) ≥ G(uk ) → s, so that
J (u∗ , v) ≥ s.
Since this holds for every v ∈ X2 , we see that
G(u∗ ) = min J (u∗ , v) ≥ s = sup G(u),
v∈X2

u∈X1

that is,
G(u∗ ) = s = max G(u).
u∈X1



Let v∗ = w(u∗ ) be the unique element in X2 given by Lemma 2.2.8. Notice that
G(u∗ ) = J (u∗ , v∗ ). The following property is determinant to conclude the proof of
Theorem 2.2.3.
Lemma 2.2.11 The element (u∗ , v∗ ) ∈ X1 × X2 is a “saddle point” for J , in the
sense that
J (u, v∗ ) ≤ J (u∗ , v∗ ) ≤ J (u∗ , v)

∀u ∈ X1 , ∀v ∈ X2 .

Proof Since J (u∗ , v∗ ) = G(u∗ ) = minv∈X2 J (u∗ , v), the inequality
J (u∗ , v∗ ) ≤ J (u∗ , v)

∀v ∈ X2

52

2

Minimization Techniques: Compact Problems

is trivial, and the proof amounts to establish the other inequality, namely
J (u, v∗ ) ≤ J (u∗ , v∗ )

∀u ∈ X1 .

(2.12)

Once more, convexity plays a fundamental role.
For every t ∈ (0, 1) and for every u ∈ X1 , set
wt = w((1 − t)u∗ + tu),
where as usual w(·) is given by Lemma 2.2.8. Since J is concave in u ∈ X1 , and u∗
maximizes G, we have
G(u∗ ) ≥ G((1 − t)u∗ + tu) = J ((1 − t)u∗ + tu, wt )
≥ (1 − t)J (u∗ , wt ) + tJ (u, wt )
≥ (1 − t)G(u∗ ) + tJ (u, wt ),
from which we see that for all t ∈ (0, 1) and all u ∈ X1 ,
G(u∗ ) ≥ J (u, wt ).

(2.13)

For u fixed, the preceding inequality, together with the fact that J is coercive in
v ∈ X2 , shows that the set {wt | t ∈ (0, 1)} is bounded in X2 . Therefore we can take
a sequence {tk }k∈N ⊂ (0, 1) such that
tk → 0 and wtk

w̃

in X2 .

Since the functional v → J (u, v) is weakly lower semicontinuous (Theorem 1.5.3),
we obtain
J (u, w̃) ≤ lim inf J (u, wtk ) ≤ G(u∗ )
k

(2.14)

by (2.13).
We now show that w̃ = v∗ ; in this case the proof is complete since (2.14) reads
J (u, v∗ ) ≤ G(u∗ ) = J (u∗ , v∗ ),

(2.15)

and u is arbitrary in X1 .
By the concavity in u ∈ X1 and the definition of w, for the same sequence as
above we have
(1 − tk )J (u∗ , wtk ) + tk J (u, wtk )
≤ J ((1 − tk )u∗ + tk u, wtk )
= G((1 − tk )u∗ + tk u) = inf J ((1 − tk )u∗ + tk u, v).
v∈X2

This means that for every v ∈ X2 ,
(1 − tk )J (u∗ , wtk ) + tk J (u, wtk ) ≤ J ((1 − tk )u∗ + tk u, v).
When k → +∞ we have tk → 0, so that
(1 − tk )u∗ + tk u → u∗ ,

w tk

w̃,

(2.16)

2.2 A min–max Theorem

53

and from (2.16) we obtain, by continuity in u and weak lower semicontinuity in v,
J (u∗ , w̃) ≤ J (u∗ , v).
This holds for every v ∈ X2 , and therefore
J (u∗ , w̃) = inf (u∗ , v) = G(u∗ ).
v∈X2

By Lemma 2.2.8, there exists a unique w ∈ X2 such that J (u∗ , w) = G(u∗ ), and
this element is exactly the one that we called v∗ . Summing up, we obtain
w̃ = v∗ ,


so that (2.15) is true.

End of the proof of Theorem 2.2.3 We first show that u∗ + v∗ is a critical point for I .
For every u ∈ X1 and every t ∈ R, let
γ (t) = J (u∗ + tu, v∗ ) = I (u∗ + tu + v∗ ).
The function γ is differentiable and has a maximum point at t = 0, by the preceding
lemma. Then
0 = γ  (0) = I  (u∗ + v∗ )u.
In the same way, if for v ∈ X2 we define
η(t) = J (u∗ , v∗ + tv) = I (u∗ + v∗ + tv),
then we see that η is differentiable and has a minimum point at t = 0. So,
0 = η (0) = I  (u∗ + v∗ )v.
Adding the two equations we obtain
I  (u∗ + v∗ )(u + v) = 0
for every u ∈ X1 and every v ∈ X2 ; since H01 () = X1 ⊕ X2 , we conclude that
I  (u∗ + v∗ ) = 0. The existence of a solution to Problem (2.1) is proved.
We now turn to the uniqueness question.
Assume that u1 , u2 are two solutions of (2.1), that is,


(ui |ψ) − f (ui )ψ dx − hψ = 0




for i = 1, 2 and for all ψ ∈ H01 (). We define a function a ∈ L∞ () by


a(x) =

f (u1 (x))−f (u2 (x))
u1 (x)−u2 (x)

α

if u1 (x) = u2 (x),
if u1 (x) = u2 (x).

From (h7 ) we see that α ≤ a(x) ≤ β for a.e. x ∈ . Subtracting the equation for u2
from the equation for u1 and setting w = u1 − u2 , we see that w satisfies

(w|ψ) − (f (u1 ) − f (u2 ))ψ dx = 0


54

2

Minimization Techniques: Compact Problems

for all ψ ∈ H01 (), that we can also write

(w|ψ) − a(x)wψ dx = 0.

(2.17)



We now write w = w1 + w2 , with wi ∈ Xi and we recall from Lemma 2.2.5 that


1
1
w12 dx ≥
w1 2 ,
w22 dx ≤
w2 2 .
λν
λν+1


Choosing ψ = w1 and then ψ = w2 in (2.17) we obtain




aw12 dx +
aw1 w2 dx and w2 2 =
aw22 dx +
aw1 w2 dx,
w1 2 =


so that





w1 2 =


≥




aw12 dx −




aw22 dx + w2 2 ≥ α






w12 dx − β



w22 dx + w2 2

α
β
w1 2 −
w2 2 + w2 2 ,
λν
λν+1

that can be written



α
1−
λν




w1

2

≥ 1−

β
λν+1


w2 2 .

Since α > λν and β < λν+1 , this inequality implies that w1 = w2 = 0, namely
w = 0 and thus u1 = u2 . Uniqueness is verified, and the proof of the theorem is
complete.

Remark 2.2.12 The proof of uniqueness uses the equation satisfied by critical points
and various inequalities. A more “abstract” proof involves just convexity properties
and works as follows. Assume for simplicity that I has a critical point at zero (translating if necessary) and a critical point at u + v ∈ X1 ⊕ X2 . Define ϕ : R2 → R as
ϕ(s, t) = I (su + tv) = J (su, tv).
It follows immediately from the properties of J (Lemma 2.2.7) that ϕ is strictly
concave in s and strictly convex in t. Just as easily, ϕ has a critical point at (0, 0)
and another one at (1, 1). This is impossible. Indeed 0 is necessarily a strict global
maximum for s → ϕ(s, 0) and a strict global minimum for t → ϕ(0, t), while 1 is a
strict global maximum for s → ϕ(s, 1), and a strict global minimum for t → ϕ(1, t).
Then
ϕ(0, 0) < ϕ(0, 1) < ϕ(1, 1) < ϕ(1, 0) < ϕ(0, 0),
a contradiction. Thus I cannot have more than one critical point.
Remark 2.2.13 One of the interesting aspects of the previous theorem is the procedure by which we have found a critical point. Indeed, we have first split the space

2.3 Superlinear Problems and Constrained Minimization

55

orthogonally as H01 () = X1 ⊕ X2 , according to convexity and concavity properties of the functional I ; then, writing the generic element of H01 () as u + v, with
u ∈ X1 and v ∈ X2 , we have found a critical level s for I as
s = max min I (u + v).
u∈X1 v∈X2

This is a first example of a procedure that we will generalize in Chap. 4.
Remark 2.2.14 It is important to notice that many steps of the proof of the theorem work because of convexity (or concavity) properties of the functional I . These
properties hold because of the rather strong assumption (h7 ), that rules the behavior
of the nonlinearity f on the entire real line. For example, if f is differentiable and
we require that it satisfies (2.7) for |t| large only, then the convexity properties of I
fail, and we cannot prove Theorem 2.2.3. This does not mean that we cannot find a
solution to the problem, but certainly we cannot repeat the above proof. These cases
will be dealt with in later chapters with stronger methods.
Remark 2.2.15 In assumption (h7 ) one cannot allow α = λν or β = λν+1 . For example, as we have already pointed out, the linear equation −u = λν u + h in H01 ()
does not admit a solution for every h ∈ L2 ().
Remark 2.2.16 As a final remark we point out that if h = 0 in Theorem 2.2.3, then
the problem admits only the trivial solution when f (0) = 0. Indeed in this case
u = 0 is a critical point of I , and, by uniqueness, it is its only critical point.

2.3 Superlinear Problems and Constrained Minimization
Up to now we have only treated problems where the nonlinear term f has an at
most linear growth. In case the nonlinearity grows faster than linearly, one speaks
of superlinear problems. For these types of problems the techniques used so far
do not work anymore; for example the functionals associated to these problems are
generally unbounded from below and they present a lack of convexity or concavity
properties that makes the arguments of the previous sections useless.
Actually for rather general f and h only partial results are known, though a quite
rich theory has been developed. We begin to present here some of the simplest cases,
in which h is identically zero and f is a power. Further results will be presented in
later sections.
We take throughout this section a real number p such that
2N
,
N −2
and we search a function u that satisfies the superlinear and subcritical problem

−u + q(x)u = |u|p−2 u in ,
(2.18)
u=0
on ∂.
2 < p < 2∗ =

56

2

Minimization Techniques: Compact Problems

Of course this problem admits the zero solution, which poses an extra difficulty. We
will prove the existence of a nontrivial solution by two different methods, which can
be extended to cover more general problems. The main result is the following.
Theorem 2.3.1 Let p ∈ (2, 2∗ ) and assume that (h1 ) holds. Then Problem (2.18)
admits at least one nonnegative and nontrivial solution.
From now on we tacitly assume that the hypotheses of Theorem 2.3.1 hold. For
the role of (h1 ), see Remark 2.1.1.
The functional whose critical points are the (weak) solutions of (2.18) is
I : H01 () → R defined by



1
1
1
1 p
1
2
2
|∇u| dx +
q(x)u dx −
|u|p dx = u 2 − |u|p ,
I (u) =
2 
2 
p 
2
p
which is differentiable by the results of Example 1.3.20. We notice immediately that
I is not bounded below, since for every u = 0 we have
I (tu) =

tp p
t2
u 2 − |u|p → −∞
2
p

if t → +∞, because p > 2. Notice also that I is the difference of two strictly convex
functionals.

2.3.1 Minimization on Spheres
In the first method that we present the key property is the homogeneity of the two
terms in I ; indeed the first term is positively homogeneous of degree 2, while the
second is positively homogeneous of degree p. This difference of degrees of homogeneity will play a central role at various steps of the proof.
Since the functional I is unbounded below, no minimization is possible on the
whole space H01 (). The first step consists in getting rid of this unboundedness by
constraining the functional on a suitable set where it becomes bounded below. The
first choice (a second one will be presented in the next section) is a sphere of Lp ().
If, for every β > 0, we set


1
|u|p dx = β ,
β = u ∈ H0 ()


we see that I restricted to β takes the form I (u) = 12 u 2 − p1 β, so that it is certainly bounded from below. Now minimizing I on β is equivalent to minimizing
just the square of the norm, so we set
mβ = inf

u∈β

u 2.

We are going to show that mβ is attained by some function, and that this function
gives rise to a solution of Problem (2.18).

2.3 Superlinear Problems and Constrained Minimization

57

Lemma 2.3.2 For every β > 0, the level mβ is attained by a nonnegative function,
namely there exists u ∈ β , u(x) ≥ 0 a.e. in , such that
u 2 = mβ .
Proof Let {uk }k ⊂ β be a minimizing sequence for u 2 . Obviously the sequence
{|uk |}k is still a minimizing sequence in β (see the properties of H01 in Sect. 1.2.1)
and therefore we can assume from the beginning that uk (x) ≥ 0 a.e. in  and for
all k. This minimizing sequence is of course bounded in H01 (), so that, up to
subsequences,
u in H01 (),

uk

uk (x) → u(x)

uk → u

in Lp (),

and

a.e. in .

We then obtain immediately, by weak lower semicontinuity of the norm,
u 2 ≤ mβ ,
together with


|u|p dx = β,

and u(x) ≥ 0 a.e. in .



Thus u ∈ β , and this shows that u 2 = mβ . Notice also that u ∈ β implies that
u does not vanish identically.

Remark 2.3.3 The preceding proof is very simple. The reader should retain from it
that the key assumption is the subcritical growth condition p < 2∗ . For such p’s the
embedding of H01 () into Lp () is compact, and this is what allows one to say that
uk → u in Lp , and eventually that u ∈ β . This is essential to conclude that u is a
minimum in β .
In critical problems, namely when p = 2∗ , the compactness of the embedding
fails and the above argument breaks down. Even worse, some problems may have
no nontrivial solution. This is the starting point of a line of research, begun with [14],
that is still very active today. For some references see [26, 45].
Lemma 2.3.4 Let u be a minimizer found with the previous lemma. Then u satisfies



mβ
∇u · ∇v dx + q(x)uv dx =
|u|p−2 uv dx
(2.19)
β 


for all v ∈ H01 ().
Proof Although u minimizes the functional N (u) = u 2 on β , we cannot conclude that the differential of N vanishes at u, because β is not a vector space.
Concretely, this means that we cannot compare the values of N (u) and of N (u + v),
because u + v will not belong to β , in general. We have to construct small “variations” of u that lie on β .

58

2

Minimization Techniques: Compact Problems

To this aim, fix v ∈ H01 (). For s ∈ R small enough, say s ∈ (−ε, ε), the function
u + sv, is not identically zero. Therefore there exists t : (−ε, ε) → (0, +∞) such
that

|t (s)(u + sv)|p dx = β;


precisely,

t (s) =



β
p
 |u + sv| dx

1/p
.

Notice that the application s → t (s)(u + sv) defines a curve on β that passes
through u when s = 0. The function t is differentiable on (−ε, ε), and

− 1 −1 
p

1/p
p
t (s) = −β
|u + sv| dx
|u + sv|p−2 (u + sv)v dx.




t (0) = 1

and t  (0) = −β −1

Then we have


|u|p−2 uv dx.


We define γ : (−ε, ε) → R as
γ (s) = N (t (s)(u + sv)) = t (s)(u + sv) 2 .
Since t (s)(u + sv) ∈ β for every s ∈ (−ε, ε), the point s = 0 is a local minimum
for γ . The function γ is differentiable and


γ  (s) = 2 t (s)(u + sv) t  (s)(u + sv) + t (s)v ,
so that
0 = γ  (0) = 2 t (0) t  (0) u 2 + 2 t 2 (0) (u|v) = −2
We have thus shown that
mβ
(u|v) =
β

mβ
β


|u|p−2 uv dx + 2(u|v).



|u|p−2 uv dx,




for every v ∈ H01 (), namely (2.19).

Remark 2.3.5 The reader with some knowledge of differential geometry will have
noticed that the preceding proof amounts to a direct check of the fact that the differential of N at u vanishes on the tangent space to β at u, as is always the case for
minimizers of differentiable functionals defined on differentiable manifolds. Indeed
the previous result can be obtained “abstractly” through the Lagrange Theorem on
constrained extrema: setting

G(u) = |u|p dx,


2.3 Superlinear Problems and Constrained Minimization

59

we see that our problem consists in minimizing N constrained on G−1 (β) = β .
Now G is of class C 1 and for u ∈ G−1 (β), we have that
G (u)u = pG(u) = pβ = 0.
Therefore, by the Implicit Function Theorem, G−1 (β) is a C 1 manifold. The Lagrange Theorem then says that if u minimizes N on G−1 (β), there exists λ ∈ R (the
Lagrange multiplier) such that
N  (u) = λG (u).
This equation is precisely (2.19), with λ = mβ /β. We do not carry out a more general theory of constrained critical points; the interested reader can consult [2, 17].
End of the proof of Theorem 2.3.1 The last step consists in getting rid of the Lagrange multiplier mβ /β, and this is where homogeneity plays again a fundamental
role.
Let u be the minimum of N over β . Set u = cw, with c ∈ R to be determined.
By the previous lemma, w satisfies

mβ p−1
c
c(w|v) =
|w|p−2 wv dx
β

1

for all v ∈ H01 (). Choosing c = (β/mβ ) p−2 , we see that w (is nonnegative and)
satisfies

(w|v) =
|w|p−2 wv dx


for all v ∈ H01 (), namely is a weak (nontrivial) solution of (2.18).



Remark 2.3.6 We have obtained a solution by minimizing N on β . It is tempting
to constrain I or N on γ with γ = β and repeat the argument. However this does
not produce a new solution. Indeed it is very easy to see that
mγ
mβ
= 2/p
2/p
β
γ
and that u is a minimum of I on β if and only if v = (γ /β)1/p u is a minimum of I
on γ . These two functions give rise to the same solution of (2.18). For this reason
one normally chooses β = 1.

2.3.2 Minimization on the Nehari Manifold
We present a second approach to the search of solutions to (2.18), still based on
constrained minimization. This approach is slightly more complicated than minimization on spheres, but has the advantage that it does not require the nonlinearity
to be homogeneous, and can thus be applied to a wider class of problems (under

60

2

Minimization Techniques: Compact Problems

convenient assumptions). To illustrate it we concentrate again on Problem (2.18),
and we recall that the functional associated to it is



1
1
1
1
1 p
I (u) =
|∇u|2 dx +
q(x)u2 dx −
|u|p dx = u 2 − |u|p ,
2 
2 
p 
2
p
defined and differentiable on H01 (). Recall that I is unbounded below; once again
we restrict I to a suitable set in order to get rid of this problem. In the previous
section we have constrained I on a sphere, now we use the set
N = {u ∈ H01 () | u = 0, I  (u)u = 0}


|u|p dx .
= u ∈ H01 () u = 0, u 2 =

(2.20)



This set is called the Nehari manifold, and indeed it can be proved, under certain
assumptions, that it is a differential manifold diffeomorphic to the unit sphere of
H01 (), see [2] or [48]. We do not prove nor use these properties, but we confine
ourselves to an “elementary” approach.
Remark 2.3.7 By definition, the Nehari manifold contains all the nontrivial critical
points of I .
Notice that on N the functional I reads




1 1
1 1
−
u 2=
−
|u|p dx.
I (u) =
2 p
2 p 
This shows at once that I is coercive on N , in the sense that if {uk }k ⊂ N satisfies
uk → ∞, then I (uk ) → ∞.
We define
m = inf I (u),
u∈N

and we show, through a series of lemmas, that m is attained by some u ∈ N which is
a critical point of I considered on the whole space H01 (), and therefore a solution
to (2.18).
We begin with some basic properties of N and I .
Lemma 2.3.8 The Nehari manifold is not empty.
Proof For every not identically zero u ∈ H01 , one sees immediately that tu ∈ N for
some t > 0. Indeed, tu ∈ N is equivalent to

tu 2 =
|tu|p dx,


which is solved by

t=



u 2
p
 |u| dx

 1

p−2

> 0.



2.3 Superlinear Problems and Constrained Minimization

61

Remark 2.3.9 Even under more general assumptions on the nonlinearity (now we
are considering only the model case s → |s|p−2 s) one can prove that for every
u = 0, there exists a unique t = t (u) > 0 such that t (u)u ∈ N . Thus one can define
a map ψ from the unit sphere of H01 () to N as ψ(u) = t (u)u. In many concrete
cases this map is the diffeomorphism between the unit sphere and the Nehari manifold that we mentioned above, see again [2] or [48].
Lemma 2.3.10 We have
m = inf I (u) > 0.
u∈N

Proof If u ∈ N , by the Sobolev inequalities we have

u 2=
|u|p dx ≤ C u p ,


for some C > 0. Since u = 0 and p > 2 we obtain
  1
1 p−2
u ≥
,
C

(2.21)

for every u ∈ N , so that

m = inf I (u) =
u∈N

1 1
−
2 p




inf u 2 ≥

u∈N

1 1
−
2 p

  1
1 p−2
> 0.
C



Lemma 2.3.11 The level m is attained by a nonnegative function, namely there
exists u ∈ N , u(x) ≥ 0 a.e. in , such that
I (u) = m.
Proof Let {uk }k ⊂ N be a minimizing sequence for I , namely such that
I (uk ) → m. Clearly |uk | ∈ N and I (|uk |) = I (uk ), so that {|uk |}k is another minimizing sequence; for this reason we assume straight away that uk (x) ≥ 0 a.e. in 
for all k. We have already observed that I is coercive on N ; this implies that the
sequence {uk }k is bounded in H01 (), and as usual this means that, up to subsequences,
uk

u in H01 (),

uk (x) → u(x)

uk → u

in Lp (),

and

a.e. in .

Then we have u ≥ 0 a.e. and, by weak lower semicontinuity,


1
1
1 p
1
p
I (u) = u 2 − |u|p ≤ lim inf
uk 2 − |uk |p
k
2
p
2
p
= lim inf I (uk ) = m.
k

(2.22)

62

2

Minimization Techniques: Compact Problems


Since uk ∈ N , we have uk 2 =  |uk |p dx. By (2.21) it cannot be uk → 0,
p
 |uk | dx cannot tend to zero; thus, by strong convergence,
and therefore
p
 |u| dx = 0, which shows that u ≡ 0. Passing to the limit we obtain

u 2≤
|u|p dx.
(2.23)




If u 2 =  |u|p dx, then u ∈ N and (2.22) shows that u is the required minimizer. Since (2.23) holds, we only have to treat the case where

u 2<
|u|p dx.
(2.24)


We now show that if this happens, we reach a contradiction. Indeed, take t > 0 such
that tu ∈ N , namely

 1
p−2
u 2
t= 
.
p
 |u| dx
Since we are assuming (2.24), we deduce that 0 < t < 1. But tu ∈ N , so that




1
1 1
2
2 1
−
tu = t
−
u 2
0 < m ≤ I (tu) =
2 p
2 p


1 1
2
−
uk 2 = t 2 lim inf I (uk ) = t 2 m < m.
≤ t lim inf
k
k
2 p
This is impossible, and the proof is complete.



Remark 2.3.12 Once again, the key property is the compactness of the embedding
of H01 () into Lp (), that has been used several times in the preceding proofs.
End of the proof of Theorem 2.3.1 Let u ∈ N be a minimizer for I found in the previous lemma. We show that I  (u)v = 0 for all v ∈ H01 (), so that u is the required
solution.
Notice that as in Lemma 2.3.4, we cannot conclude this directly because we have
minimized I with the constraint u ∈ N .
Take any v ∈ H01 (). For every s in some small interval (−ε, ε) certainly the
function u + sv does not vanish identically. Let t (s) > 0 be a function such that
t (s)(u + sv) ∈ N , namely

 1
p−2
u + sv 2
t (s) = 
.
p
 |u + sv| dx
The function t (s) is a composition of differentiable functions, so it is differentiable;
the precise expression of t  does not matter here. Notice also that t (0) = 1.
The map s → t (s)(u + sv) defines a curve on N along which we evaluate I .
Thus we define γ : (−ε, ε) → R as
γ (s) = I (t (s)(u + sv)).

2.4 A Perturbed Problem

63

By construction, s = 0 is a minimum point for γ . Therefore
0 = γ  (0) = I  (t (0)u)[t  (0)u + t (0)v] = t  (0)I  (u)u + I  (u)v = I  (u)v.
For the last equality we have used the fact that I  (u)u = 0 because u ∈ N . We have
obtained I  (u)v = 0 for all v ∈ H01 (), proving that u is a solution of (2.18).

Remark 2.3.13 The last part of the proof shows that a minimum of I constrained
on the Nehari manifold N is actually a free critical point of I , on the whole space
H01 (). This remarkable fact is expressed by saying that the Nehari manifold is a
natural constraint for I .

2.4 A Perturbed Problem
As we have anticipated the method of minimization on the Nehari manifold can be
extended to cover more general problems than that of the preceding section.
We begin with an existence result for a perturbed problem, in the sense that we
consider a power nonlinearity plus a fixed function h ∈ L2 (). The result contained
in this section is quite delicate, and can be omitted upon first reading.
We are going to prove that under suitable assumptions, and particularly if h is
small, the problem admits two solutions. Let us make this more precise.
We consider, for h ∈ L2 () and p ∈ (2, 2∗ ), the Dirichlet problem

−u + q(x)u = |u|p−2 u + h(x) in ,
(2.25)
u=0
on ∂.
Or aim is to show that if |h|2 is sufficiently small, then (2.25) admits at least two nontrivial solutions. This is not really surprising since the unperturbed problem (h ≡ 0)
also admits two solutions: the one found with Theorem 2.3.1 and the trivial solution
u ≡ 0. If h does not vanish identically, the trivial solution is replaced by a “true”
nonzero solution. Thus one can think that for h small the two solutions are “perturbations” of the two solutions already present in the autonomous case.
We add that the solution corresponding in this scheme to the trivial solution of
the unperturbed case can be found very easily, while most of the work must be
devoted to the search of the analogue of the solution found in Theorem 2.3.1 by
minimization on the Nehari manifold.
The functional associated to (2.25) is



1
1
1
1 p
J (u) = u 2 −
|u|p dx −
hu dx = u 2 − |u|p −
hu dx,
2
p 
2
p


which is of course differentiable on H01 (). The main result is the following.
Theorem 2.4.1 Let p ∈ (2, 2∗ ) and assume that (h1 ) holds. Then there exists ε ∗ > 0
such that for every h ∈ L2 (), with |h|2 ≤ ε ∗ , Problem (2.25) admits at least two
solutions.

64

2

Minimization Techniques: Compact Problems

We will prove this result going through a series of lemmas, as usual, and we start
with the argument leading to the analogue of the solution found in Theorem 2.3.1,
which is the hard part.
We introduce some notation. We denote by m the same constant as in the previous
section, namely


1 1
−
inf u 2 ,
m=
2 p u∈N
where N is the Nehari manifold defined in (2.20). Notice that N is not the Nehari
manifold associated to J , but the “unperturbed” one, relative to the functional I of
the previous section.
Next, we denote by Sp the best constant for the embedding of H01 () into Lp (),
that is,
Sp = inf{C > 0 | |u|p ≤ C u ∀u ∈ H01 ()}.
Lastly, we define the positive numbers
 1



p−2
1
1 2 1/p
d
,
d
=
,
d1 =
2
p
2 1
(p − 1)Sp

d3 =


1
d2
.
min d1 ,
2
Sp

Notice, for further reference, that d3 < d1 .
Lemma 2.4.2 There exists ε1 > 0 such that for every h ∈ L2 () with |h|2 ≤ ε1 and
for every u ∈ H01 (), if



p
u 2=
|u|p dx +
hu dx = |u|p +
hu dx,
(2.26)






then either
u < d3

or

u > d1 .

(2.27)

If the second case occurs, we have also
|u|p ≥ d2 .

(2.28)

Remark 2.4.3 Interpretation. Condition (2.26) expresses the fact that u belongs to
the Nehari manifold relative to J (we will introduce it later). Then the meaning of
the lemma is that, for |h|2 small, if u is in the Nehari manifold, then either u is small
( u < d3 ) or u is large ( u > d1 ). The region u ∈ [d3 , d1 ] is forbidden.
Proof We begin by showing that if |h|2 is small, one of the two inequalities in (2.27)
must hold. Assuming (2.26), we obtain
p

p

u 2 ≤ Sp u p + |h|2 |u|2 ≤ Sp u p + c|h|2 u ,
where c = ( λ11 )1/2 . Then, if u = 0,
p

u − Sp u p−1 − c|h|2 ≤ 0.

(2.29)

2.4 A Perturbed Problem

65

Consider now the function γ : [0, +∞) → R defined by
p

γ (t) = t − Sp t p−1 − c|h|2 .
Since
γ  (t) = 1 − (p − 1)Sp t p−2 ,
p

the function γ has a unique global maximum point located at t = d1 . Moreover
γ is strictly increasing on (0, d1 ), strictly decreasing on (d1 , +∞) and it satisfies
γ (0) < 0 and limt→+∞ γ (t) = −∞. With a simple computation one finds that

 1
p−2 p − 2
1
1
γ (d1 ) = p
− c|h|2 =: α1 − c|h|2 .
p−1
p−1
Spp−2
Since p > 2, there results α1 > 0, and if we take |h|2 ≤ α2c1 , then
γ (d1 ) ≥

α1
> 0.
2

This argument shows that if we assume
α1
,
2c
then the function γ has exactly two zeros t1 , t2 such that t1 < d1 < t2 , and γ (t) > 0
in (t1 , t2 ), while γ (t) < 0 in [0, t1 ) ∪ (t2 , +∞).
We notice that t1 satisfies

p p−1
p p−2 
.
c|h|2 = t1 − Sp t1 = t1 1 − Sp t1
|h|2 ≤

Since t1 < d1 , we deduce from this and the definition of d1 that



1
p−2
p p−2 
= t1
,
c|h|2 ≥ t1 1 − Sp d1
= t1 1 −
p−1
p−1
so that
t1 ≤

p−1
c|h|2 .
p−2

But then, if we take
|h|2 <
we get t1 < d3 .
Summing up, if we choose
|h|2 < min



p − 2 d3
,
p−1 c

p − 2 d3 α1
,
,
p − 1 c 2c

we obtain that γ (t) ≤ 0 implies t < d3 or t > d1 .
Therefore, with this choice of |h|2 , the inequality (2.29) implies (2.27) and thus
also (2.26) implies (2.27). The first part is proved.

66

2

Minimization Techniques: Compact Problems

We still have to check (2.28). If (2.26) holds and u > d1 , we can write

p
2
hu dx ≥ d12 − |h|2 |u|2 ≥ d12 − d|h|2 |u|p ,
|u|p = u −


where d = ||

p−2
2p

. We obtain
p

|u|p + d|h|2 |u|p − d12 ≥ 0.

(2.30)

Consider the function η : [0, +∞) → R defined by
η(t) = t p + d|h|2 t − d12 .
We have
η(d2 ) =

1 2
1
d + d|h|2 d2 − d12 = d|h|2 d2 − d12 ,
2 1
2

so that if
|h|2 <

d12
,
2dd2

there results η(d2 ) < 0. Since η (t) > 0 for all t > 0, we deduce that η(t) < 0 for
t ∈ [0, d2 ], so that the inequality (2.30) implies |u|p ≥ d2 .
The proof is then complete, with the choice

p − 2 d3 α1 d12
.
, ,
ε1 = min

p − 1 c 2c 2dd2
From now on we always assume |h|2 < ε1 ; further restrictions will be imposed
later.
We define the set
Nh = {u ∈ H01 () | J  (u)u = 0, u > d1 }



= u ∈ H01 () u 2 =
|u|p dx +
hu dx, u > d1




and the value
mh = inf J (u).
u∈Nh

Notice that Nh is not the complete Nehari manifold associated to J , but only a
subset of it, containing “large” functions ( u > d1 ). On Nh , the functional J takes
the form




1 1
1
J (u) =
−
u 2− 1−
hu dx.
2 p
p 
First we investigate under which conditions Nh is not empty.
Lemma 2.4.4 There exists ε2 ∈ (0, ε1 ] such that for every h ∈ L2 () with |h|2 ≤ ε2 ,
there results Nh = 0.

2.4 A Perturbed Problem

67

Proof Let u ∈ H01 () \ {0}. We study the behavior of the function


t → J  (tu)tu = t 2 u 2 − t p
|u|p dx − t
hu dx



p
hu dx
= t t u 2 − t p−1 |u|p −


for t > 0 by analyzing the function
γ (t) = t u

2

−t

p−1

p
|u|p −


hu dx.


Since
γ  (t) = u 2 − (p − 1)t p−2 |u|p ,
p

the function γ has a global maximum at
 1

p−2
u 2
.
t˜ =
p
(p − 1)|u|p
With an easy computation we see that
γ (t˜ ) =

u

2 p−1
p−2
p


α−

hu dx,

|u|pp−2



1

p−2
> 0.
p−1

where
α=

(p − 1)

1
p−2

Then we obtain
u

γ (t˜ ) ≥

2 p−1
p−2



p
p−2

Sp

α−

hu dx = u

1

p α − |h|2 |u|2
Spp−2


α
1
≥ u
α
−
c
u
|h|
=
u
−
c|h|
2
2 .
p
p
p−2
p−2
Sp
Sp

u

p
p−2



If
|h|2 ≤

α
p

,

2cSpp−2
we have γ (t˜) > 0. For such values of |h|2 , the function γ has then the following
properties: γ (t) is strictly increasing in (0, t˜), strictly decreasing in (t˜, +∞) and it
satisfies γ (t˜) > 0 and limt→+∞ γ (t) = −∞.
This shows that γ has at least one zero t1 ∈ (t˜, +∞), which implies that the
function v = t1 u satisfies (2.26). Moreover,
 1

p−2
u 2
1
u ≥
= d1 ,
v = t1 u > t˜ u =
p
p
1
(p − 1)|u|p
(p − 1) p−2 Spp−2

68

2

Minimization Techniques: Compact Problems

and this shows that v ∈ Nh . The proof is then complete provided we choose

α
.
ε2 = min ε1 ,
p
2cSpp−2



We now prove that for |h|2 small, the levels mh are uniformly bounded from
above. A uniform bound from below will be obtained in Lemma 2.4.7.
Lemma 2.4.5 Let ε3 = min{1, ε2 }. There exists c2 > 0 such that for every |h|2 < ε3
there results mh ≤ c2 .
Proof We denote by u0 and m0 , respectively, the solution and the level of the solution of the unperturbed problem (h ≡ 0) solved in the preceding section, that is,
u0 ∈ N ,

I (u0 ) = min I (u) = m0 .
u∈N

From Lemma 2.4.4 we know that if |h|2 < ε3 , there exists th > 0 such that
p
th u0 ∈ Nh . Since u0 ∈ N , it satisfies u0 2 = |u0 |p , so that the condition th u0 ∈ Nh
is equivalent to

2
p
th − th u0 2 = th hu0 dx,


namely to

p−1 
u0 2 =
th − th


hu0 dx.


This last condition implies

p−1 
u0 2 ≥ −c|h|2 u0 ,
th − th
i.e.
p−1

≥−

c|h|2
.
u0

p−1

≥−

c
.
u0

th − t h
If |h|2 < ε3 ≤ 1 we obtain

th − th

(2.31)

Since the function t → t − t p−1 tends to −∞ as t → +∞, the inequality (2.31)
implies the existence of c3 > 0, independent of h, such that th ≤ c3 . It is now simple
to conclude. Since th u0 ∈ Nh we have




1 1
1
−
th u0 2 − 1 −
hth u0 dx
mh ≤ J (th u0 ) =
2 p
p 




1
1 1 2
c3 u0 2 + 1 −
c3 c|h|2 u0
≤
−
2 p
p




1
1 1 2
c3 u0 2 + 1 −
c3 c u0 .
≤
−
2 p
p

2.4 A Perturbed Problem

69

The last term of this inequality is a positive number that does not depend on h. We
call it c2 and the proof is complete.

We go on with a uniform bound on minimizing sequences.
Lemma 2.4.6 There exists c4 > 0 independent of h, such that if |h|2 < ε3 , then
there exists a minimizing sequence {uk }k for mh such that uk ≤ c4 for all k, and
hence also |uk |p ≤ Sp c4 for all k.
Proof Let |h|2 < ε3 ≤ 1 and let {vk }k be a minimizing sequence for mh , namely
v k ∈ Nh

and J (vk ) → mh .

Since mh ≤ c2 , there exists k̃ such that for every k ≥ k̃ there results J (vk ) ≤ 2c2 ,
and this implies




1 1
1
2
−
vk − 1 −
hvk dx
2c2 ≥
2 p
p 




1 1
1
≥
−
vk 2 − 1 −
c|h|2 vk
2 p
p
≥ a1 v k 2 − a2 v k ,
where a1 = ( 12 − p1 ) and a2 = (1 − p1 )c. From this inequality one easily sees that

a2 + a22 + 8a1 c2
vk ≤
.
2a1


a2 + a22 +8a1 c2
and uk = vk̃+k to complete the proof. 
Then it is enough to set c4 =
2a1

The next result completes the estimate of Lemma 2.4.5.
Lemma 2.4.7 There exists ε4 ≤ ε3 such that if |h|2 < ε4 , then mh ≥ 12 m0 > 0.
Proof In this proof we denote by Jh the functional J , to stress its dependence on h.
We also recall that I is the functional associated to the “unperturbed” problem dealt
with in the previous section and that N is the corresponding Nehari manifold.
For every h with |h|2 < ε3 , we consider the minimizing sequence {uk }k obtained
in Lemma 2.4.6. Let tk be such that tk uk ∈ N (notice that both uk and tk depend
on h, but we do not denote it explicitly to have lighter notation).
As we know from the preceding section,
 1

uk 2 p−2
.
tk =
p
|uk |p

p
On the other hand uk ∈ Nh , so that uk 2 = |uk |p +  huk dx, and hence

 1

p−2
 huk dx
tk = 1 +
.
(2.32)
p
|uk |p

70

2

Minimization Techniques: Compact Problems

Then we can write



1 1 2
−
t uk 2
m0 ≤ I (tk uk ) =
2 p k

 
 



1 1 2
1 2
1 2
tk uk 2 − 1 −
tk
t
=
huk dx + 1 −
huk dx
−
2 p
p
p k 

 

1 2
t
huk dx.
(2.33)
= tk2 Jh (uk ) + 1 −
p k 

We want to obtain a uniform bound from below on Jh (uk ). First of all we estimate
tk from above. To this aim, by the estimates obtained in Lemmas 2.4.2 and 2.4.6 we
have

|  huk dx|
c uk
cc4
≤ |h|2
p
p ≤ |h|2 p ,
|uk |p
|uk |p
d2
so that if
p

d
|h|2 ≤ 2
cc4
we obtain


|  huk dx|
p

|uk |p

  p−2
4 2
−1 ,
3
  p−2
4 2
≤
−1
3

and hence, from (2.32),

 1/2
4
tk ≤
,
3
which is the desired estimate on tk . Next we analyze the last term in (2.33). We see
immediately that



 


1 2
1 2
1
4
1−
t
t |h|2 c uk ≤ |h|2 1 −
cc4 .
huk dx ≤ 1 −
p k 
p k
3
p
We now choose
m0
|h|2 <
,
4(1 − p1 )cc4
so that we obtain



 
1 2
m0
1−
tk
.
huk dx ≤
p
3

From this and from (2.33), we deduce that
2
tk2 Jh (uk ) ≥ m0 ,
3

which implies first of all that Jh (uk ) > 0. Since we also have tk2 ≤ 43 , we finally get
to
2
4
m0 ≤ tk2 Jh (uk ) ≤ Jh (uk ),
3
3

2.4 A Perturbed Problem

71

namely 12 m0 ≤ Jh (uk ). Passing to the limit as k → ∞, we see that
1
m0 ≤ mh .
2
All this holds with the bounds we described on |h|2 . The lemma is thus proved with

p   p−2
d2
4 2
m0
.
ε4 = min ε3 ,
−1 ,
cc4
3
4(1 − p1 )cc4



We have now everything we need to conclude the argument. First of all we show
that the minimum on Nh is attained.
Lemma 2.4.8 There exists ε5 ≤ ε4 such that for every |h|2 < ε5 the infimum mh is
attained by some u ∈ Nh .
Proof To begin with, let |h|2 < ε4 and let {uk } be a minimizing sequence for mh
constructed as in Lemma 2.4.6. Being bounded, we can assume that, up to subsequences, there exists u ∈ H01 such that
uk

u in H01 (),

uk → u in Lp () and in L2 ().

It is then immediate to deduce that
J (u) ≤ lim inf J (uk ) = mh ,
k

and that
p

(2.34)



u 2 ≤ |u|p +

hu dx.

(2.35)



Let us suppose first of all that in (2.35) equality holds, that is,

p
2
hu dx.
u = |u|p +

(2.36)



In Lemma 2.4.2 we have seen that if (2.36) holds, then either u > d1 or u < d3 .
In the first case, u ∈ Nh , and then (2.34) implies that u is the minimum we are
looking for. If, on the contrary, u < d3 , then recalling the definition of d3 we
obtain
d2
|u|p ≤ Sp u ≤ Sp d3 < Sp
= d2 .
Sp
But Lemma 2.4.2 says that |uk |p ≥ d2 , and, by the strong convergence in Lp () we
obtain |u|p ≥ d2 . This contradiction shows that if (2.36) holds, it cannot be u < d3
and hence, as we have seen, u is a minimum.
Let us suppose now that in (2.35) the strict inequality holds, namely

p
2
u < |u|p +
hu dx.
(2.37)


72

2

Minimization Techniques: Compact Problems

We know from Lemma 2.4.4 that there exists t ∗ > 0 such that t ∗ u ∈ Nh and
 1

p−2
u 2
∗
˜
t >t =
.
p
(p − 1)|u|p
Since (2.35) holds, we have

 1
 1
 p 

p−2
|u|p +  hu dx p−2
1
 hu dx
t˜ ≤
=
.
+
p
p
p − 1 (p − 1)|u|p
(p − 1)|u|p
But on the other hand,

|  hu dx|

1

u

p ≤ |h|2 c
p ≤ |h|2 cc4
p.
(p − 1)|u|p
(p − 1)|u|p
(p − 1)d2
p

(p−2)(p−1)d2

1
< 1, it is clear that we can choose ε5 = min{
Since p−1
2cc4
that if |h|2 < ε5 , then t˜ < 1.
Let us consider now the function

p
γ (t) = t u 2 − t p−1 |u|p −
hu dx

, ε4 }, to obtain



that we have already studied. We know that γ is decreasing in (t˜, +∞). Since
t ∗ u ∈ Nh , we have γ (t ∗ ) = 0. The inequality (2.37) is equivalent to γ (1) < 0. Since
t˜ < 1 and t˜ < t ∗ , we must necessarily have t ∗ < 1. This last estimate allows us to
conclude. Indeed, since t ∗ u ∈ Nh we obtain




1 1
1
−
u 2 − t∗ 1 −
mh ≤ J (t ∗ u) = (t ∗ )2
hu dx
2 p
p 




1 1
1
−
uk 2 − t ∗ lim 1 −
huk dx
≤ (t ∗ )2 lim inf
k
k
2 p
p 




1 1
1
−
uk 2 − 1 −
huk dx
≤ t ∗ lim inf
k
2 p
p 
= t ∗ lim inf J (uk ) = t ∗ mh < mh .
k

The last strict inequality holds because t ∗ ∈ (0, 1) and mh > 0. The contradiction
shows that (2.37) cannot hold, so that (2.36) is true. In this case, as we have seen, u
is the required minimum.

The last step consists in proving that the minimum is a critical point of J on the
whole space H01 ().
Lemma 2.4.9 There exists ε6 ∈ (0, ε5 ) such that if |h|2 < ε6 , then the minimum u
of J on Nh satisfies J  (u)v = 0 for all v ∈ H01 ().
Proof Fix v ∈ H01 () and consider the function ϕ : R × (0, +∞) → R defined by

2
2
p
p
h(u + sv) dx.
ϕ(s, t) = t u + sv − t |u + sv| − t


2.4 A Perturbed Problem

73

Since u ∈ Nh we have ϕ(0, 1) = 0. Clearly ϕ is of class C 1 and


∂ϕ
p
2
2
hu dx = (2 − p) u + (p − 1) hu dx.
(0, 1) = 2 u − p|u|p −
∂t


If it were ∂ϕ
∂t (0, 1) = 0, then we would have

p−1
p−1
|h|2 c u ,
u 2=
hu dx ≤
p−2 
p−2
namely,
u ≤

p−1
|h|2 c.
p−2

(2.38)

However, we know that u > d1 . If we take
|h|2 <

p−2
d1 ,
c(p − 1)

then (2.38) yields u < d1 , a contradiction. Therefore, for such choices of h it
must be ∂ϕ
∂t (0, 1) = 0. We can then apply the Implicit Function Theorem, obtaining
that there exist a number δ > 0 and a C 1 function t (s) : (−δ, δ) → R such that
ϕ(s, t (s)) = 0 for every s ∈ (−δ, δ), and t (0) = 1. Since u > d1 , we can also take
δ so small that t (s)(u + sv) > d1 . We have thus constructed a differentiable curve
s → Nh passing through u when s = 0. We now evaluate J along this curve, by
considering the function
γ (s) = J (t (s)(u + sv)).
The function γ is differentiable and has a local minimum at s = 0. Then
0 = γ  (0) = J  (u)[t  (0)u + t (0)v] = t  (0)J  (u)u + J  (u)v = J  (u)v,
because u ∈ Nh . Since this holds for every v ∈ H01 (), it is enough to take a positive
ε6 such that

(p − 2)d1
ε6 < min ε5 ,
c(p − 1)


to conclude.

We have found a solution to Problem (2.25). We now complete the proof of the
theorem by constructing a second solution.
Lemma 2.4.10 For every ε > 0 there exists δ > 0 such that if |h|2 < δ, then Problem
(2.25) admits a solution uh satisfying uh < ε.
p

Proof Let as usual I (u) = 12 u 2 − p1 |u|p ; we have
p

Sp
1
I (u) ≥ u 2 −
u p.
2
p

74

2

Minimization Techniques: Compact Problems

The function
p

Sp p
1
t
g(t) = t 2 −
2
p
is strictly increasing in a right neighborhood of 0, is continuous and satisfies
g(0) = 0; therefore there certainly exists ε  ≤ ε such that for all t ∈ (0, ε  ) there
results g(t) > 0.
Then fixing any η ∈ (0, ε  ), we obtain I (u) ≥ g(η) > 0 if u = η. We deduce
that

J (u) = I (u) −
hu dx ≥ g(η) − |h|2 cη.


Choosing
δ=

g(η)
2cη

and |h|2 < δ,

J (u) ≥

g(η)
> 0.
2

we conclude that, for u = η,

Let now
Bη = {u ∈ H01 () | u ≤ η} and nη = inf J (u).
u∈Bη

Clearly nη = ±∞. Moreover nη ≤ J (0) = 0. It is then straightforward to check,
with arguments already used many times in the first part of this chapter, that the
value nη is attained by some uh ∈ Bη . Since J (uh ) = nη ≤ 0, it cannot be uh = η,
and therefore uh lies in the interior of the ball Bη . The function uh is thus a local
minimum for J and solves (2.25). Moreover, uh < ε.

End of the proof of Theorem 2.4.1 Thanks to Lemma 2.4.9 we know that for every |h|2 < ε6 , there exists a solution u1 of Problem (2.25) with u1 > d1 . By
Lemma 2.4.10, choosing ε = d1 , we can fix δ > 0 such that for every |h|2 < δ there
exists a solution uh of Problem (2.25) with uh < d1 . If
|h|2 < ε ∗ := min{ε6 , δ},
we obtain two distinct solutions of Problem (2.25). The proof is complete.



2.5 Nonhomogeneous Nonlinearities
The method of minimization on the Nehari Manifold can also be extended to cases
where the nonlinearity is not homogeneous, under suitable assumptions. In this section we provide some examples in this sense.
We begin with the following problem: find u such that

−u + q(x)u = f (u) in ,
(2.39)
u=0
on ∂,

2.5 Nonhomogeneous Nonlinearities

75

where the nonlinearity
f satisfies the following assumptions. We recall that we det
note F (t) = 0 f (s)ds.
(f1 ) f : R → R is of class C 1 and is odd.
 (t)|
(f2 ) f  (0) = 0 and there exists p ∈ (2, 2∗ ) such that lim supt→+∞ |ft p−2
< +∞.
(f3 ) There exists μ > 2 such that f (t)t ≥ μF (t) for all t ∈ R.
(f4 ) For every t ∈ (0, +∞) there results f  (t)t > f (t).
Remark 2.5.1 Notice that the power nonlinearity f (u) = |u|p−2 u, with p ∈ (2, 2∗ ),
treated in Sect. 2.3 satisfies all the above assumptions.
Actually, assumptions (f3 ) and (f4 ) imply that the functions
F (t)
f (t)
and t →
tμ
t
are increasing, as one checks immediately by differentiation. This provides some
bounds at zero and at infinity. For example, comparing with t = 1 one finds that
F (t) ≤ F (1)t μ for t ∈ [0, 1] and F (t) ≥ F (1)t μ for t ≥ 1, and similarly for f .
t →

We will prove the following result.
Theorem 2.5.2 Assume that (h1 ) and (f1 )–(f4 ) hold. Then Problem (2.39) admits
at least one nontrivial and nonnegative solution.
As usual, the proof will be split in a series of lemmas, in each of which the
assumptions of Theorem 2.5.2 will be taken for granted.
We begin with the description of some properties of f (t) and F (t) that can be
deduced from the assumptions (f1 )–(f4 ) and that will be used during the proof.
Lemma 2.5.3 We have
(1) limt→0 Ft(t)
2 = 0.
(2) There exist positive constants M1 , M2 such that
|f  (t)| ≤ M1 |t|p−2

for |t| > M2 .

(3) There exist positive constants M3 , M4 such that
|F (t)| + |f (t)t| ≤ M3 |t|p

for |t| > M4 .

(4) For every ε > 0 there exists Cε > 0 such that
|F (t)| + |f (t)t| ≤ εt 2 + Cε |t|p

∀t ∈ R.

(2.40)

(5) There exists a positive constant D such that for every t ≥ 1,
f (t)t ≥ Dt μ

and

F (t) ≥ Dt μ .

(2.41)

Proof The first statement follows by applying twice the de l’Hôpital rule. Point (2)
is a direct consequence of (f2 ) and the oddness of f . Integrating, one obtains (3).

76

2

Minimization Techniques: Compact Problems

Likewise, the fact that f  (0) = 0 and (f2 ) imply (4), after integration. Lastly, (5)
follows from Remark 2.5.1 and (f3 ).

Weak solutions to Problem (2.39) are critical points of the functional

1
2
I (u) = u −
F (u) dx
2

where the norm is the same as in Sect. 2.3. The Nehari manifold in the present
case is
N = {u ∈ H01 () | I  (u)u = 0, u = 0}


= u ∈ H01 () u 2 =
f (u)u dx, u = 0 .


As usual, we begin by checking that working on the Nehari manifold makes sense.
Lemma 2.5.4 The Nehari manifold N is not empty.
Proof We prove that for every u ∈ H01 (), u ≡ 0, there exists t > 0 such that
tu ∈ N . We begin by assuming that u(x) ≥ 0 a.e., and we consider the function


2
2
γ (t) = I (tu)tu = t u −
f (tu)tu dx.


We want to study the behavior of γ for t → 0+ and for t → +∞. The aim is to find
a zero of γ .
Let


ϕ(t) =

f (tu(x))tu(x) dx.


By (2.40), for every ε > 0 there exists Cε > 0 such that
|f (tu(x))tu(x)| ≤ εt 2 u(x)2 + Cε t p u(x)p
Therefore



for all t > 0 and for a.e. x ∈ .


f (tu(x))tu(x) dx ≤ εt

ϕ(t) =



u(x) dx + Cε t

2

2



p

u(x)p dx.


Since u is fixed, ε is arbitrary and p > 2, this shows that ϕ(t) = o(t 2 ) as t → 0+ .
We have thus proved that
γ (t) = t 2 u 2 + o(t 2 )

as t → 0+ .

Next we study γ for t large. We begin by choosing t0 so large that the set
A = {x ∈  | t0 u(x) ≥ 1}
has positive measure; this is possible since u(x) ≥ 0 a.e. and u ≡ 0. Notice that if
t ≥ t0 , then tu(x) ≥ 1 a.e. on A. Now we apply (2.41) with t ≥ t0 , also recalling that
f is positive on positive arguments:

2.5 Nonhomogeneous Nonlinearities

77







f (tu(x))tu(x) dx =


f (tu(x))tu(x) dx +
A



≥ Dt μ

f (tu(x))tu(x) dx
\A

u(x)μ dx.
A

Notice that (3) and (5) of Lemma 2.5.3 imply that μ ≤ p, so that the last integral is
certainly finite.
The preceding inequality shows that

γ (t) ≤ t 2 u 2 − Dt μ u(x)μ dx for every t ≥ t0 .
A

The two properties of γ that we have established tell us that γ (t) is strictly positive for positive and small values of t, while γ (t) → −∞ if t → +∞.
Then there exists t˜ > 0 such that γ (t˜) = 0. Since t˜u ≡ 0, we conclude that
t˜u ∈ N .
Finally, if u is not almost everywhere positive, we argue on the function v = |u|:
we find again t˜ > 0 such that

f (t˜v)t˜v dx = 0.
t˜v 2 −


Since f (t)t is even, of course


f (t˜v)t˜v dx =
f (t˜u)t˜u dx


and

t˜v 2 = t˜u 2 ,




so that also t˜u 2 −  f (t˜u)t˜u dx = 0, and t˜u ∈ N .



We can now define a candidate critical level as
m = inf I (u)
u∈N

and we try to see if m is attained on N .
Lemma 2.5.5 There results
inf u 2 > 0.

u∈N

Proof Let λ1 be the first eigenvalue of the operator − + q(x), and choose a number C1 > 0 such that
1
|f (t)t| ≤ λ1 t 2 + C1 |t|p
2

∀t;

this is possible by (2.40).
For every u ∈ N we have



λ1
1
2
2
u =
f (u)u dx ≤
u dx + C1 |u|p dx ≤ u 2 + C2 u p ,
2
2




78

2

Minimization Techniques: Compact Problems

so that

u ≥

1
2C2

 1

p−2

,


which proves the claim.
Lemma 2.5.6 The functional I is coercive on N and m > 0.
Proof For every u ∈ N , by (f3 ), we have




1
1
1
1
2
2
2
−
u +
u − F (u) dx
I (u) = u − F (u) dx =
2
2 μ
μ









1
1
1
1
1
2
−
u +
f (u)u − F (u) dx ≥
−
u 2,
=
2 μ
2 μ
 μ
which shows that I is coercive on N and that

 2



1
1
1
1 p−2
1
−
u 2≥
−
> 0,
m = inf I (u) ≥ inf
μ
2 μ
2C2
u∈N
u∈N 2



by Lemma 2.5.5.
Lemma 2.5.7 There exists u ∈ N such that I (u) = m and u ≥ 0 a.e. in .

Proof Let {uk }k ⊂ N be a minimizing sequence for I . The fact that F (t) and f (t)t
are even implies that also {|uk |}k is a minimizing sequence, so that we can assume
from the beginning that uk (x) ≥ 0 a.e. in . Since I is coercive on N , the sequence
{uk }k is bounded and then, up to subsequences,
uk

u

in H01 (),

uk (x) → u(x)

uk → u in Lq () ∀q ∈ [2, 2∗ ),

a.e. in .

This shows that u(x) ≥ 0 a.e. and, with arguments already used many times,


F (uk ) dx →
F (u) dx,




f (uk )uk dx →
f (u)u dx,
u 2 ≤ lim inf uk 2 .
k→+∞

∗
Clearly the assumption p < 2 is essential in the first two limits.


Thus we deduce that



I (u) ≤ lim inf I (uk ) = m
k

u 2≤

and

f (u)u dx.



Now we notice that from uk 2 =  f (uk )uk dx we have

f (u)u dx = lim uk 2 .


k

2.5 Nonhomogeneous Nonlinearities

79

Since


uk 2 ≥

for all k we obtain

1
2C2

 2

p−2

>0


f (u)u dx > 0,


which shows that it cannot be u ≡ 0.
If u 2 =  f (u)u dx, then u ∈ N , u is the required minimum and the proof is
complete. It remains to show that

f (u)u dx
(2.42)
u 2<


leads to a contradiction.
To this aim, assume that (2.42) holds and consider the function

2
2
γ (t) = t u −
f (tu)tu dx.


We already know that γ (t) > 0 in a right neighborhood of 0. The inequality (2.42)
tells us that γ (1) < 0. Then there exists t ∗ ∈ (0, 1) such that γ (t ∗ ) = 0, which means
that t ∗ u ∈ N . We then obtain

1
∗
f (t ∗ u)t ∗ u − F (t ∗ u) dx.
m ≤ I (t u) =
2

From (f4 ) it is easy to see that the function
1
s → f (s)s − F (s)
2
is strictly increasing in (0, +∞), and then, since u ≥ 0 and t ∗ ∈ (0, 1), we see that


1
1
f (t ∗ u)t ∗ u − F (t ∗ u) dx <
f (u)u − F (u) dx
m≤
2
2



1
f (uk )uk − F (uk ) dx = lim I (uk ) = m.
= lim
k
k
2

This contradiction shows that (2.42) cannot hold and concludes the proof.



The last step consists in showing that u is a critical point for I .
Lemma 2.5.8 Let u ∈ N be such that I (u) = m. Then I  (u) = 0.
Proof For every v ∈ H01 () there exists ε > 0 such that u + sv ≡ 0 for all s in
(−ε, ε). We know that there exists t (s) ∈ R such that t (s)(u + sv) ∈ N . We now
deduce some properties of the function t (s). To this aim, consider the function

2
2
ϕ(s, t) = t u + sv −
f (t (u + sv))t (u + sv) dx,


80

2

Minimization Techniques: Compact Problems

defined for (s, t) ∈ (−ε, ε) × R. Since u ∈ N , we have

2
ϕ(0, 1) = u −
f (u)u dx = 0.


Moreover, by (f2 ) and (f4 ), ϕ is a C 1 function and



∂ϕ
2
(0, 1) = 2 u −
f (u)u dx −
f  (u)u2 dx
∂t





f (u)u − f  (u)u2 dx < 0.
=


Then, by the Implicit Function Theorem, for ε small there exists a C 1 function t (s)
such that ϕ(s, t (s)) = 0 and t (0) = 1. This also shows that t (s) = 0, at least for ε
very small. Therefore t (s)(u + sv) ∈ N .
Then setting
γ (s) = I (t (s)(u + sv)),
we have that γ is differentiable and has a minimum at s = 0; therefore
0 = γ  (0) = I  (t (0)u)(t  (0)u + t (0)v) = t  (0)I  (u)u + I  (u)v = I  (u)v.
Since v is arbitrary in H01 (), we deduce that I  (u) = 0.



Example 2.5.9 We list a couple of examples of nonlinearities that satisfy assumptions (f1 )–(f4 ). These are functions that behave “like powers” without being exact
powers. Since we want odd functions, we define them only for t > 0, and we extend
them by oddness.
(2, 2∗ ) and p = q.
• f (t) = t p−1 + t q−1 , with p, q ∈
pi −1 with a > 0 and p ∈ (2, 2∗ ).
• Slightly more generally, f (t) = M
i
i
i=1 ai t
q−1
t
∗
• f (t) = 1+t
q−p , with p ∈ (2, 2 ) and q > 2.
Remark 2.5.10 Let 2 < q < p < 2∗ ; the function
f (t) = t p−1 − t q−1

(2.43)

for t > 0 and extended by oddness to R, does not satisfy the assumptions (f3 )
and (f4 ). However if one repeats the arguments carried out in the previous lemmas, one see that they still work, with minor changes. Therefore Problem (2.39)
admits a solution also for this particular f . We now try to generalize this remark to
a wider class of nonlinearities that contains (2.43).
We consider the problem

−u + q(x)u = f (u) − g(u) in ,
(2.44)
u=0
on ∂.
t
We set G(t) = 0 g(s)ds and we introduce the following assumptions. Here
μ > 2, as in (f3 ).

2.5 Nonhomogeneous Nonlinearities

81

(g1 ) g : R → R is of class C 1 and is odd;
 (t)|
(g2 ) g  (0) = 0 and there exists θ ∈ (2, μ) such that lim supt→+∞ |gt θ−2
< +∞;

(g3 ) the inequalities g(t) ≥ 0 and g (t)t ≤ (μ − 1)g(t) hold for every t ∈ (0, +∞).
As far as f is concerned, we have to replace (f3 ) and (f4 ) with the stronger
assumption
(f5 ) the inequality f  (t)t ≥ (μ − 1)f (t) > 0 holds for every t ∈ (0, +∞).
We can now prove the following result.
Theorem 2.5.11 Assume that (h1 ), (f1 ), (f2 ), (f5 ) and (g1 )–(g3 ) hold. Then Problem (2.44) admits at least one nontrivial and nonnegative solution.
The proof follows exactly the same lines as the previous one. We start by noticing
that since (f5 ) implies (f3 ) and (f4 ), all the properties of the functions F (t) and f (t)t
obtained earlier are still valid. Concerning g and G, we list the properties that can
be obtained working as in Lemma 2.5.3.
Lemma 2.5.12 We have
(1) limt→0 G(t)
= 0.
t2
(2) There exist positive constants M5 , M6 such that
|g  (t)| ≤ M5 |t|θ−2

for |t| > M6 .

(3) There exist positive constants D1 , D2 such that
|G(t)| + |g(t)t| ≤ D1 t 2 + D2 |t|θ

∀t ∈ R.

(2.45)

Solutions of Problem (2.44) are critical points of the functional


1
2
I (u) = u −
F (u) dx +
G(u) dx
2


and the corresponding Nehari manifold is
N = {u ∈ H01 () | I  (u)u = 0, u = 0}



1
2
= u ∈ H0 () u =
f (u)u dx −
g(u)u dx, u = 0 .




The first step consist of course in checking that we can work in N .
Lemma 2.5.13 The Nehari manifold N is not empty.
Proof Repeating the argument of Lemma 2.5.4, we fix u ∈ H01 () with u ≡ 0 and
u ≥ 0, and we consider the function



2
2
γ (t) = I (tu)tu = t u −
f (tu)tu dx +
g(tu)tu dx.




82

2

We already know that

Minimization Techniques: Compact Problems


f (tu)tu dx = o(t 2 )


as t → 0, and the same ideas show that also

g(tu)tu dx = o(t 2 ),


so that
γ (t) = t 2 u 2 + o(t 2 )
as t → 0.
On the other hand, from the properties of g we deduce that for a suitable C > 0,

g(tu)tu dx ≤ Ct 2 + Ct θ = o(t μ ),


when t → +∞. From this and the proof of Lemma 2.5.4 we immediately obtain

γ (t) ≤ t 2 u 2 − Dt μ uμ dx + o(t μ )


as t → +∞. This proves the existence of t > 0 such that tu ∈ N . We conclude the
proof as in Lemma 2.5.4 when u has arbitrary sign.

Defining as usual
m = inf I (u),
u∈N

we proceed to prove that m is attained by a function that solves Problem (2.44).
Lemma 2.5.14 There results
inf u 2 > 0.

u∈N

Proof Working as in Lemma 2.5.5 and using the fact that g(u)u ≥ 0, we obtain for
every u ∈ N ,




1
u 2=
f (u)u dx −
g(u)u dx ≤ λ1 u2 dx + C1 |u|p dx
2




1
2
p
≤ u + C2 u ,
2
which allows us to conclude exactly as above.

Lemma 2.5.15 The functional I is coercive on N and m > 0.
Proof From (g3 ) we deduce that μG(u) ≥ g(u)u. Then, if u ∈ N , we have

2.5 Nonhomogeneous Nonlinearities

83





1
u 2−
F (u) dx +
G(u) dx
2







1
1
1
2
=
−
u +
f (u)u − F (u) dx
2 μ
 μ



 
1
1
1
−
u 2,
G(u) − g(u)u dx ≥
+
μ
2 μ


I (u) =



and we conclude as in Lemma 2.5.6.
We can now prove that the infimum of I on N is attained.
Lemma 2.5.16 There exists u ∈ N such that I (u) = m and u ≥ 0.

Proof Let {uk }k ⊂ N be a minimizing sequence for I . As above, we can assume
that uk ≥ 0. By Lemma 2.5.15, I is coercive on N , and hence {uk }k is bounded. Up
to subsequences,
uk

u

uk → u in Lq () ∀q ∈ [2, 2∗ ),

in H01 (),

uk (x) → u(x)

a.e. in .

Then u(x) ≥ 0, and with the usual arguments, as k → ∞,




F (uk ) dx →
F (u) dx,
f (uk )uk dx →
f (u)u dx,






G(uk ) dx →
G(u) dx,




g(uk )uk dx →
g(u)u dx,
u 2 ≤ lim inf uk 2 .


k→+∞



These yield immediately



I (u) ≤ lim inf I (uk ) = m

and

k

u 2≤


f (u)u dx −



g(u)u dx.


Since
f (u)u dx −


we obtain







g(u)u dx = lim uk 2 ≥
k





1
2C2


f (u)u dx −


g(u)u dx > 0,


which shows that it cannot be u ≡ 0.
Now, if


2
u =
f (u)u dx −
g(u)u dx,




 2

p−2

> 0,

84

2

Minimization Techniques: Compact Problems

then u ∈ N , and u is the required minimum. We must therefore show that it cannot
be


2
u <
f (u)u dx −
g(u)u dx.
(2.46)




To this aim, we consider the function


2
2
f (tu)tu dx +
g(tu)tu dx.
γ (t) = t u −




We have already noticed that γ (t) > 0 in a right neighborhood of zero. Assuming (2.46) means that γ (1) < 0, hence there exists t ∗ ∈ (0, 1) such that γ (t ∗ ) = 0,
namely t ∗ u ∈ N . Then we see that


1
m ≤ I (t ∗ u) = t ∗ u 2 −
F (t ∗ u) dx +
G(t ∗ u) dx
2





 
1
1
1
∗ 2
∗
∗
∗
−
t u +
f (t u)t u − F (t u) dx
=
2 μ
 μ

 
1
∗
∗
∗
G(t u) − g(t u)t u dx.
+
μ

From assumptions (f5 ) and (g3 ) we deduce immediately that the functions
s →

1
f (s)s − F (s)
μ

and s → G(s) −

1
g(s)s
μ

are nondecreasing in (0, +∞), so that being u ≥ 0 and t ∗ ∈ (0, 1), we have



 
1
1
1
−
t ∗u 2 +
f (t ∗ u)t ∗ u − F (t ∗ u) dx
m≤
2 μ
 μ

 
1
G(t ∗ u) − g(t ∗ u)t ∗ u dx
+
 μ




 
 
1
1
1
1
2
−
u +
f (u)u − F (u) dx +
G(u) − g(u)u dx
<
2 μ
 μ
 μ



1
1
1
≤ lim inf
−
uk 2 + lim
f (uk )uk − F (uk ) dx
k
k
2 μ
 μ

1
G(uk ) − g(uk )uk dx
+ lim
k
μ

= lim inf I (uk ) = m.
k

This contradiction shows that (2.46) cannot hold, and the proof is complete.
Lastly we prove that the minimizer u is a critical point of I on H01 ().
Lemma 2.5.17 Let u ∈ N be such that I (u) = m. Then I  (u) = 0.



2.5 Nonhomogeneous Nonlinearities

85

Proof The technique is the same as in Lemma 2.5.13. Take v ∈ H01 () and let ε > 0
be so small that u + sv = 0 for all s ∈ (−ε, ε). We know that there exists t (s) ∈ R
such that t (s)(u + sv) ∈ N . Consider the function

2
2
ϕ(s, t) = t u + sv −
f (t (u + sv))t (u + sv) dx


g(t (u + sv))t (u + sv) dx,
+


defined for (s, t) ∈ (−ε, ε) × R. Since u ∈ N , we have


2
ϕ(0, 1) = u −
f (u)u dx +
g(u)u dx = 0.




On the other hand, by (f5 ) and (g3 ),



∂ϕ
2

2
(0, 1) = 2 u −
f (u)u dx −
f (u)u dx +
g(u)u dx
∂t




+
g  (u)u2 dx




f (u)u dx − (μ − 1) f (u)u dx +
g(u)u dx
≤2 u 2−




+ (μ − 1) g(u)u dx


2
= 2 u − μ f (u)u dx + μ g(u)u dx = (2 − μ) u 2 < 0.




So, by the Implicit Function Theorem, for ε small enough we can determine a function t ∈ C 1 (−ε, ε) such that f (s, t (s)) = 0 and t (0) = 1. This says that t (s) = 0, at
least for ε very small, and then t (s)(u + sv) ∈ N .
Setting
γ (s) = I (t (s)(u + sv)),
we obtain that γ is differentiable and has a minimum point at s = 0; thus
0 = γ  (0) = I  (t (0)u)(t  (0)u + t (0)v) = t  (0)I  (u)u + I  (u)v = I  (u)v.
Since v ∈ H01 (), is arbitrary, we conclude that I  (u) = 0.



Example 2.5.18 Also in this case it is easy to produce examples of nonlinearities
that satisfy the assumption of Theorem 2.5.11. As usual we define the functions for
t > 0 and we extend them by oddness.
• f (t) = t p−1 , g(t) = t q−1 , where 2 < q < p < 2∗ .

N
pi −1 and g(t) =
qi −1 with
Slightly more generally, f (t) = M
i=1 ai t
i=1 bi t
∗
ai , bi > 0, pi , qi ∈ (2, 2 ) and min{pi } > max{qi }.
s q−1
∗
• f (t) = 1+s
q−p , where p ∈ (2, 2 ), q > 2 and g as in the preceding example, with
max{qi } < min{p, q}.

86

2

Minimization Techniques: Compact Problems

2.6 The p-Laplacian
In this section we leave temporarily the semilinear equations studied up to now to
give an example of how the techniques introduced so far can be successfully applied, and with almost no changes, to more general quasilinear equations. Although
quasilinear equations are in general much more difficult than semilinear ones, a certain number of results can be proved by the application of variational methods with
surprisingly little effort.
This section should be considered as an example and can be skipped on first
reading.
The particular type of equations we consider are the so-called p-Laplace equations, that are commonly seen as the simplest generalizations of the Laplacian to the
quasilinear context.
The p-Laplacian is the second order non linear differential operator defined as


p u = div |∇u|p−2 ∇u .
Here p > 1, and of course when p = 2 the p-Laplacian is the usual Laplacian.
Notice that this operator is linear in the second derivatives, but contains terms
which are nonlinear functions of the gradient of the unknown.
When u is regular enough an easy computation shows that
p u = |∇u|p−2 u + (p − 2)|∇u|p−4

n

i,j =1

∂ 2 u ∂u ∂u
,
∂xi ∂xj ∂xi ∂xj

a rather complicated expression. For this reason, it is much more convenient to use
some weak formulation for this operator. To write down such a weak form we need,
as in the previous chapters, to introduce suitable function spaces. We will list a
number of definitions and results that generalize those we have seen in Chap. 1 for
the Sobolev spaces H 1 () and H01 ().
• W 1,p (), for p ∈ [1, +∞), is the Sobolev space defined by

∂u
1,p
W () = u ∈ Lp ()
∈ Lp (), i = 1, . . . , N ,
∂xi
∂u
is in the sense of distributions. The spaces W 1,p () are
where the derivative ∂x
i
reflexive Banach spaces when endowed with the norm

u p = |u|p +

N

∂u
.
∂xi p
i=1

Recall that | · |p
1,p
• W0 () is the closure of C0∞ () in W 1,p ().
1,p
1,p
• If u ∈ W0 (), then |u|, u+ , u− ∈ W0 () and


p
∇|u| dx = |∇u|p dx.
is the Lp norm.





2.6 The p-Laplacian

87

We also recall, as in the previous chapters, some embedding theorems.
Theorem 2.6.1 Let  ⊂ RN be open, bounded and have smooth boundary. Let
p ≥ 1.
• If p < N , then W 1,p () → Lq () for every q ∈ [1, NNp
−p ]; the embedding is

compact for every q ∈ [1, NNp
−p ).
1,p
• If p = N , then W () → Lq () for every q ∈ [1, +∞); the embedding is
compact.
• If p > N , then W 1,p () → L∞ (); the embedding is compact.
The following particular case is the most used in our context, and we state it
separately.
Theorem 2.6.2 Let  be an open and bounded subset or RN , with N ≥ 3. Let
1 < p < N . Then
1,p

W0 () → Lq ()

for every q ∈ 1,

Np
.
N −p

The embedding is compact for every q ∈ [1, NNp
−p ).
∗
The number NNp
−p is denoted by p and is called the critical Sobolev exponent
1,p

for the embedding of W0 () into Lq .
1,p

Theorem 2.6.3 (Poincaré inequality for W0 ) Let  ⊂ RN be open and bounded.
Then there exists a constant C > 0, depending only on , such that


1,p
|u|p dx ≤ C |∇u|p dx ∀u ∈ W0 ().




1

1,p
Therefore, if  is a bounded open set, (  |∇u|p dx) p is a norm on W0 (),
equivalent to the standard one.

2.6.1 Basic Theory
1,p

We begin by studying the differentiability of some relevant functionals on W0 ().
We start with the norm.
Theorem 2.6.4 Let  ⊆ RN , N ≥ 3, be an open set. For p ∈ (1, +∞), define a
1,p
functional J : W0 () → R by

J (u) =
|∇u|p dx.


88

2

Minimization Techniques: Compact Problems

1,p

Then J is differentiable in W0 () and


J (u)v = p |∇u|p−2 ∇u · ∇v dx.


Proof Consider the function ϕ : RN → R, defined by ϕ(x) = |x|p . It is a C 1 function and ∇ϕ(x) = p|x|p−2 x, so that, for all x, y ∈ RN ,
ϕ(x + ty) − ϕ(x)
= p|x|p−2 x · y.
t→0
t
lim

As a consequence,
|∇u(x) + t∇v(x)|p − |∇u(x)|p
= p|∇u(x)|p−2 ∇u(x) · ∇v(x) a.e. in .
t→0
t
By the Lagrange Theorem there exists θ ∈ R such that |θ | ≤ |t| and
lim

|∇u + t∇v|p − |∇u|p
≤ p |∇u + θ ∇v|p−2 (∇u + θ ∇v) · ∇v
t


≤ C |∇u|p−1 |∇v| + |∇v|p ∈ L1 ().
By dominated convergence we obtain


|∇u + t∇v|p − |∇u|p
dx = p |∇u|p−2 ∇u · ∇v dx,
lim
t→0 
t

so that J is Gâteaux differentiable and

JG (u)v = p |∇u|p−2 ∇u · ∇v dx.


1,p
We have now to prove that JG : W0 () → [W 1,p ()] is continuous. To this aim
1,p
1,p
we take a sequence {uk }k in W0 () such that uk → u in W0 (). In particular

we can assume, as usual, that up to subsequences,

• ∇uk → ∇u in (Lp ())N as k → ∞;
• ∇uk (x) → ∇u(x) a.e. as k → ∞;
• there exists w ∈ L1 () such that |∇uk (x)|p ≤ w(x) a.e. in , and for all k ∈ N.
We have
(JG (u) − JG (uk ))v = p
and


(|∇u|p−2 ∇u − |∇uk |p−2 ∇uk ) · ∇v dx



(|∇u|p−2 ∇u − |∇uk |p−2 ∇uk ) · ∇v dx




≤

|∇uk |

p−2

∇uk − |∇u|

p−2

∇u

p
p−1

 p−1 
p





|∇uk |p−2 ∇uk − |∇u|p−2 ∇u

≤


p
p−1

 p−1



p

dx

1/p
|∇v|p dx

dx
v ,

2.6 The p-Laplacian

89

so that


JG (u) − JG (uk ) = sup (JG (u) − JG (uk ))v v ∈ W 1,p (), v = 1

 p−1
p
p
≤
.
|∇uk |p−2 ∇uk − |∇u|p−2 ∇u p−1 dx


Now we know that
|∇uk (x)|p−2 ∇uk (x) → |∇u(x)|p−2 ∇u(x)
almost everywhere in , and that
p

|∇uk |p−2 ∇uk − |∇u|p−2 ∇u p−1 ≤ C(|∇uk |p + |∇u|p ) ≤ w + |∇u|p ∈ L1 ().
By dominated convergence we then obtain

p
|∇uk |p−2 ∇uk − |∇u|p−2 ∇u p−1 dx → 0,


and hence JG (uk ) − JG (u) → 0. This holds for a subsequence of the original
sequence {uk }, but we can argue as before to obtain that JG is a continuous function,
so that J is differentiable with differential given by


(u)v
=
p
|∇u|p−2 ∇u · ∇v dx.
J



1,p
Remark 2.6.5 When p = 2, W0 () is not a Hilbert space. So here is an example

of a Banach space where the norm is differentiable, see Remark 1.3.15.
Theorem 2.6.6 Let  ⊂ RN , N ≥ 3, be a bounded open set. Take a number
1 < p < N and let p ∗ = NNp
−p be the critical exponent for the embedding of
1,p

W0 () in Lq (). Let f : R → R be a continuous function, and assume that there
exist a, b > 0 such that
∗

|f (t)| ≤ a + b|t|p −1
for all t ∈ R. Define
F (t) =

(2.47)

 t
f (s) ds
0

1,p

and consider the functional J : W0 () → R given by

J (u) =
F (u(x)) dx.

1,p
Then J is differentiable on W0 () and




J (u)v =

f (u(x))v(x) dx


1,p

for all u, v ∈ W0 ().

90

2

Minimization Techniques: Compact Problems

We do not write down the proof of this result, because the argument is very
similar to the one of Example 1.3.20.
We can now state a definition of weak solution for equations involving the pLaplacian. The idea for a weak formulation can be obtained, as in the usual case
p = 2, using integration by parts. Let us assume that u and v are functions defined
on a bounded open set , that they vanish on ∂, and are smooth enough for the
following computations to make sense. Integrating by parts we obtain





v p u dx =
v div |∇u|p−2 ∇u dx = − |∇u|p−2 ∇u · ∇v dx.






This suggests that a good candidate as a weak form for the p-Laplacian is the operator

v → − |∇u|p−2 ∇u · ∇v dx.


We now give a precise formulation to the preceding heuristic discussion, at least for

the cases that we want to treat. Let us consider 1 < p < N and take h ∈ Lp , where
p
p  = p−1 is the conjugate exponent of p. Let f : R → R be a continuous function
satisfying the growth assumption (2.47). We will say that u is a weak solution of the
boundary value problem

−p u = f (u) + h in ,
(2.48)
u=0
on ∂
1,p

if u ∈ W0 () and



|∇u|p−2 ∇u · ∇v dx = f (u)v dx + hv dx






1,p

∀v ∈ W0 ().

Notice that, as in the case of the Laplacian, the boundary conditions are englobed
1,p
in the function space W0 (). Thanks to the previous results about differentiation
of functionals, it is easy to spot the link between weak solutions and critical points.
t
1,p
Indeed, denoting F (t) = 0 f (s) ds, we can define a functional J : W0 () → R
by



J (u) =
|∇u|p dx − F (u) dx − hu dx.



1,p
We know that J is differentiable on W0 (), with

J  (u)v =







|∇u|p−2 ∇u · ∇v dx −




f (u)v dx −


hv dx.


Hence, a critical point of J is exactly a weak solution of (2.48) in the sense previously stated.
Remark 2.6.7 The procedure to obtain a classical solution from a weak one is more
problematic in the case of quasilinear equations. Indeed, a weak solution which
is regular enough is also a classical solution, but the regularity results for weak
solutions of p-Laplacian equations that have been obtained so far are not completely
satisfactory: weak solution may be not regular enough to be also classical solutions.

2.6 The p-Laplacian

91

We conclude with a simple existence result for equations with right-hand-side
independent of u.
p
be
Theorem 2.6.8 Let  ⊂ RN be a bounded open set and let p > 1. Let p  = p−1


the conjugate exponent of p. Then, for every h ∈ Lp (), the problem

−p u = h in ,
u=0
on ∂

(2.49)

has a unique (weak) solution.
1,p

Proof Define a functional J : W0 () → R by


1
p
J (u) =
|∇u| dx − hu dx.
p 

1,p

We know that J is differentiable on W0 () with


|∇u|p−2 ∇u · ∇v dx − hv dx.
J  (u)v =




It is well known that the function x → |x|p , x ∈ RN , is strictly convex. From this, it
is easy to deduce that J is strictly convex. Moreover,
J (u) ≥

1
1
u p − |h|p |u|p ≥
u p −C u ,
p
p

so that J is coercive because p > 1. Applying Theorems 1.5.6 and 1.5.8, we find
that J has a unique critical point which is the unique (weak) solution of Problem
(2.49).

Remark 2.6.9 Notice that the previous theorem holds for any p > 1.
Remark 2.6.10 In Sect. 1.6 we have seen similar results. In that case we dealt with
linear equations, and it is well known that they can be solved by different methods,
for example by a straightforward application of the Riesz Theorem 1.2.9. On the
contrary, (2.49), being quasilinear, cannot be treated by the standard methods of the
linear theory, available for example for (1.22) and (1.23). Variational methods give
an unified treatment for linear and nonlinear problems.

2.6.2 Two Applications
We start with a nonlinear eigenvalue problem. Indeed, it is possible to generalize part
of the theory and of the results concerning linear eigenvalue problems to nonlinear
problems. Nonlinear eigenvalue problems are a largely studied subject in recent
research. For some references on these topics, start for example from [20].

1,p
Recall that in the Banach space W0 () we use the norm u p =  |∇u|p dx.

92

2

Minimization Techniques: Compact Problems

Theorem 2.6.11 Let  ⊂ RN , N ≥ 3, be a bounded open set and let 1 < p < N .
Define

|∇u|p dx
u p

=
inf
μ=
inf
p .
p
1,p
1,p
u∈W0 ()\{0}  |u| dx
u∈W0 ()\{0} |u|p
1,p

Then μ is positive and is achieved by some u ∈ W0 () \ {0}. The function u can
be chosen nonnegative and satisfies (weakly)



− div |∇u|p−2 ∇u = μup−1 in ,
(2.50)
u=0
on ∂.
1,p

p

Proof For u ∈ W0 (), set I (u) = u p , J (u) = |u|p and define the quotient func1,p
tional Q : W0 ()\{0} → R as
I (u)
.
Q(u) =
J (u)
Then
μ=

inf

1,p

Q(u).

u∈W0 ()\{0}

The Poincaré inequality immediately gives μ > 0. Let {uk }k be a minimizing sequence. Clearly |uk | is also a minimizing sequence for Q, so we can assume that
uk (x) ≥ 0 a.e. in . As the functional Q is homogeneous of degree zero, i.e.
Q(λu) = Q(u) for every λ ∈ R, we can normalize uk by setting |uk |p = 1 for every k. Then we see that J (uk ), namely the W 1,p norm of uk , must be bounded
independently of k.
By the Sobolev embeddings (Theorem 2.6.2), we deduce that, up to subsequences,
u in W 1,p ();
• uk
• uk → u in Lp ();
• uk (x) → u(x) a.e. in ;
In particular, J (u) = 1 and u(x) ≥ 0 a.e. Then, by weak lower semicontinuity of the
norm,
Q(u) = I (u) ≤ lim inf I (uk ) = lim inf Q(uk ) = μ,
k

k

1,p
so u ∈ W0 ()\{0} and Q(u) = μ.

We have seen in the preceding subsection that I and J are differentiable. Then
so is Q, and

1  
I (u)v − Q(u)J  (u)v .
Q (u)v =
J (u)
Since u is a minimum point for Q, we obtain Q (u) = 0 and therefore
I  (u)v = Q(u)J  (u)v = μJ  (u)v
1,p

for every v ∈ W0 (), which is nothing but the weak form of (2.50).



2.7 Exercises

93

We give a last result, concerning existence of a minimum for a coercive functional involving the p-Laplacian. This result generalizes Theorem 2.1.5.
Theorem 2.6.12 Let  be an open bounded subset of RN , N ≥ 3, and let
1 < p < N . Let f : R → R be a continuous function such that
|f (t)| ≤ a + b|t|q−1

∀t ∈ R,


p
, there
where a, b > 0 and 1 ≤ q < p. Then, for all h ∈ Lp (), where p  = p−1
exists a weak solution of the problem

− div(|∇u|p−2 ∇u) = f (u) + h(x) in ,
(2.51)
u=0
on ∂.
1,p

Proof We consider the functional I : W0 () → R defined by



1
I (u) =
|∇u|p dx −
F (u) dx −
hu dx
p 




1
u p−
=
F (u) dx −
hu dx,
p


t
where as usual F (t) = 0 f (s) ds. The hypotheses on f immediately imply that
F (t) ≤ a1 + b1 |t|q , and therefore, by the Hölder and Sobolev inequalities,
I (u) ≥



1
q
u p − C1 − C2 |u|q − C3 |h|p |u|p ≥ C u p − u q − u − 1 ,
p

which shows that I is coercive because q < p. Thus, any minimizing sequence uk
1,p
for I is bounded in W0 (). Then we can extract a subsequence, still denoted
1,p
uk , that converges weakly to some u ∈ W0 (); by compactness of the Sobolev
embedding, we can make sure that it also converges strongly in Lq (). Weak lower
semicontinuity of the norm and the usual arguments show that the weak limit u is a
minimum point for I . This gives I  (u) = 0, which is the weak form of (2.51).


2.7 Exercises
1. Let X be a complete normed space, and let a : X × X → R be a continuous
bilinear form. Let φ : X → R be the associated quadratic form, φ(u) = a(u, u).
Consider the following statements.
(a) ∀u = 0, φ(u) > 0.
(b) lim u →∞ φ(u) = +∞.
(c) There exists α > 0 such that for every u ∈ X, φ(u) ≥ α u 2 .
Prove that if X has finite dimension, then (a), (b) and (c) are equivalent. Prove
that if X is infinite dimensional, then (c) ⇐⇒ (b) ⇒ (a), but (a) needs not
imply (b) or (c).

94

2

Minimization Techniques: Compact Problems

2. Let A be an N × N symmetric matrix. Prove that A has at least one eigenvalue
by maximizing the function φ : RN → R defined by φ(x) = Ax · x constrained
on the unit sphere of RN .
3. Let f : R → R be continuous and satisfy f (t) = 0 if t ≤ 0. Assume that
t →

f (t)
is strictly decreasing on (0, +∞)
t

f (t)
and denote α = limt→0+ f (t)
t and β = limt→+∞ t .
N
Let  ⊂ R be a bounded open set. Prove that if the problem
⎧
⎨ −u = f (u) in ,
u>0
in ,
⎩
u=0
on ∂

has a solution, then α > λ1 and β < λ1 . Hint: multiply the equation by ϕ1 .
4. Let  ⊂ RN , with N ≥ 3, be open and bounded, h ∈ L∞ ()\{0} and
2 < p < 2∗ , and consider the problem

−u = h(x)|u|p−2 u in ,
u=0
on ∂.
(a) Prove that if h(x) ≤ 0 a.e. in , the problem has no nontrivial solutions.
(b) If h(x) > 0 on a set of positive measure, prove that the problem has at least
one nontrivial solution. Hint: consider the set


M = u ∈ H01 ()
h(x)|u|p dx = 1 ,


prove that M = ∅ and argue as in Sect. 2.3.1.
5. Let  ⊂ RN , with N ≥ 3, be open and bounded, and let a ∈ L∞ () satisfy
a(x) > 0 a.e. in . Take p ∈ (2, 2∗ ). Assume that the differentiable functional
Q : H01 () \ {0} → R defined by

|∇u|2 dx
Q(u) =  
(  a(x)|u|p dx)2/p
has a critical point v. Show that a multiple of v is a weak solution of the problem

−u = a(x)|u|p−2 u in ,
u=0
on ∂.
Hint: recall Example 1.3.16.
6. Let  ⊂ RN , with N ≥ 3, be open and bounded, let a, b ∈ C()\{0} and let
2 < p < q < 2∗ . Assume that b ≥ 0 in  and that for a.e. x, a(x) = 0 implies
b(x) = 0. Consider the problem

−u = a(x)|u|p−2 u + b(x)|u|q−2 u in ,
(2.52)
u=0
on ∂.
(a) Write down an energy functional I such that I  (u) = 0 if and only if u is a
weak solution for this problem.

2.8 Bibliographical Notes

95

(b) Prove that the set


1

N = u ∈ H0 () I (u)u = 0, b(x)|u|q dx > 0


is not empty.
(c) Prove that there exists a minimum point u for I on N such that u ≥ 0.
(d) Prove that the minimum is a weak solution of (2.52).
7. Let  ⊂ RN , with N ≥ 3, be open and bounded, and take numbers r, p such
that 1 < r < 2 < p < 2∗ . Consider the problem

−u = |u|p−2 u − |u|r−2 u in ,
u=0
on ∂.
Define the energy functional and the Nehari manifold for this problem, and
prove the existence of a non trivial solution via minimization on the Nehari
manifold.
8. Let  be an open and bounded subset of RN , with N ≥ 3. Take p ∈ (2, 2∗ ] and
define

2
 |∇u| dx

Sp = inf
p
2/p
u∈H01 () (  |u| dx)
u=0

This number is positive by the Sobolev embedding Theorem 1.2.1. Consider the
functional I : H01 () → R defined by


1
1
2
|∇u| dx −
|u|p dx
I (u) =
2 
p 
and let N be the Nehari manifold associated to I . Prove that
 p

1 1
−
Spp−2 .
inf I (u) =
2 p
u∈N
9. Prove Theorem 2.6.6 by modifying the argument of Example 1.3.20.
10. Let  ⊂ RN , with N ≥ 3, be open and bounded, and let 1 < p < N and p <
r < q < p ∗ . Consider the p-Laplacian problem

−p u = |u|r−2 u + |u|q−2 u in ,
u=0
on ∂.
Define the energy functional and the Nehari manifold for this problem, and
prove the existence of a non trivial solution via minimization on the Nehari
manifold.

2.8 Bibliographical Notes
• Section 2.1: The techniques presented in this section apply to much more general
cases, for instance to quasilinear problems. The direct methods of the Calculus of

96

2

Minimization Techniques: Compact Problems

Variations, built upon the two notions of coercivity and weak lower semicontinuity have been developed enormously and allow one to deal with general functionals depending on x, u and ∇u. See Chap. I.1 in Struwe [45], or Giusti [21] for a
vast description of these problems.
• Section 2.2: The abstract structure behind it is a particular case of the Ky Fan–Von
Neumann Theorem. The content of the section is a simplified version of a result
from Kavian [26]. Min–maximization under convexity and concavity assumptions is one of central themes of convex analysis. A comprehensive treatment of
it, with applications to differential problems, can be found in the book [19] by
Ekeland and Temam.
• Section 2.3: The failure of the direct method (minimization) for problems with
superlinear growth due to the fact that the functionals are not bounded from below led to the idea of constraints. Some problems in mechanics and geometry
were the main motivations for the introduction of artificial constraints. The Nehari manifold was introduced in Nehari [36] in the context of ordinary differential
equations. A modern review on superlinear Dirichlet problems is Bartsch, Wang,
and Willem [8].
• Section 2.4: The question whether “perturbations” can destroy existence results
has been widely analyzed in the last few years, especially when the unperturbed
problem possesses infinitely many solutions (as is the case for odd nonlinearities).
The interested reader can read Rabinowitz [43], or Chap. II.7 of Struwe [45] and
the references therein. The reading however requires more sophisticated techniques than those described in these notes.
• Section 2.5: The method of minimization on the Nehari manifold is particularly
useful for nonhomogeneous nonlinearities, for which minimization on spheres
does not apply. A rather detailed exposition can be found in the books by
Willem [48], and Kuzin–Pohožaev [27]; the applications given in [27] however
concern problems on unbounded domains, which we treat in Chap. 3.
• Section 2.6: There is by now a vast literature on problems involving the
p-Laplacian. A good starting point is Garcia Azorero and Peral [20]. A systematic treatment of many questions concerning the p-Laplacian can be found in
the book by Lindqvist [30].

Chapter 3

Minimization Techniques: Lack of Compactness

In this chapter we present some examples of problems where compactness is not
guaranteed a priori. The lack of compactness can take different forms, but in the
simplest case, it is manifest through the fact that minimizing sequences are maybe
bounded, but not (pre-)compact in the function spaces where the problem is set.
The reasons for this often come from geometrical or physical aspects of the problem, and we refer for example to [45] for a discussion on this point of view.
Here we confine ourselves to some more or less simple examples of problems
with lack of compactness and we try to show some ways to overcome the obstacle.
As in Chap. 2, we will study equations with different hypotheses on the nonlinearity f . In particular when dealing with critical problems (Sect. 3.4) we will study
∗
the homogeneous nonlinearity f (t) = |t|2 −2 t through minimization on spheres (as
in Sect. 2.3.1), while in the first part of this section we will study a nonhomogeneous
nonlinearity, applying the method of minimization on the Nehari manifold. In principle we could treat a generic f satisfying a set of hypotheses including (f1 )–(f4 ),
but for the sake of simplicity we will deal with the specific and simple nonhomogeneous nonlinearity given by
f (t) = |t|p−2 t + λ|t|r−2 t
with 2 < r < p < 2∗ and λ ∈ R (for λ = 0 this includes the homogeneous case).

3.1 A Radial Problem in RN
A first case of lack of compactness takes place when one works in unbounded open
sets. For simplicity we treat the case where  = RN , with N ≥ 3, by studying the
following problem:

−u + αu = |u|p−2 u + λ|u|r−2 u in RN ,
(3.1)
u ∈ H 1 (RN )
where α > 0, λ ∈ R, p, r ∈ (2, 2∗ ) and p > r.
M. Badiale, E. Serra, Semilinear Elliptic Equations for Beginners, Universitext,
DOI 10.1007/978-0-85729-227-8_3, © Springer-Verlag London Limited 2011

97

98

3

Minimization Techniques: Lack of Compactness

A weak solution of (3.1) is a function u ∈ H 1 (RN ) such that


∇u · ∇v dx + α
uv dx
RN
RN


=
|u|p−2 uv dx + λ
|u|r−2 uv dx ∀v ∈ H 1 (RN ).
RN

RN

Remark 3.1.1 The condition u ∈ H 1 (RN ) is a typical way to replace the boundary
conditions on RN . Indeed, it can be viewed as a weak form of the requirement
u(x) → 0 for |x| → ∞, a natural condition to associate to the equation in many
cases. Notice however that u ∈ H 1 (RN ) does not imply that u vanishes at infinity.
Often the condition u ∈ H 1 (RN ) and the fact that u solves the equation imply that
u(x) → 0 at infinity, but this has to be proved in each case.
A problem like (3.1) is not compact. Without supplying irrelevant details, imagine that it has a solution u ≡ 0 which minimizes some functional. Since the problem is invariant under translations, it is clear that for every y ∈ RN , the sequence
uk (x) = u(x + ky) is a bounded (in H 1 (RN ), for instance) minimizing sequence
which cannot be precompact in any Lp (RN ). Thus, roughly speaking, the problem
admits bounded minimizing sequences that do not converge. The reason for this is
the invariance of RN with respect to translations, which in turn makes the embedding of H 1 (RN ) into Lp (RN ) not compact for any p.
A natural attempt to overcome this problem is to guess that translational invariance is the only reason for the failure of compactness, and to try to work in a space
of functions where translations are not allowed. This is possible in this case because
the problem is also invariant under rotations, so that one can try to work in spaces
of radial functions. Let us make this precise.
We define
Dr = {u ∈ D 1,2 (RN ) | u is radial}
and
Hr = {u ∈ H 1 (RN ) | u is radial};
clearly Hr ⊂ Dr ; see Sect. 1.2.1 for the definition of D 1,2 (RN ). Also notice that
by classical results (see [11]), functions in Dr and in Hr can be assumed to be
continuous at all points except the origin.
We prove the following lemma, which gives a pointwise estimate for functions
in Dr . The argument for its proof is a slight modification of a result in [37].
Lemma 3.1.2 There exists a constant C > 0 such that for every u ∈ Dr ,
|u(x)| ≤ C

u
N−2

|x| 2

for every x = 0.

Proof Using a density argument, it is enough to prove the inequality for functions
u ∈ C0∞ (RN ) ∩ Dr .

3.1 A Radial Problem in RN

99

Let ϕ : [0, +∞[ → R be defined by
ϕ(r) = u(x)

if r = |x|.

Then ϕ is C ∞ and has compact support in [0, +∞).
We now estimate, for x = 0,
 +∞
 +∞
 +∞
N−1
|u(x)| = |ϕ(r)| =
ϕ  (s) ds ≤
|ϕ  (s)| ds =
|ϕ  (s)|s 2
≤

  +∞

r


r

2 N −1

|ϕ (s)| s

1/2   +∞
ds

r

=

  +∞
ω
|ϕ  (s)|2 s N −1 ds
1/2

1
ω

=C

N−2

|x| 2

s

ds

s 1−N ds

r
1/2

√

r

u

r
1/2

1
N−1
2

1

1

N − 2 r N−2
2

,

where ω is the measure of the unit sphere in RN .



Remark 3.1.3 For functions u ∈ Hr the following stronger decay estimate can be
proved
|u(x)| ≤ C

u
N−1

|x| 2

for every |x| ≥ 1,

see for example [2]. We won’t need this stronger form.
We now prove that the heuristic idea that translations are the only obstruction to
compactness is correct. The Sobolev inequalities on RN (Theorem 1.2.2) show that
Hr is continuously embedded into Lp (RN ), for p ∈ [2, 2∗ ]. The following lemma
proves that this embedding is compact if p ∈ (2, 2∗ ).
Lemma 3.1.4 Let p ∈ (2, 2∗ ). Then the embedding of Hr into Lp (RN ) is compact.
Proof It is enough to show that if {uk }k is a sequence in Hr such that uk
uk → 0 in Lp (RN ). Of course we can assume
p

uk → 0 in Lloc (RN )

0, then

and uk (x) → 0 a.e.

Let B = {x ∈ RN | |x| < 1} be the unit ball of RN , and let B c = RN \B. By what we
have just said, as k → ∞,




p
p
p
|uk | dx = |uk | dx +
|uk | dx =
|uk |p dx + o(1).
RN

B
Bc
Bc
∗
c
Let us fix q > 2 . By Lemma 3.1.2, in B we have, for some appropriate constant

C > 0,
|uk (x)|q ≤

C
q N−2
2

|x|

,

100

3

Minimization Techniques: Lack of Compactness

and q N 2−2 > N . This shows that
1
q N−2
2

|x|

∈ L1 (B c ),

and then, by dominated convergence,

|uk (x)|q dx → 0.
Bc

Let now t ∈ (0, 1) be such that p = 2t + q(1 − t); by the Hölder inequality we can
write

t 
1−t


|uk |p dx =
|uk |2t |uk |q(1−t) dx ≤
|uk |2 dx
|uk |q dx
.
Bc

Bc

Bc



Since the sequence
{ B c |uk |2 dx}k is bounded and

p
ately obtain B c |uk | dx → 0, so that

|uk |p dx → 0.



Bc

q
B c |uk | dx → 0, we immedi-

RN



Having established the main functional properties of the space Hr , we need a way
to pass from functions in H 1 (RN ) to functions in Hr . A way to do this, suitable for
our purposes, is given by a procedure called Schwarz symmetrization. We can not
give here an introduction to the theory of symmetrization, for which the reader can
see [29]. We just describe roughly the idea for nonnegative functions and state the
result that we will need in this section.
Let u ∈ D 1,2 (RN ) be such that u(x) ≥ 0 a.e. in RN . We denote, for t > 0,
{u > t} = {x ∈ RN | u(x) > t} and μ(t) = |{u > t}|.
∗

Notice that since u ∈ L2 (RN ), we have μ(t) < +∞ for all t > 0. The Schwarz
symmetrization constructs a radial function u∗ : RN → R such that
{u∗ > t} = Bρ(t)

with |Bρ(t) | = μ(t).

Thus, the sets where u and u∗ are greater than t have the same measure. It is easy
to see that u∗ is (radially) nonincreasing. The most important properties of u∗ are
stated in the following result.
Theorem 3.1.5 For every u ∈ D 1,2 (RN ), u ≥ 0, there results u∗ ∈ Dr , u∗ ≥ 0,


|∇u∗ |2 dx ≤
|∇u|2 dx and
RN
RN


∗ p
|u | dx =
|u|p dx, for all p > 1.
RN

RN

These properties imply of course that if u ∈ H 1 (RN ) then u∗ ∈ Hr .
We can now state and prove the main result of this section.

3.1 A Radial Problem in RN

101

Theorem 3.1.6 Problem (3.1) admits at least one nontrivial nonnegative solution.
This result will be obtained by a sequence of lemmas, and the scheme of the
argument is the same as that we have used in the compact case.
We equip H 1 (RN ) with the norm


2
2
u =
|∇u| dx + α
|u|2 dx
RN

RN

and we look for a solution as a minimizer of the associated functional constrained
on the Nehari manifold. So we define the functional I : H 1 (RN ) → R as




1
α
1
λ
2
2
p
I (u) =
|∇u| dx +
u dx −
|u| dx −
|u|r dx
2 RN
2 RN
p RN
r RN
1 p
λ
1
= u 2 − |u|p − |u|rr
2
p
r
and the Nehari Manifold


N = u ∈ H 1 (RN ) | u = 0, I  (u)u = 0


p
= u ∈ H 1 (RN ) u = 0, u 2 = |u|p + λ|u|rr .
Notice that, if u ∈ N , then
I (u) =



1 1
−
2 r




1 1
p
−
|u|p .
+
r
p


u

2

As 2 < r < p, we have I (u) > ( 12 − 1r ) u 2 > 0 for all u ∈ N .
Lemma 3.1.7 The Nehari manifold is not empty.
Proof We fix u ∈ H 1 (RN ), with u = 0, and for t ∈ R we define the function
γ (t) = I  (tu)tu = t 2 u 2 − t p |u|p − λt r |u|rr .
p

It is then obvious that γ (t) > 0 for small t > 0 and that limt→+∞ γ (t) = −∞; hence
there exists t > 0 such that I  (tu)tu = 0, so that tu ∈ N .

We define
m = inf I (u)
u∈N

and we try to show that m is attained by some u ∈ N .
Lemma 3.1.8 There results m > 0.
Proof If λ = 0, the nonlinearity is homogeneous and the argument is the same as
that of the compact case (Sect. 2.3.2). If λ = 0 and u ∈ N , then


p
u 2 = |u|p + λ|u|rr ≤ C u p + u r ,

102

3

namely

Minimization Techniques: Lack of Compactness



1 ≤ C u p−2 + u r−2 .

If u ≤ 1 this implies 1 ≤ 2C u r−2 .
So we have obtained, for all u ∈ N ,


1 
u ≥ min 1, (2C)− r−2 .

Therefore, if u ∈ N we have





1 2
1 1
1 1
2
−
−
I (u) >
u ≥
min 1, (2C)− r−2 ,
2 r
2 r


and the lemma is proved.
Lemma 3.1.9 There exists u ∈ N such that I (u) = m.

Proof We first show that we can take a minimizing sequence for m in N ∩ Hr . To
this aim, let {vk }k ⊆ N be a minimizing sequence. As usual we can assume vk ≥ 0.
Let wk = vk∗ ∈ Hr be the non negative radial function given by Theorem 3.1.5. We
have




wk 2 =
|∇vk∗ |2 dx + α
|vk∗ |2 dx ≤
|∇vk |2 dx + α
|vk |2 dx
N
N
N
N
R
 R
 R
 R
p
r
∗ p
=
|vk | dx + λ
|vk | dx =
|vk | dx + λ
|vk∗ |r dx
RN
RN
RN
RN


p
=
|wk | dx + λ
|wk |r dx.
RN

RN

Hence if we set
γ (t) = I  (twk )twk = t 2 wk 2 − t p |wk |p − λ|wk |rr ,
p

we have γ (1) ≤ 0, while γ (t) > 0 for t positive and small. Therefore there exists
tk ∈ (0, 1] such that γ (tk ) = 0, that is, tk wk ∈ N . We obtain
m ≤ I (tk wk )




1
1
p 1
p
2 1
2
−
wk + tk
−
|wk |p
= tk
2 r
r
p




1 1
1 1
p
2
−
wk +
−
|wk |p
≤
2 r
r
p




1 1
1 1
p
2
−
vk +
−
|vk |p = I (vk ).
≤
2 r
r
p
This implies that {tk wk }k is a minimizing sequence for m and tk wk ∈ Hr , as we had
claimed. In the sequel we set uk = tk wk . Of course, uk ≥ 0, and we can assume that,
up to subsequences, uk
u in H 1 (RN ). By Lemma 3.1.4 we obtain
uk → u in Lp (RN ) and in Lr (RN )

3.1 A Radial Problem in RN

103

and, again up to subsequences, uk (x) → u(x) almost everywhere, so that u(x) ≥ 0
a.e. and u ∈ Hr . We now prove that the weak limit u belongs to N and I (u) = m.
Let us first check that u ∈ N . We have
p

0 < C ≤ uk 2 = |uk |p + λ|uk |rr

(3.2)

and hence, passing to the limit,
p

0 < C ≤ |u|p + λ|u|rr ;
this implies u = 0. Still from (3.2), we also get
p

u 2 ≤ |u|p + λ|u|rr .
If
p

u 2 = |u|p + λ|u|rr ,
then u ∈ N . So, arguing by contradiction, we assume that
p

u 2 < |u|p + λ|u|rr .
Defining as above, for t > 0,
γ (t) = I  (tu)tu = t 2 u 2 − t p |u|p − λt r |u|rr ,
p

we see that γ (t) > 0 for small t > 0 while
p

γ (1) = u 2 − |u|p − λ|u|rr < 0.
So there is t ∈ (0, 1) such that tu ∈ N . Hence,




1 1
1 1
p
2
0 < m ≤ I (tu) =
−
tu +
−
|tu|p
2 r
r
p




1
1
p
2 1
2
p 1
=t
−
u +t
−
|u|p
2 r
r
p




1 1
1 1
p
2
−
u +
−
|u|p
<
2 r
r
p




1 1
1 1
p
2
−
uk + lim
−
|uk |p
≤ lim inf
k
k
2 r
r
p





1 1
1
1
p
2
−
uk +
−
|uk |p = lim inf I (uk ) = m.
= lim inf
k
k
2 r
r
p
p

This contradiction proves that u 2 = |u|p + λ|u|rr , and therefore u ∈ N . By the
weak lower semicontinuity of the norm it is straightforward to deduce that I (u) ≤

lim infk I (uk ) = m, and the lemma is proved.
Lemma 3.1.10 The minimum u is a critical point for I in H 1 (RN ).
Proof Fix v ∈ H 1 (RN ) and ε > 0 such that u + sv = 0 for all s ∈ (−ε, ε). Define a
function ϕ : (−ε, ε) × (0, +∞) → R by
ϕ(s, t) = I  (t (u + sv))t (u + sv) = t 2 u + sv 2 − t p |u + sv|p − λt r |u + sv|rr .
p

104

3

Minimization Techniques: Lack of Compactness

p

Then ϕ(0, 1) = u2 − |u|p − λ|u|rr = 0 and
∂ϕ
p
p
(0, 1) = 2 u 2 − p|u|p − rλ|u|rr = (2 − r) u 2 + (r − p)|u|p < 0.
∂t
So, by the Implicit Function Theorem there exists a C 1 function t : (−ε0 , ε0 ) → R
such that t (0) = 1 and
ϕ(s, t (s)) = 0
for all s ∈ (−ε0 , ε0 ). Defining
γ (s) = I (t (s)(u + sv)),
we see that the function γ is differentiable and has a minimum point at s = 0;
therefore
0 = γ  (0) = I  (t (0)u)(t  (0)u + t (0)v) = I  (u)v.
Since this holds for all v ∈ H 1 (RN ), we have I  (u) = 0.



Remark 3.1.11 In view of Lemma 3.1.2, the radial solution u found above does
indeed satisfy u(x) → 0 as |x| → ∞.

3.2 A Problem with Unbounded Potential
In this section we study a variant of problem (3.1), where the constant α is replaced
by a function q(x) (the potential in the physical literature).
Precisely, we consider the problem

−u + q(x)u = |u|p−2 u + λ|u|r−2 u in RN ,
(3.3)
u ∈ H 1 (RN ),
with 2 < r < p < 2∗ and λ ∈ R.
The fact that we are working on RN suggests that we may have to face a lack
of compactness. We will now describe what kind of assumptions on q allow us to
overcome this type of problem.
We assume that q : RN → R is continuous (for simplicity) and satisfies
(q1 ) infx∈RN q(x) > 0 and lim|x|→+∞ q(x) = +∞.
Notice that under (q1 ), if u ∈ H 1 (RN ) a term like

q(x)u2 dx
RN

may diverge; this means that we cannot work directly in the space H 1 (RN ).
Also, the function q is not necessarily radial, so that it makes no sense to restrict the problem to spaces of radial functions as we did in the previous section.
Compactness will be recovered by means of assumption (q1 ).

3.2 A Problem with Unbounded Potential

105

We introduce the following subspace X of H 1 (RN ):


X = u ∈ H 1 (RN )
q(x)u2 dx < +∞ .
RN

It is easy to recognize that X is a Hilbert space with scalar product and norm given
by


(u|v) =
∇u · ∇v dx +
q(x)uv dx and u 2 = (u|u).
RN

RN

A weak solution of Problem (3.3) is a function u ∈ X such that


∇u · ∇v dx +
q(x)uv dx
RN
RN


p−2
|u|
uv dx + λ
|u|r−2 uv dx
=
RN

RN

(3.4)

for every v ∈ X.
From (q1 ) one deduces immediately that X is embedded continuously into
H 1 (RN ) and therefore also into Lp (RN ), for p ∈ [2, 2∗ ]. But much more can be
said about this last embedding.
Lemma 3.2.1 The embedding of X into Lp (RN ) is compact for all p ∈ [2, 2∗ ).
Proof Let {uk }k ⊂ X be a sequence such that uk
0 in X. We have to show that
uk → 0 in Lp (RN ). Extracting subsequences if necessary, we can assume that
p

uk → 0 in Lloc (RN )

and uk (x) → 0

a.e. in RN .

We first show that uk → 0 in L2 (RN ). For this, let
M = sup{ uk 2 }.
k

For every ε > 0, let Rε > 0 be such that q(x) ≥ M/ε for all |x| ≥ Rε ; this number
exists due to (q1 ). We know that

u2k dx = 0,
lim
k→∞ |x|<Rε

so that we obtain


2
uk dx =
RN

|x|<Rε


u2k dx +

ε
≤ o(1) +
M





|x|≥Rε

|x|≥Rε

This shows that

u2k dx = o(1) +

qu2k dx ≤ o(1) +


lim sup
k→∞

RN

u2k dx ≤ ε,

1 2
quk dx
q
|x|≥Rε

ε
uk 2 ≤ o(1) + ε.
M

106

3

Minimization Techniques: Lack of Compactness

and since this holds for every ε > 0, we conclude that

lim
u2k dx = 0.
k→∞ RN

We can now finish easily with the usual interpolation argument: the sequence uk
∗
being bounded in X, is also bounded in H 1 (RN ), and then also in L2 (RN ). Take
any p ∈ (2, 2∗ ) and write p = 2t + 2∗ (1 − t) with t ∈ (0, 1); then

t 
1−t

∗
|uk |p dx ≤
|uk |2 dx
|uk |2 dx
→ 0.

RN

RN

RN

We can now introduce the Nehari manifold and repeat the argument of the previous section. We leave this to the reader, and we just state the existence result.
Theorem 3.2.2 Let p, r ∈ (2, 2∗ ), r < p, and assume that (q1 ) holds. Then there
exists u ∈ X, u ≥ 0, that solves weakly Problem (3.3).
The solution that we have found satisfies (3.4). We want now to see that the weak
equation is satisfied for any test function in H 1 (RN ).
Theorem 3.2.3 If u ∈ X satisfies (3.4), then it also satisfies


∇u · ∇v dx +
quv dx
RN
RN


=
|u|p−2 uv dx + λ
|u|r−2 uv dx ∀v ∈ H 1 (RN ).
RN

RN

Proof Fix v ∈ H 1 (RN ) and assume that v ≥ 0. Let {ϕk }k be a sequence of C ∞
functions such that
• 0 ≤ ϕk (x) ≤ 1 for every x,
• ϕk (x) = 1 if |x| ≤ k,
• ϕk (x) = 0 if |x| ≥ k + 1,
• |∇ϕk (x)| ≤ C for every x.
It is then easy to check that ϕk (x)v ∈ H 1 (RN ) and that
ϕk (x)v → v

in H 1 (RN ),

and then also in Lp (RN ) and Lr (RN ). As q is locally bounded and ϕk v has compact
support, we obtain that ϕk v ∈ X; therefore


∇u · ∇(ϕk v) dx +
quϕk v dx
RN
RN


=
|u|p−2 uϕk v dx + λ
|u|r−2 uϕk v dx.
(3.5)
RN

Strong convergence in H 1 (RN ) implies

RN

3.3 A Serious Loss of Compactness

107





∇u · ∇(ϕk v) dx =
∇u · ∇v dx,
N
R
lim
|u|p−2 uϕk v dx =
|u|p−2 uv dx,
N
N
k
R
R
r−2
lim
|u| uϕk v dx =
|u|r−2 uv dx,

lim
k

R

k

RN

N

RN

and hence from (3.5) we deduce that

0 ≤ lim
quϕk v dx
N
k
 R


p−2
=−
∇u · ∇v dx +
|u|
uv dx + λ
RN

RN

RN

|u|r−2 uv dx < +∞.

On the other hand we have
0 ≤ q(x)ϕk (x)v(x) ≤ q(x)ϕk+1 (x)v(x)
for all k and almost every x so that by Beppo Levi’s monotone convergence theorem,
we have


lim
quϕk v dx =
quv dx.
k

RN

RN

Summing up, we obtain



quv dx = −
∇u · ∇v dx +
RN

RN

RN


|u|

p−2

uv dx + λ

RN

|u|r−2 uv dx,

and this holds for v ∈ H 1 (RN ) and v ≥ 0. To get the result for any v it is enough to
write v = v + − v − , and to do the computations for v + and v − separately.


3.3 A Serious Loss of Compactness
In this section we study a problem where the loss of compactness takes a more
serious form. The method to overcome the problem will therefore be considerably
longer and more involved than in the preceding sections.
We study the same equation as in Sect. 3.2, namely

−u + q(x)u = |u|p−2 u + λ|u|r−2 u in RN ,
(3.6)
u ∈ H 1 (RN )
with p, r ∈ (2, 2∗ ), r < p and λ ∈ R but this time we make the following assumptions on q:
(q2 ) q is continuous and 0 < δ := infRN q < supRN q =: α < +∞.
(q3 ) lim|x|→+∞ q(x) = α.
We will work in H 1 (RN ) with scalar product and norm given by


(u|v) =
∇u · ∇v dx +
q(x)uv dx and u 2 = (u|u).
RN

RN

108

3

Minimization Techniques: Lack of Compactness

Thanks to (q2 ), these are equivalent to the standard scalar product and norm of
H 1 (RN ).
A weak solutions of problem (3.6) is a function u ∈ H 1 (RN ) such that


∇u · ∇v dx +
quv dx
RN
RN


=
|u|p−2 uv dx + λ
|u|r−2 uv dx ∀v ∈ H 1 (RN ),
RN

RN

namely a critical point of the functional I ∈ C 1 (H 1 (RN )) defined by
 



1
1
λ
|∇u|2 dx + q(x)u2 dx −
I (u) =
|u|p dx −
|u|r dx
2 RN
p RN
r RN
1 p λ
1
= u 2 − |u|p − |u|rr dx.
2
p
r
Remark 3.3.1 The loss of compactness appears in the same way as in the preceding
example, where it was overcome thanks to the behavior of q at infinity (assumption
(q1 )).
In the present case, the behavior of q specified by assumption (q1 ) prevents the
use of the same argument, and this is what makes the problem considerably more
difficult.
We are going to prove the following result through a series of lemmas, in which
we tacitly assume that (q2 ) and (q3 ) hold.
Theorem 3.3.2 Let p, r ∈ (2, 2∗ ), r < p, and assume that (q2 ) and (q3 ) hold. Then
Problem (3.6) admits at least one nontrivial and nonnegative (weak) solution.
As in previous sections, we use the method of minimization on the Nehari manifold. We set again


N = u ∈ H 1 (RN ) | u = 0, I  (u)u = 0


p
= u ∈ H 1 (RN ) u = 0, u 2 = |u|p + λ|u|rr .
If u ∈ N ,


I (u) =

1 1
−
2 r

and since 2 < r < p, then




I (u) >


u 2+

1 1
−
2 r


1 1
p
−
|u|p ,
r
p


u 2>0

for all u ∈ N .
We define
m = inf I (u).
u∈N

3.3 A Serious Loss of Compactness

109

Using the same arguments as above one can immediately prove the following result.
Lemma 3.3.3 The Nehari manifold is not empty, infu∈N u > 0 and m > 0.
We consider now a minimizing sequence {uk }k ⊂ N . Of course we can assume
uk (x) ≥ 0 almost everywhere in RN . The sequence uk is bounded in H 1 (RN ), and
therefore, up to subsequences, there exists u ∈ H 1 (RN ) such that
u in H 1 (RN ), Lp (RN ), Lr (RN ),
• uk
p
• uk → u in Lloc (RN ),
• uk (x) → u(x) a.e.
The last property tells us at once that u ≥ 0. By extracting a further subsequence, if
necessary, we can define β ≥ 0 as

|uk |p
β = lim
k

and we let

RN


l=

RN

|u|p dx;

by weak convergence it is obvious that l ∈ [0, β].
Lemma 3.3.4 There results β > 0.
Proof If β = 0, we have
lim |uk |p = 0.
k

Let t ∈ (0, 1) be such that r = 2t + (1 − t)p. Then by the Hölder inequality,


p(1−t)
|uk |r dx =
|uk |2t |uk |p(1−t) dx ≤ |uk |2t
.
2 |uk |p
RN

RN

As {|uk |2 }k is a bounded sequence, we see that
lim |uk |r = 0.
k

p
uk 2 = |uk |p + λ|uk |rr , and then we obtain uk → 0 in H 1 (RN ) and

Since uk ∈ N ,
m = 0, a contradiction.



Remark 3.3.5 Up to now the proof has followed the same lines that we have encountered many times. The real difficulty, the point where the lack of compactness
becomes manifest, is to show that the minimizing sequence converges in a strong
enough sense to pass to the limit in the nonlinear terms. In the preceding sections,
compactness was restored from the beginning, either by working in the space of radial functions, or by the use of the space X, as testified by Lemmas 3.1.4 and 3.2.1.
In the present case, nothing of the sort can be used, and this is what makes the
present problem more difficult. The main argument of the proof consists in a rather

110

3

Minimization Techniques: Lack of Compactness

careful analysis of the minimizing sequences, much more precise than the ones seen
so far. We will try to classify the possible behaviors of minimizing sequences, and
from this we will first rule out some possibilities, and then show that in the remaining cases there is enough compactness to conclude the proof.
This kind of argument is a first (and simplified) example of the application of a
highly refined theory aimed at classifying all the possible behaviors of sequences of
“approximate solutions”, like minimizing sequences. The theory, beyond the scopes
of this book, was developed by P.-L. Lions in a series of papers [31–34], and culminates with the “Concentration–Compactness Principle”, a largely used tool in
problems with lack of compactness.
We will find another example of application of this principle in the next section.
For the analysis of the minimizing sequence {uk } that we need here it is sufficient
to consider three cases: l = β, l = 0, and l ∈ (0, β).
It is quite useful, in this and in many other cases where compactness is the problem, to visualize intuitively the minimizing sequence {uk } as made of number of
“bumps” in RN , changing their shape and moving around as k → ∞. One says that
the “mass” of uk , for example some integral of |uk |p , is concentrated where the
bumps are located. Following this image, one can easily realize that if at least one
bump escapes to infinity, then uk will not be compact (in the weak limit some mass
is lost, and there is no strong convergence in Lp for instance). This is of course
not the only possible reason for a failure of compactness, but it certainly helps in
following the technical parts of the argument.
For example, keeping in mind the definition of β and l, it is reasonable to visualize the case l = β as a situation where no mass is lost, and hence compactness should
be expected. The case l = 0 corresponds to a total loss of mass (all the bumps of uk
escape to infinity); if this happens, the key will be the analysis of an auxiliary problem, where q(x) is replaced by α = lim|x|→∞ q(x). The hardest case is l ∈ (0, β)
which means that only some of the mass is lost in the limit.
We now make all this rigorous, beginning from the simplest case and confirming
our initial guess that compactness can be recovered.
Lemma 3.3.6 If l = β, then u ∈ N and I (u) = m.
u in Lp (RN ) we also have |uk |p → |u|p , and
Proof If l = β, in addition to uk
p
N
this implies uk → u in L (R ) (see [11]). By the same interpolation argument of
the previous lemma, this yields also uk → u in Lr (RN ). Hence, by weak convergence, we obtain
I (u) ≤ lim inf I (uk ) = m,
k

while the relation

p
uk 2 = |uk |p + λ|uk |rr implies
p

u 2 ≤ |u|p + λ|u|rr .
If equality holds, then u ∈ N (recall that l = β > 0, so u = 0) and the lemma is
proved.

3.3 A Serious Loss of Compactness

111

p

The case u 2 < |u|p + λ|u|rr cannot occur, since arguing as usual, and taking
t ∈ (0, 1) such that tu ∈ N , we would have
m ≤ I (tu)




1 1
1 1
p
= t2
−
u 2 + tp
−
|u|p
2 r
r
p




1 1
1 1
p
−
u 2+
−
|u|p ≤ lim inf I (uk ) = m,
<
k
2 r
r
p


a contradiction.

We now turn to the case l = 0. We are going to use some of the results of Sect. 3.1.
First we introduce in H 1 (RN ) the norm


2
2
|∇u| dx + α
|u|2 dx,
u α=
RN

RN

where α is the positive number defined in (q2 ). Of course u α in an Hilbertian
norm equivalent to u . Then we define a functional
Iα : H 1 (RN ) → R as

Iα (u) =

1
1 p
1
u 2α − |u|p − λ |u|rr ,
2
p
r

and the associated Nehari manifold


Nα = u ∈ H 1 (RN ) | u = 0, Iα (u)u = 0


p
= u ∈ H 1 (RN ) u = 0, u 2α = |u|p + λ|u|rr .
Finally we define
mα = inf Iα (u).
u∈Nα

The intuitive idea behind the introduction of this auxiliary problem is that if l = 0,
then all the mass of uk escapes to infinity. But close to infinity q(x) “looks like α”,
which is supRN q: it should not be convenient, if uk has to minimize I , to have its
mass located where q is large. Let us see that this is indeed true. First we compare
m and mα .
Lemma 3.3.7 There results m < mα .
Proof By the results of Sect. 3.1 we know that Nα = ∅, mα > 0 and that there exists
u0 ∈ Nα such that Iα (u0 ) = mα . We also know that u0 ≥ 0.
By (q2 ) and (q3 ) we infer that there exist δ1 > 0 and a ball BR (x1 ) such that
q(x) ≤ α − δ1

∀x ∈ BR (x1 ).

Since u0 does not vanish identically, there exist δ2 > 0, a ball BR (x2 ) and a set
A ⊆ BR (x2 ) of positive measure such that
u0 (x) ≥ δ2

a.e. in A.

112

3

Minimization Techniques: Lack of Compactness

We now define a function u1 ∈ H 1 (RN ) as
u1 (x) = u0 (x − x1 + x2 ).
By the invariance of integrals with respect to translations we have
and Iα (u1 )u1 = Iα (u0 )u0 = 0.

Iα (u1 ) = Iα (u0 ) = mα

Notice that if x ∈ BR (x1 ), then x − x1 + x2 ∈ BR (x2 ); therefore u1 (x) ≥ δ2 a.e. in a
set A ⊆ BR (x1 ) of positive measure. Then


(α − q(x))u21 dx ≥
δ1 δ22 = Cδ1 δ22 ,
A

BR (x1 )

where C is the measure of A .
Since q(x) ≤ α for every x, we obtain the estimate


2
(α − q(x))u1 dx ≥
(α − q(x))u21 dx ≥ Cδ1 δ22 > 0,
RN

so that

BR (x1 )


RN

which implies


|∇u1 |2 dx +
RN

RN


q(x)u21 dx < α

RN

u21 dx,


q(x)u21 dx <

RN


|∇u1 |2 dx + α

RN

u21 dx,

that is,
u1 2 < u1 2α .
We then have
I  (u1 )u1 = u1 2 − |u1 |p − λ|u1 |rr < u1 2α − |u1 |p − λ|u1 |rr
p

p

= Iα (u1 )u1 = Iα (u0 )u0 = 0.
Hence, by usual arguments, there exists t ∈ (0, 1) such that tu1 ∈ N , so that




1
1
p
2 1
2
p 1
−
u1 + t
−
|u1 |p
m ≤ I (tu1 ) = t
2 r
r
p




1 1
1 1
p
2
−
u1 +
−
|u1 |p
<
2 r
r
p




1 1
1 1
p
2
−
u1 α +
−
|u1 |p
<
2 r
r
p




1 1
1 1
p
2
−
−
=
u0 α +
|u0 |p = Iα (u0 ) = mα .

2 r
r
p
Now the last step: if all the mass of uk escapes to infinity, then I (uk ) is too large
(at least mα ), and uk cannot be a minimizing sequence.
Lemma 3.3.8 The case l = 0 cannot occur.

3.3 A Serious Loss of Compactness

113

Proof If l = 0, then u = 0, which implies in particular that uk → 0 in L2loc (RN ). We
first prove the following claim:

lim
|q(x) − α| u2k dx = 0.
(3.7)
k→+∞ RN

To prove (3.7) we fix ε > 0 and we take Rε > 0 such that
|q(x) − α| ≤ ε

∀|x| ≥ Rε ;

this is possible by (q3 ). We can then estimate



|q(x) − α|u2k dx =
|q(x) − α|u2k dx +
|q(x) − α|u2k dx
RN
|x|≤Rε
|x|>Rε

≤C
u2k dx + Mε,
|x|≤Rε

where


C = max |q(x) − α|

and M = sup

x∈RN

k

When k → ∞ we obtain

RN

u2k dx.



lim sup

RN

k

|q(x) − α|u2k dx ≤ εM

for every ε > 0, because uk → 0 in L2loc (RN ). As this holds for every ε > 0, (3.7) is
proved.
From (3.7) we deduce that
lim

k→+∞

uk α = lim

k→+∞

uk .

(3.8)

Now we know that
p

uk 2α ≥ uk 2 = |uk |p + λ|uk |rr ,
so that, by usual arguments, we can prove that for each k there is tk ≥ 1 such that
tk uk ∈ Nα , namely
p

p

tk2 uk 2α = tk |uk |p + λtkr |uk |rr .

(3.9)

We know that the sequences {|uk |p }, {|uk |r } and { uk α } are bounded and that
p

lim |uk |p = β > 0.
k

Therefore from (3.9) we deduce that {tk }k is bounded and, up to a subsequence, we
can assume tk → t0 with, of course, t0 ≥ 1. We also know that
uk 2α = uk 2 + εk ,
with εk → 0, and that
p

λ|uk |rr = uk 2 − |uk |p .

114

3

Minimization Techniques: Lack of Compactness

Substituting in (3.9) we get



p
p
tk2 − tkr uk 2 + tk εk = tk − tkr |uk |p .
Passing to the limit, and setting γ = limk uk 2 > 0, we obtain


p

t02 − t0r γ = t0 − t0r β;
so t0 > 1 gives a contradiction because 2 < r < p, and then necessarily t0 = 1. Now
we can write




1
1
p 1
p
2 1
2
−
uk α + tk
−
|uk |p
mα ≤ Iα (tk uk ) = tk
2 r
r
p






1
1
1
p
2 1
2
2 1
2 1
−
uk + tk
−
εk + tk
−
|uk |p
= tk
2 r
2 r
r
p



1 1
p
p
2
−
|uk |p
+ tk − tk
r
p
= tk2 I (uk ) + o(1).
Passing to the limit we then obtain
mα ≤ m,


a contradiction which concludes the proof.

As we anticipated, the hard case occurs when l ∈ (0, β), because this means that
the weak limit u is not identically zero, namely that only part of the mass escapes to
infinity. A careful analysis will show that this is enough to conclude. We define
l1 = |u|rr .
We begin by choosing an increasing sequence {Rj }j of positive numbers such
that Rj +1 > Rj + 1, so that in particular Rj → +∞, and such that the following
properties hold:


• l − j1 ≤ BR |u|p dx ≤ l, hence also B c |u|p dx ≤ j1 ,
R
j

j
1
r
• l1 − j ≤ BR |u| dx ≤ l1 , hence also B c |u|r dx ≤ j1 ,
Rj
j

• B c u2 dx ≤ j1 .
Rj

Then we define
Cj = BRj +1 \BRj = {x ∈ RN | Rj ≤ |x| < Rj + 1}.
Since we have compactness on bounded subsets of RN , for every j there results




p
p
p
lim
|uk | dx =
|u| dx,
lim
|uk | dx =
|u|p dx,
k

BRj

BRj

k

BRj

|uk |r dx =

lim
k





|u|r dx,
BRj



Cj

Cj

|uk |r dx =

lim
k



Cj

|u|r dx
Cj

3.3 A Serious Loss of Compactness

and

115




|uk |2 dx =

lim
k

Cj

Moreover, since


|u|p dx ≤
Cj

and

|u|2 dx.

Cj



1
|u|p dx ≤ ,
c
j
BR


|u|r dx ≤
Cj

j

BRc
j

|u|r dx ≤

1
j




|u|2 dx ≤
Cj

1
|u|2 dx ≤ ,
j
BRc
j

we can extract a subsequence ukj in order to have, for every j ∈ N,


2
1
2
l− ≤
|ukj |p dx ≤ l + ,
|ukj |p dx ≤ ,
j
j
j
BRj
Cj



2
1
2
2
r
r
|ukj | dx ≤ l1 + ,
|ukj | dx ≤ ,
|ukj |2 dx ≤ .
l1 − ≤
j
j
j
j
BRj
Cj
Cj
We take {ukj } as a new minimizing sequence renaming it {uj }j .
We also consider, for every j , a function ψj ∈ C ∞ (RN ) such that
• 0 ≤ ψj (x) ≤ 1 for every x,
• ψj (x) = 1 if |x| ≤ Rj ,
• ψj (x) = 0 if |x| ≥ Rj + 1,
• |∇ψj (x)| ≤ C for every x
and we define auxiliary functions
uj = ψj uj ,

and uj = (1 − ψj )uj .

Of course, uj , uj ≥ 0 and uj = uj + uj for every j .
Lemma 3.3.9 The following properties hold as j → ∞:
1. uj tends to u weakly in H 1 (RN ) and strongly in Lp (RN ) and in Lr (RN ), while
uj tends to 0 weakly in H 1 (RN ).



2. RN |uj |p dx = RN |uj |p dx + RN |uj |p dx + o(1).



3. RN |uj |r dx = RN |uj |r dx + RN |uj |r dx + o(1).
4. uj 2 ≥ uj 2 + uj 2 + o(1).
Proof 1. If B is any bounded set in RN , we know that uj = uj in B, for every
j big enough, from which we can immediately conclude that uj
u in H 1 (RN )
(hence in Lp (RN ) and Lr (RN )). This also implies uj
0 in H 1 (RN ), Lp (RN )
r
N
and L (R ).

116

3

Moreover,


RN

|uj |p dx ≥


BRj

Minimization Techniques: Lack of Compactness

|uj |p dx =



2
|uj |p dx ≥ l − ,
j
BRj

and on the other hand, recalling that 0 ≤ uj ≤ uj ,



 p
 p
|uj | dx =
|uj | dx ≤
|uj |p dx
RN

BRj +1


=

BRj +1



|uj |p dx +

|uj |p dx ≤ l +

BRj

Thus we obtain that

Cj


lim
j

RN

|uj |p dx = l =

3
1 2
+ =l+ .
j
j
j


RN

|u|p dx,

and since we have weak convergence we can conclude (see e.g. [11]) that uj → u
in Lp (RN ). In the same way we get uj → u in Lr (RN ).
2. It is immediate to check that |uj |p ≥ |uj |p + |uj |p ; hence,
 

|uj |p − |uj |p − |uj |p dx ≥ 0.
RN

On the other hand,


|uj |p dx =
RN



BRj


=

BRj


≤

RN


≤
so that

RN


0≤



|uj |p dx +
|uj |p dx +

|uj |p dx +



|uj |p dx +



|uj |p dx +

Cj

Cj


|uj |p dx +

Cj

2
+
j

|uj |p dx +


RN

BRc +1

|uj |p dx

j

BRc +1

|uj |p dx

j

RN

|uj |p dx

|uj |p dx,



2
|uj |p − |uj |p − |uj |p dx ≤ ,
j
RN

which proves 2.
3. The identity for the Lr norms can be proved as in 2.
4. Exactly as above, |uj |2 ≥ |uj |2 + |uj |2 , and since q(x) ≥ 0, we obtain



2
 2
q(x)uj dx ≥
q(x)|uj | dx +
q(x)|uj |2 dx.
RN

Also,


RN


|∇uj | dx =
2

RN

RN

|∇uj |2 dx +

RN


RN

|∇uj |2 dx + 2


RN

∇uj · ∇uj dx.

3.3 A Serious Loss of Compactness

117

Then we have



 

uj ∇ψj + ψj ∇uj · (1 − ψj )∇uj − uj ∇ψj dx
∇uj · ∇uj dx =
RN
RN


uj (1 − ψj )∇ψj · ∇uj dx −
u2j |∇ψj |2 dx
=
RN
RN


2
ψj (1 − ψj )|∇uj | dx −
ψj uj ∇uj · ∇ψj dx
+
RN
RN


uj (1 − ψj )∇ψj · ∇uj dx −
u2j |∇ψj |2 dx
≥
RN
RN

ψj uj ∇uj · ∇ψj dx.
−
RN

We also have

RN

and




u2j |∇ψj |2 dx ≤ C


RN

Cj

u2j dx ≤

2C
= o(1),
j


ψj uj ∇uj · ∇ψj dx ≤

RN

ψj uj |∇uj ||∇ψj | dx
1/2 


≤

RN


≤M

|∇uj | dx
2

2C
j

1/2

RN

1/2
u2j |∇ψj |2 dx

= o(1),


where M = supj ( RN |∇uj |2 dx)1/2 .
In the same way we obtain

(1 − ψj )uj ∇uj · ∇ψj dx ≤ o(1),
RN

and putting all the estimates together we deduce that



|∇uj |2 dx ≥
|∇uj |2 dx +
|∇uj |2 dx + o(1),
RN

RN

RN

and finally,
uj 2 ≥ uj 2 + uj 2 + o(1).
Lemma 3.3.10 There results




1 1
1 1
p
−
u 2+
−
|u|p ≤ m.
2 r
r
p
Proof Since uk

u in H 1 (RN ) and in Lp (RN ),



118

3



Minimization Techniques: Lack of Compactness




1 1
1 1
p
−
u 2+
−
|u|p
2 r
r
p




1 1
1 1
p
−
lim inf uk 2 +
−
lim inf |uk |p
≤
k
k
2 r
r
p
≤ lim inf I (uk ) = m.
k



We now prove that u ∈ N . We know that u = 0, so we just have to check that
p
u 2 = |u|p + λ|u|rr . First we rule out the easy inequality.
Lemma 3.3.11 It cannot be
p

u 2 < |u|p + λ|u|rr .
p

Proof If u 2 < |u|p + λ|u|rr , then, by usual arguments, there is some t ∈ (0, 1)
such that tu ∈ N , so that




1 1
1 1
p
−
u 2 + tp
−
|u|p
m ≤ I (tu) = t 2
2 r
r
p




1 1
1 1
p
−
u 2+
−
|u|p ≤ m,
<
2 r
r
p


a contradiction.
Then, with some more effort, the opposite case.
Lemma 3.3.12 It cannot be
p

u 2 > |u|p + λ|u|rr .
Proof Using Lemma 3.3.9 we can write
uj 2 + uj 2 ≤ uj 2 + o(1) = |uj |p + λ|uj |rr + o(1)
p

= |uj |p + λ|uj |rr + |uj |p + λ|uj |rr + o(1).
p

Assume for contradiction that

p

(3.10)

p
u 2 > |u|p + λ|u|rr and pick δ > 0 such that
p

q

u 2 > |u|p + λ|u|q + δ.
Since uj

u in H 1 (RN ),
lim inf uj 2 ≥ u 2 ,
j

while uj → u in Lp (RN ) and in Lr (RN ). From this we deduce that, for large j ’s,
uj 2 > |uj |p + λ|uj |rr + δ1 ,
p

for some δ1 ∈ (0, δ). Together with (3.10), this implies
uj 2 ≤ |uj |p + λ|uj |rr − δ2 ,
p

3.4 Problems with Critical Exponent

119

for large j ’s and for some δ2 ∈ (0, δ1 ). Recalling that uj
ing as in Lemma 3.3.8, we obtain

0 in H 1 (RN ) and argu-

lim uj 2 = lim uj 2α ,
j

j

so that
uj 2α ≤ |uj |p + λ|uj |rr − δ3 ,
p

for large j ’s and for some δ3 ∈ (0, δ2 ). Hence, by usual arguments, we can find
sj ∈ (0, 1) such that sj uj ∈ Nα . So we obtain




1 1
1
p 1
p
−
uj 2α + sj
−
|uj |p
mα ≤ Iα (sj uj ) = sj2
2 r
r
p




1 1
1 1
p
−
uj 2 +
−
|uj |p + o(1)
≤
2 r
r
p





1 1   p
1 1   2
p
−
uj + uj 2 +
−
|uj |p + |uj |p + o(1)
≤
2 r
r
p




1
1
1 1
p
−
uj 2 +
−
|uj |p + o(1) = I (uj ) + o(1).
≤
2 r
r
p
Passing to the limit this yields
mα ≤ m,


a contradiction.

End of the proof of Theorem 3.3.2 We can now conclude easily the proof of the
main result. The previous lemmas say that in any case the weak limit u satisfies
u = 0, u ≥ 0 and
p

u 2 = |u|p + λ|u|rr .
Therefore u ∈ N and also
I (u) =



1 1
−
2 r




u 2+


1 1
p
−
|u|p ≤ m,
r
p

so that I (u) = m and u is a minimum point for I on N . It is then easy, arguing as
in the previous sections, to prove that u is a critical point for I on H 1 (RN ).


3.4 Problems with Critical Exponent
We discuss in this section some examples of problems where the nonlinearity has
critical growth. This is one of the most dramatic cases of loss of compactness and
has been studied intensively in the last 25 years, starting with the pioneering paper
[14].
We present here only simple cases, with the aim of showing some example of the
techniques involved.

120

3

Minimization Techniques: Lack of Compactness

3.4.1 The Prototype Problem
We consider in RN , with N ≥ 3, the equation
∗

−u = |u|2 −2 u.

(3.11)

Formally, solutions of (3.11) should arise as critical points of the functional


1
1
∗
|∇u|2 dx − ∗
|u|2 dx.
(3.12)
I (u) =
2 RN
2 RN
It is not convenient to think of I as defined on H 1 (RN ), since in this space the first
integral in I is not (the square of) a norm, and this poses serious difficulties.
We will work in the space D 1,2 (RN ) that we introduced in Sect. 1.2. The problem
we are dealing with then becomes

∗
−u = |u|2 −2 u,
(3.13)
1,2
N
u ∈ D (R ).
∗

We know that D 1,2 (RN ) ⊂ L2 (RN ), with continuous embedding, but the embedding is not compact, not even in a local sense, as we now make precise.
Clearly, since we are working in RN , there is a lack of compactness due to the
invariance under translations, as we discussed in earlier sections. However in this
case there is an even more serious problem, that arises from the invariance under
scalings, as follows. Let v ∈ C0∞ (RN ) (hence v ∈ D 1,2 (RN )) be a fixed function,
and set, for λ > 0,
N−2

vλ (x) = λ 2 v(λx).
Then it is an exercise to check that


|∇vλ |2 dx =
RN

RN

|∇v|2 dx

for every λ > 0

and
vλ
However also


RN

0 in D 1,2 (RN )
∗

|vλ |2 dx =



for λ → 0 or λ → +∞.
∗

RN
∗

|v|2 dx

for every λ > 0,

(3.14)

so that {vλ }λ is not precompact in L2 (RN ). This happens exactly because the exponent is 2∗ .
With respect to the informal discussion on the loss of compactness carried out
in the preceding section, we have to face here new ways in which this phenomenon
takes place. Indeed, assuming to fix ideas that v(0) = 0,we see that when λ → 0 the
∗
functions vλ ∈ C0∞ (RN ) tend to zero uniformly, while RN |u|2 dx is kept constant
(see (3.14)). One can say that the “mass” spreads everywhere. On the contrary, if
λ → ∞, then vλ (x) → 0 for every x = 0, while vλ (0) → ∞, and again (3.14) holds;
this is the famous loss of compactness by concentration, that one meets in every
problem with critical growth, even on bounded domains.

3.4 Problems with Critical Exponent

121

The hard part in the proof of the main result of this section will be devoted to a
careful analysis of minimizing sequences to understand the consequences of spreading or concentration of mass.
Anyway, the first thing to do if one wants to solve (3.13), is to get rid of the
invariance under translations. This can be done by symmetrization, as in Sect. 3.1.
We recall that we have defined


Dr = u ∈ D 1,2 (RN ) | u is radial .
We are going to prove the following theorem.
Theorem 3.4.1 There exists a nonnegative and nontrivial u ∈ Dr that solves weakly
Problem (3.13), namely such that


∗
∇u · ∇v dx =
u2 −1 v dx
(3.15)
RN

RN

for every v in D 1,2 (RN ).
Remark 3.4.2 It can be proved, with essentially the same arguments as in Example 1.3.21, that the functional

∗
u →
|u|2 dx
RN

(and hence the functional I ) is differentiable on D 1,2 (RN ). This does not follow
directly from Example 1.3.21, because the H 1 norm is larger that the D 1,2 norm. In
other words, quantities that are o( v H 1 ) are not, generally, o( v D 1,2 ). A slightly
more general case is reported in Exercise 4.
In the proof of Theorem 3.4.1 we will need the pointwise estimate that we have
proved in Lemma 3.1.2.
Now we can start with the main argument. We want to minimize the functional I
∗
on the unit sphere of L2 (RN ). This amounts to setting


∗
2
1,2
N
u ∈ D (R ),
S = inf u
|u|2 dx = 1 .
(3.16)
RN

Remark 3.4.3 The value S is known as the best Sobolev constant. It is the largest
positive constant S such that
S|u|22∗ ≤ u 2

for every u ∈ D 1,2 (RN ).

Thanks to the Sobolev inequalities, we know that S > 0. We will show that the
infimum S is attained by some u ∈ D 1,2 (RN ).
We begin to carry out the analysis of minimizing sequences by selecting one that
enjoys some special properties, as we show in the next three lemmas. To begin with,
we need a minimizing sequence made by radial functions.

122

3

Minimization Techniques: Lack of Compactness

Lemma 3.4.4 There exists a sequence {vk }k ⊂ Dr such that vk ≥ 0,
vk 2 → S.
|vk |2∗ = 1 and
Proof Let {wk }k ⊂ D 1,2 (RN ) be a minimizing sequence for S; of course it is not
restrictive to assume that wk ≥ 0. Define vk = wk∗ ≥ 0 (see Theorem 3.1.5). Then
v k ∈ Dr ,

|vk |2∗ = |wk |2∗ = 1

and

v k 2 ≤ wk 2 ,

so that {vk }k ⊂ Dr is a minimizing sequence for S.



Lemma 3.4.5 There exist a minimizing sequence {uk }k ⊂ Dr for S and a function
u ∈ Dr with the following properties:
• uk ≥ 0, u ≥ 0.

∗
∗
• |x|<1 |uk |2 dx = |x|≥1 |uk |2 dx = 12 .
• uk

∗

u in D 1,2 (RN ) and in L2 (RN ), and uk (x) → u(x) a.e. in RN .

Proof Let {vk }k ⊂ Dr be a minimizing sequence for S, with vk ≥ 0. Since

∗
|vk |2 dx = 1,
RN

there exists Rk > 0 such that


∗
|vk |2 dx =

1
∗
|vk |2 dx = .
2
|x|≥Rk

|x|<Rk

If we define
N−2

uk (x) = Rk 2 vk (Rk x),
it is immediate to check that uk ∈ Dr and that uk = vk and |uk |2∗ = |vk |2∗ .
This means that {uk }k is a minimizing sequence too. Of course uk ≥ 0, and a simple
change of variables shows that


1
∗
∗
|uk |2 dx =
|uk |2 dx = .
2
|x|<1
|x|≥1
Since {uk }k is bounded in D 1,2 (RN ), up to subsequences, uk
u in D 1,2 (RN ) and
∗
2
N
in L (R ). Moreover, for every ball B, the sequence uk is bounded in H 1 (B),
so that, again up to subsequences, it converges strongly in L2 (B) and also satisfies
uk (x) → u(x) almost everywhere in RN . The proof is complete.

Next, we force the sequence uk to have the technical property stated in the following lemma.
Lemma 3.4.6 There exists a minimizing sequence {uk }k for S that, in addition to
those of the previous lemma, satisfies also the following properties: for every j ∈ N,
j ≥ 1, the sequences


2
|∇uk | dx
and
|∇uk |2 dx
|x|<1/j

admit finite limits as k → ∞.

k

|x|>j

k

3.4 Problems with Critical Exponent

123

Proof Let {uk }k be the sequence defined in the previous lemma. Since the numerical
sequences


|∇uk |2 dx and
|∇uk |2 dx
|x|<1

|x|>1

are bounded, there exists a subsequence {uk,1 }k such that the sequences


2
|∇uk,1 | dx and
|∇uk,1 |2 dx
|x|<1

|x|>1

admit finite limits. From {uk,1 }k we can extract a new subsequence {uk,2 }k such that
the sequences


|∇uk,2 |2 dx and
|∇uk,2 |2 dx
|x|<1/2

|x|>2

admit finite limits. Proceeding in this way, for every j ≥ 2 we have a sequence
{uk,j }k such that the sequences


|∇uk,j |2 dx and
|∇uk,j |2 dx
|x|<1/j

|x|>j

admit finite limits as k → ∞ and {uk,j }k is a subsequence of {uk,j −1 }k . Then we
relabel as uk the “diagonal”, namely the sequence uk = uk,k . This is a minimizing
sequence that satisfies the conditions of the previous lemma, because it has been
extracted from the original minimizing sequence. Moreover, for every given j , except the first j terms, the sequence is a subsequence of {uk,j }k , and therefore the
numerical sequences


|∇uk |2 dx and
|∇uk |2 dx
|x|<1/j

|x|>j

are subsequences of a convergent sequence, and therefore they are convergent too. 
In the next lemma we introduce some quantities that we will use in the main
argument. The reader can recognize the effort in trying to gain information on the
spreading or on the concentration of uk , as k → ∞.
Lemma 3.4.7 The following limits exist and are finite:

∗
1. ν0 = limR→0+ (lim supk |x|<R |uk |2 dx),

∗
ν∞ = limR→+∞ (lim supk |x|≥R |uk |2 dx).

2. μ0 = limR→0+ (lim supk |x|<R |∇uk |2 dx),

μ∞ = limR→+∞ (lim supk |x|≥R |∇uk |2 dx).
Moreover
3. ν0 , ν∞ ∈ [0, 1/2].

124

3

Proof Defining the functions

∗
f (R) = lim sup
|uk |2 dx
|x|<R

k

Minimization Techniques: Lack of Compactness


and g(R) = lim sup
k

∗

|x|≥R

|uk |2 dx,

it is immediate to see that f is bounded and nondecreasing, while g is bounded and
nonincreasing. Therefore
lim f (R) = ν0

R→0+

lim g(R) = ν∞

and

R→+∞

exist and are finite (and nonnegative).
The same argument works for μ0 and μ∞ . The fact that ν0 ≤ 1/2 and ν∞ ≤ 1/2
comes from


1
∗
∗
|uk |2 dx =
|uk |2 dx = .

2
|x|<1
|x|≥1
The following lemmas establish some inequalities among the numbers introduced in the above result that will be essential in the proof of Theorem 3.4.1.
Loosely speaking, the next result establishes that as k → ∞, the original mass of
uk in not less than the sum of the contributions of the weak limit, of the part that
spreads (ν∞ ) and of the part that concentrates (ν0 ).
Lemma 3.4.8 Let u be the weak limit of the minimizing sequence uk constructed
above. Then

∗
1≤
|u|2 dx + ν0 + ν∞ .
RN

Proof For every k ∈ N and for every R > 1 we have




2∗
2∗
2∗
1=
|uk | dx =
|uk | dx +
|uk | dx +
RN

|x|<1/R

|x|≥R

1/R<|x|<R

∗

|uk |2 dx.

In the bounded open set
{x ∈ RN 1/R < |x| < R}
∗

∗

we have |uk (x)|2 → |u(x)|2 almost everywhere and moreover
∗

|uk (x)|2 ≤ CR N ,
by Lemma 3.1.2. Then, by dominated convergence,


2∗
lim
|uk | dx =
k

1/R<|x|<R

∗

|u|2 dx.

1/R<|x|<R

Then we have




∗
∗
∗
1 = lim sup
|uk |2 dx +
|uk |2 dx +
|uk |2 dx
|x|<1/R
1/R<|x|<R
|x|≥R
k



∗
∗
∗
|u|2 dx + lim sup
|uk |2 dx + lim sup
|uk |2 dx.
≤
1/R<|x|<R

k

|x|<1/R

k

|x|≥R

3.4 Problems with Critical Exponent

As R → +∞ we obtain

125


1≤

∗

RN

|u|2 dx + ν0 + ν∞ .



A similar behavior (but with the opposite inequality) holds also for the D 1,2
norm.
Lemma 3.4.9 Let u be the weak limit of the minimizing sequence uk constructed
above. Then

S≥
|∇u|2 dx + μ0 + μ∞ .
RN

Proof Setting
εk = uk 2 − S,
for every k and every j there results

S + εk =
|∇uk |2 dx
RN


=
|∇uk |2 dx +
|x|<1/j


|∇uk |2 dx +

1/j <|x|<j

The functional

|x|>j

|∇uk |2 dx. (3.17)


J (u) =

|∇u|2 dx
1/j <|x|<j

is continuous and convex in D 1,2 (RN ), so that it is weakly lower semicontinuous.
Recalling that εk → 0 and that the two numerical sequences


|∇uk |2 dx
and
|∇uk |2 dx
|x|<1/j

k

|x|>j

k

admit limits, if in (3.17) we take the lim inf with respect to k, we obtain




2
2
2
S = lim inf
|∇uk | dx +
|∇uk | dx +
|∇uk | dx
k
|x|<1/j
1/j <|x|<j
|x|>j



|∇uk |2 dx + lim
|∇uk |2 dx + lim
|∇uk |2 dx
= lim inf
k
k
k
1/j <|x|<j
|x|<1/j
|x|>j



2
2
≥
|∇u| dx + lim
|∇uk | dx + lim
|∇uk |2 dx.
k

1/j <|x|<j

k

|x|<1/j

Letting now j → ∞ we see that

S≥

RN

|x|>j

|∇u|2 dx + μ0 + μ∞ .

From the definition of S one has, for every v ∈ D 1,2 (RN ),
2/2∗ 

∗
|v|2 dx
≤
|∇v|2 dx.
S
RN

RN



(3.18)

126

3

Minimization Techniques: Lack of Compactness

The next lemma is of fundamental importance. In some sense it says that the
inequality (3.18) holds also for the “components” of uk that spread or concentrate.
Lemma 3.4.10 There results
2/2∗

Sν0

≤ μ0

2/2∗

and

Sν∞

≤ μ∞ .

Proof Let ϕ : R → R be a C ∞ function such that ϕ(t) = 1 if t ∈ [0, 1] and ϕ(t) = 0
if t ≥ 2. For every R > 0 and every x ∈ RN , set
 
|x|
ϕR (x) = ϕ
.
R
Then ϕR ∈ C0∞ (RN ),

⎧
⎨ ϕR (x) = 1
ϕR (x) = 0
⎩
|∇ϕR (x)| ≤ C/R

if |x| ≤ R,
if |x| ≥ 2R,
for every x ∈ RN

for some C independent of x and R.
For every v ∈ D 1,2 (RN ), the function ϕR v is also in D 1,2 (RN ). Indeed ϕR v
∗
belongs to L2 (RN ), and we only have to check that its gradient is in L2 . But
∇ (ϕR v) = v∇ϕR + ϕR ∇v,
and obviously |ϕR ∇v| ∈ L2 (RN ). On the other hand,


2
2
|v| |∇ϕR | dx =
|v|2 |∇ϕR |2 dx
RN

R<|x|<2R



2∗

 N−2 

|v|

≤
R<|x|<2R


≤

RN

∗

 N−2 
N

|v|2

2/N

N

C
RN

|∇ϕR | dx
N



R<|x|<2R

2/N
≤ C|v|22∗ < +∞.

dx
R<|x|<2R

Thus, the gradient of ϕR v is the sum of two L2 functions.
We now consider, for every k and for every R, the function ϕR uk ∈ D 1,2 (RN ).
Certainly,
2/2∗ 

2∗
|ϕR uk | dx
≤
|∇(ϕR uk )|2 dx.
(3.19)
S
RN

RN

We analyze what happens to this inequality when we compute some limits. As
far as the left-hand side is concerned, we have



∗
∗
∗
|uk |2 dx ≤
|ϕR uk |2 dx ≤
|uk |2 dx,
|x|<R

so that
lim sup
k


|x|<R

RN

|x|<2R



∗

|uk |2 dx ≤ lim sup
k

RN



∗

|ϕR uk |2 dx ≤ lim sup
k

|x|<2R

∗

|uk |2 dx.

3.4 Problems with Critical Exponent

127

Now the first and the last term in this inequality tend to ν0 , when R tends to zero
(Lemma 3.4.7), and therefore so does the central term, namely



2∗
lim lim sup
|ϕR uk | dx = ν0 .
R→0

RN

k

We turn to the study of the right-hand side of (3.19). First of all,
|∇(ϕR uk )|2 = u2k |∇ϕR |2 + ϕR |∇uk |2 + 2uk ϕR ∇ϕR · ∇uk .
Repeating the above argument, we deduce that


2
2
|uk | |∇ϕR | dx ≤ C
RN

R<|x|<2R

 
lim lim
k

∗

|u|2 dx

R<|x|<2R



∗
|uk |2 dx = lim


RN

From this it also easy to see that
 
lim lim
R→0

k

RN

Finally, since


|uk | |∇ϕR | dx = 0.
2

k

2


uk ϕR ∇ϕR · ∇uk dx = 0.


|∇uk |2 dx ≤



RN

|ϕR ∇uk |2 dx ≤

arguing as above we obtain


lim lim sup
R→0

k

|u|2 dx = 0,





lim lim

R→0

∗

R→0 R<|x|<2R

R<|x|<2R

which yields

|x|<R

.

R<|x|<2R

k

R→0

N

|uk | dx

Moreover, working as in Lemma 3.4.8, we see that


∗
|uk |2 dx =
lim
so that

 N−2

2∗

|x|<2R

|∇uk |2 dx,


|ϕR ∇uk | dx = μ0 .
2

RN

Summing up, from (3.19), taking first the lim sup over k, and then the limit as
R → 0, we get to
2/2∗

Sν0

≤ μ0 ,

the first inequality we wanted to prove.
The other inequality can be deduced in a similar way. Defining ψ : R → R to
be a C ∞ function such that ψ(t) = 0 if t ∈ [0, 1] and ψ(t) = 1 if t ≥ 2, for every
R > 0 and every x ∈ RN we set
 
|x|
.
ψR (x) = ψ
R

128

3

Minimization Techniques: Lack of Compactness

Again, it is immediate to check that ψR ∈ C ∞ (RN ),
⎧
if |x| ≤ R,
⎨ ψR (x) = 0
if |x| ≥ 2R,
ψR (x) = 1
⎩
|∇ψR (x)| ≤ C/R for every x ∈ RN
for some C independent of x and R. As before, ψR v ∈ D 1,2 (RN ) if v ∈ D 1,2 (RN ).
Starting from the inequality

2/2∗ 
∗
S
|ψR uk |2 dx
≤
|∇(ψR uk )|2 dx
RN

RN

and arguing as in the first part of the proof, we obtain



2∗
lim lim sup
|ψR uk | dx = ν∞
R→+∞

and

RN

k




lim sup

lim

R→+∞

k

RN


|ψR ∇uk |2 dx = μ∞ ,

so that also the inequality
2/2∗

Sν∞

≤ μ∞


is established.
The next lemma is the final step in the proof of Theorem 3.4.1.
Lemma 3.4.11 There results



ν0 = ν∞ = 0

and

∗

RN

|u|2 dx = 1.

Proof We know that ν0 , ν∞ ∈ [0, 1/2] and, by weak lower semicontinuity,

∗
|u|2 dx ∈ [0, 1].
RN

∗

Since 2∗ > 2, for every a ∈ [0, 1] we have a 2/2 ≥ a, and equality holds if and only
if a = 0 or a = 1.
Putting together the inequalities proved in the preceding lemmas, we have

S≥
|∇u|2 dx + μ0 + μ∞
RN



≥S

≥S

∗

RN

RN

|u|2 dx
∗

2/2∗

2/2∗

+ ν0

2/2∗

+ ν∞

|u|2 dx + ν0 + ν∞ ≥ S.

3.4 Problems with Critical Exponent

129

Thus equality must hold everywhere, and in particular

2/2∗

∗
∗
2/2∗
2/2∗
|u|2 dx
+ ν0 + ν∞ =
|u|2 dx + ν0 + ν∞ .
RN

RN



2∗
RN |u| dx, ν0 and ν∞ must either be 0 or 1. As

But then, each of the numbers
ν0 , ν∞ ∈ [0, 1/2], necessarily ν0 = ν∞ = 0.
Since

∗
|u|2 dx + ν0 + ν∞ ≥ 1,
we deduce that



RN

∗
2
2∗
RN |u| dx ≥ 1 and hence RN |u| dx = 1.



End of the proof of Theorem 3.4.1 We have proved so far that there exists a minimizing sequence for S that admits a weak limit u satisfying

∗
|u|2 dx = 1.
(3.20)
RN

By weak lower semicontinuity, we also have u 2 ≤ S, and by the definition of S
and (3.20), it must be u 2 = S. Thus u is a minimizer.
Now the fact that a multiple of u weakly solves (3.13) follows from standard
arguments already used in Chap. 2. The proof of Theorem 3.4.1 is now complete. 
Remark 3.4.12 The solutions of (3.13) that we have found are explicitly known.
Elementary computations show that a solution is given, for a suitable constant c > 0,
by
c
U (x) = 
 N−2 ,
1 + |x|2 2
and it can be proved (it is not easy at all) that this function indeed solves the minimization problem (3.16).
Actually all the solutions of (3.16) are known: they are the family of functions
N−2

Uλ,y (x) = λ 2 U (λ(x − y))
for each y ∈ RN and each λ > 0. Note that they are generated by the function u
above by translations and scalings (see e.g. [29]).

3.4.2 A Problem with a Radial Coefficient
We now use the results of the previous section to deal with a problem that depends
on a radial coefficient. It is a simple variant of (3.13).
We consider

∗
−u = β(|x|)|u|2 −2 u,
(3.21)
1,2
N
u ∈ D (R ),
where β satisfies the following assumptions

130

3

Minimization Techniques: Lack of Compactness

(b1 ) β : [0, +∞) → [0, +∞) is continuous.
(b2 ) β(r) > β(0) for all r > 0 and limr→+∞ β(r) = β(0).
r
−r satisfy the above
For example, the functions β(r) = C + 1+r
2 or β(r) = C +re

assumptions for every C ≥ 0. Hypothesis (b2 ) can be weakened, see Remark 3.4.22
below.
We will prove the following result.

Theorem 3.4.13 Assume that (b2 ) and (b2 ) hold. Then there exists a nonnegative
and nontrivial u ∈ Dr that solves weakly Problem (3.21), namely such that


∗
∇u · ∇v dx =
β(|x|)u2 −1 v dx
(3.22)
RN

RN

for every v in D 1,2 (RN ).
To prove this result we cannot use the symmetrization technique as in the previous section, that is, we cannot apply Theorem 3.1.5. The reason is the fact that, if
v ∈ D 1,2 (RN ) and v = u∗ (see Theorem 3.1.5), it is true that u 2 ≤ v 2 but the
equality


∗
2∗
β(|x|)u dx =
β(|x|)v 2 dx
RN

RN

does not hold.
Hence we adopt a different strategy: we will study the variational problem not in
the space D 1,2 (RN ) but directly in the space Dr . Of course this is possible because
the problem is invariant under rotations.
We begin by introducing the following definition. For every positive number
b > 0 we set


∗
2
1,2
N
u ∈ D (R ),
Sb = inf u
|u|2 dx = b .
RN

Notice that S1 coincides with the number S defined in the previous section. We will
always write S instead of S1 in order to be consistent with the results of Sect. 3.4.1.
The following lemma establishes the behavior of minimizers when b changes.
Lemma 3.4.14 For every b > 0,
N−2

1. Sb = b N S.
∗
2. If u1 is the minimizer for S found in Theorem 3.4.1, and vb (x) = b1/2 u1 (x), the
function vb is a minimizer for Sb , namely

∗
|vb |2 dx = b and
vb 2 = Sb .
RN

3. There results


Sb = inf


u 2 u ∈ Dr ,

∗

RN

|u|2 dx = b .

3.4 Problems with Critical Exponent

131

Proof As it has been sketched in Remark 2.3.6, it is easy to see that for all a, b > 0
there results
Sb
Sa
= N−2 ,
N−2
a N
b N
so for a = 1 we obtain the claim. The proof of the second part is obvious, and the
third part easily derives from the fact that u1 and vb are radial functions.

We now define the number


S = inf u 2 u ∈ Dr ,

∗

RN

β(|x|)|u|2 dx = 1

and we show that S is attained.
We start the argument by setting, in case β(0) > 0,
β0 = β(0)
and we first compare S to Sβ −1 .
0

Lemma 3.4.15 We have S < Sβ −1 .
0

Proof Let w be a nonnegative radial minimizer for Sβ −1 , that is, w ∈ Dr \{0}, w ≥ 0,
0

∗
β0 w 2 dx = 1 and w 2 = Sβ −1 .
RN

0

From (b2 ) we see that




2∗

RN

β(|x|)w dx >

We define now

∗

RN


μ=

∗

RN

1/2∗

β(|x|)w 2 dx

so that μ > 1, and v = w/μ. Then

RN

β0 w 2 dx = 1.

,

∗

β(|x|)v 2 dx = 1

and therefore
S≤ v 2=

1
w 2 < Sβ −1 .
0
μ2



We can now repeat the arguments of the previous section, and we give the details
only in case something different has to be done. As a first thing, arguing as we did
in Lemmas 3.4.5 and 3.4.6, we obtain the following result.
Lemma 3.4.16 There exist a minimizing sequence {uk }k ⊂ Dr for S and a function
u ∈ Dr such that

132

3

Minimization Techniques: Lack of Compactness

• uk ≥ 0, u ≥ 0.
∗
u in D 1,2 (RN ) and in L2 (RN ), and uk (x) → u(x) a.e. in RN .
• uk
• for all j ∈ N the sequences


2
|∇uk | dx
and
|∇uk |2 dx
|x|<1/j

|x|>j

k

k

admit finite limits as k → ∞.
We continue with the analogue of Lemma 3.4.7.
Lemma 3.4.17 The following limits exist and are finite:

∗
1. ν0 = limR→0+ (lim supk |x|<R β(|x|)|uk |2 dx),

∗
ν∞ = limR→+∞ (lim supk |x|≥R β(|x|)|uk |2 dx),

2. μ0 = limR→0+ (lim supk |x|<R |∇uk |2 dx),

μ∞ = limR→+∞ (lim supk |x|≥R |∇uk |2 dx).
Moreover, ν0 , ν∞ ∈ [0, 1] and
3. if β(0) = 0 then ν0 = ν∞ = 0.
Proof The argument is exactly the same as that of Lemma 3.4.7. We have only to
prove the last claim. Assume β(0) = 0 and take ε > 0 and rε , Rε > 0 such that
β(r) ≤ ε

∀r ∈ [0, rε ] ∪ [Rε , +∞)

which is possible by (b2 ). Define



M = sup
k

∗

RN

|uk |2 dx .

Then, for all 0 < R1 < rε and all R2 > Rε we have


∗
β(|x|)|uk |2 dx ≤ Mε and
|x|<R1

|x|>R2

∗

β(|x|)|uk |2 dx ≤ Mε,

so that ν0 ≤ Mε and ν∞ ≤ Mε. This holds for all ε > 0 and the claim follows.



This allows us to prove the same limit relations on the above quantities as we did
in the previous section. We collect all the results in a single statement.
Lemma 3.4.18 There results

∗
1≤
β(|x|)|u|2 dx + ν0 + ν∞ ;
N
R
S≥
|∇u|2 dx + μ0 + μ∞ ;
RN
2/2∗
Sν0 ≤ μ0 ,

2/2∗

Sν∞

≤ μ∞ .

Lemma 3.4.19 Only the following three cases can occur: either

3.4 Problems with Critical Exponent

133


∗
• RN β(|x|)u2 dx = 1 and ν0 = ν∞ = 0,

∗
• or ν0 = 1 and RN β(|x|)u2 dx = ν∞ = 0,

∗
• or ν∞ = 1 and RN β(|x|)u2 dx = ν0 = 0.


Proof Same as that of Lemma 3.4.11.
The only result that requires a new proof is the next one.
Lemma 3.4.20 There results



ν0 = ν∞ = 0 and

∗

β(|x|)|u|2 dx = 1.

RN

Proof We argue by contradiction. If the claim is not true, then by the previous
lemma we have

∗
β(|x|)|u|2 dx = 0,
RN

2∗

that is β(|x|)|u| = 0 a.e., and ν0 = 1 or ν∞ = 1. Hence, by Lemma 3.4.17, we
have β(0) = β0 > 0, so, by Lemma 3.4.15, S < Sβ −1 . We claim that
0

∗
lim
β0 |uk |2 dx = 1.
(3.23)
k

RN

Indeed we have


∗
1=
β(|x|)|uk |2 dx =
RN

RN

so we have to prove that



∗

β0 |uk |2 dx +



lim
k

∗

RN

(β(|x|) − β0 )|uk |2 dx,

∗

RN

(β(|x|) − β0 )|uk |2 dx = 0.

To this aim, fix ε > 0 and take rε , Rε > 0 such that β(r) − β0 ≤ ε for all r ∈ [0, rε ]
and all r ∈ [Rε , +∞), and define

∗
M = sup
|uk |2 dx .
RN

k

Then


0≤

∗

RN

(β(|x|) − β0 )|uk |2 dx


=

|x|<rε

∗

(β(|x|) − β0 )|uk |2 dx
rε <|x|<Rε



+



∗

(β(|x|) − β0 )|uk |2 dx +
2∗

|x|>Rε

(β(|x|) − β0 )|uk | dx



∗

(β(|x|) − β0 )|uk |2 dx.

≤ 2Mε +
rε <|x|<Rε

134

3

Minimization Techniques: Lack of Compactness
∗

In the bounded set Aε = {x ∈ RN | rε < |x| < Rε } the functions β(|x|)|uk |2 are uni∗
formly bounded and they converge pointwise to β(|x|)|u|2 = 0, so that, by dominated convergence,

∗
lim
(β(|x|) − β0 )|uk |2 dx = 0,
k

rε <|x|<Rε

which yields


0 ≤ lim sup

∗

RN

k

(β(|x|) − β0 )|uk |2 dx ≤ 2Mε.

Since this holds for all ε > 0,

∗
(β(|x|) − β0 )|uk |2 dx = 0,
lim
k

RN

which concludes the proof of (3.23). Now we can finish the proof of the lemma.
∗
∗
Define μk = ( RN β0 |uk |2 dx)1/2 and vk = uk /μk . We have

∗
β0 |vk |2 dx = 1
RN

and therefore
1
uk 2 → S.
μ2k

Sβ −1 ≤ vk 2 =
0

This shows that Sβ −1 ≤ S, a contradiction.



0

Since



∗

RN

β(|x|)|u|2 dx = 1,

arguing as in Chap. 2 we can conclude that there exists u ∈ Dr \{0}, u ≥ 0, such that


∗
∇u · ∇v dx =
β(|x|)u2 −1 v dx
(3.24)
RN

RN

for all v ∈ Dr . We now want to prove that this equation is satisfied for all v in
D 1,2 (RN ). This is carried out in the following lemma, which is a particular case of
the “principle of symmetric criticality” by Palais [38], see also [48].
Lemma 3.4.21 Equation (3.24) holds for every v ∈ D 1,2 (RN ).
Proof Let us consider the functional I : D 1,2 (RN ) → R defined by

1
1
∗
2
β(|x|)|u|2 dx
I (u) = u − ∗
N
2
2 R
and let Ir be its restriction to Dr . By (3.24) we have Ir (u) = 0. We want to prove
that also I  (u) = 0, that is, ∇I (u) = 0 in D 1,2 (RN ). For this, we claim that ∇I (u)
is a radial function.

3.4 Problems with Critical Exponent

135

To prove the claim, we take a rotation of RN with matrix R and we denote its
transpose by S. Of course, S = R −1 .
We set fR (x) = f (Rx) for all f ∈ D 1,2 (RN ) and we prove that for all such R
and for all f, g ∈ D 1,2 (RN ) there results


∇fR · ∇g dx =
∇f · ∇gS dx.
(3.25)
RN

RN

We check (3.25) for smooth f, g, the general case being easily obtained by density.
An easy computation gives
∇fR (x) = S∇f (Rx),
and hence
∇fR (x) · ∇g(x) = S∇f (Rx) · ∇g(x) = ∇f (Rx) · R∇g(x).
Integrating and changing variables yields



∇fR (x) · ∇g(x) dx =
∇f (Rx) · R∇g(x) dx =
∇f (x) · R∇g(Sx) dx
RN
RN
RN

=
∇f (x) · ∇gS (x) dx.
RN

This means
(fR |g) = (f |gS ),
where (·|·) is the scalar product in D 1,2 (RN ).
To prove that ∇I (u) is radial we have to prove that, for all rotations R,
∇I (u) = (∇I (u))R ,
that is



(∇I (u)|v) = (∇I (u))R v

for all v ∈ D 1,2 (RN ). Recalling that u is a radial function, we compute


(∇I (u))R v = (∇I (u)|vS ) = I  (u)vS


2∗ −1
2∗ −1
= (u|vS ) −
β(|x|)u
vS dx = (uR |v) −
β(|x|)uR
v dx
N
N
R
R

∗
= (u|v) −
β(|x|)u2 −1 v dx = I  (u)v = (∇I (u)|v).
RN

This shows that ∇I (u) is radial.
Now it is easy to conclude the proof. We have
0 = Ir (u)(∇I (u)) = I  (u)(∇I (u)) = (∇I (u) | ∇I (u)) = ∇I (u) 2 ,
so ∇I (u) = 0, namely I  (u)v = 0 for all v ∈ D 1,2 (RN ).



136

3

Minimization Techniques: Lack of Compactness

Remark 3.4.22 Hypothesis (b2 ) can be weakened in the sense that it is not necessary to assume β(r) > β(0) for all r > 0 but it is enough that β(r) ≥ β(0) for all
r > 0 and β(r0 ) > β(0) for some r0 > 0. Indeed, if we assume this weaker condition, as we know that the minimizer for S is everywhere strictly positive (see
Remark 3.4.12), in Lemma 3.4.15 we obtain


∗
∗
β(|x|)w 2 dx >
β0 w 2 dx,
RN

RN

and this is all we need to conclude.

3.4.3 A Nonexistence Result
If one tries to attack the analogue of problem (3.13) on a bounded domain , namely
the problem

∗
−u = |u|2 −2 u in ,
(3.26)
u=0
on ∂,
one realizes quickly that the methods used in Sect. 3.4.1 break down.
The question that one has to face is then: are there more powerful techniques that
allow one to solve (3.26), or does something really happen when the growth of the
nonlinearity reaches the critical value 2∗ ?
In this section we show, via a classical argument, that no method can produce a
nontrivial solution to (3.26), for example when  is a ball. In other words, when
power nonlinearities are considered, the value 2∗ represents a threshold beyond
which existence of nontrivial solutions may fail. For the sake of simplicity we limit
ourselves to the nonexistence of solutions of constant sign; the general case requires
some technical arguments that are beyond the scope of this book.
We begin by describing the class of sets  to which the argument applies.
Definition 3.4.23 We say that an open subset  of RN is starshaped with respect to
a point x0 ∈  if for every x ∈ , the segment joining x0 to x, namely the set
{λx + (1 − λ)x0 | λ ∈ [0, 1]}
is entirely contained in .
One says that  is strictly starshaped with respect to x0 ∈  if for every x ∈ ,
the segment
{λx + (1 − λ)x0 | λ ∈ [0, 1)}
is entirely contained in .
Normally one assumes that 0 ∈ , and requires  to be strictly starshaped with
respect to 0. In this case the definition reads
x ∈  implies λx ∈  ∀λ ∈ [0, 1).

3.4 Problems with Critical Exponent

137

Convex sets are starshaped with respect to every internal point, and strict convexity
implies strict starshapedness. However it is easy to see that there are starshaped sets
that are not convex (those that look like a star, exactly).
The main property that we are going to use is contained in the following lemma.
The reader can prove it as an exercise or consult [18].
Lemma 3.4.24 Assume that  ⊂ RN is smooth and strictly starshaped with respect
to 0. Let ν(x) denote the outward normal to ∂ at x. Then
ν(x) · x > 0 ∀x ∈ ∂.
The main nonexistence result is the following.
Theorem 3.4.25 Assume that  ⊂ RN , with N ≥ 3, is open, bounded, smooth and
strictly starshaped with respect to 0. Then the problem
⎧
∗
⎨ −u = |u|2 −2 u in ,
(3.27)
u>0
in ,
⎩
u=0
on ∂
has no solutions in H01 ().
The proof of this theorem is based on a regularity result, which asserts that any
weak H01 () solution is in fact of class C 2 on  (see [45]), and on an integral identity established in [39] that we now describe. If one wants to bypass the regularity
argument, one can read the above theorem simply as follows: problem (3.27) has no
smooth solutions. Of course the same result holds for negative solutions, with the
same proof.
Theorem
 t 3.4.26 (Pohožaev identity [39]) Let f : R → R be continuous and let
F (t) = 0 f (s) ds. Assume that  ⊂ RN is open and bounded. If u ∈ C 2 () is a
solution of the problem

−u = f (u) in ,
(3.28)
u=0
on ∂,
then


  2

∂u
N −2
|∇u|2 dx − N F (u) dx = −
ν(x) · x dσ.
2


∂ ∂ν

(3.29)

Proof The proof consists in multiplying the equation in (3.28) by ∇u · x and integrating by parts by means of the Green’s formula (Theorem 1.2.5). We begin with
the left-hand side. We have



∂u
− u ∇u · x dx = ∇u · ∇(∇u · x) dx −
∇u(x) · x dσ. (3.30)


∂ ∂ν
Now

138

3

Minimization Techniques: Lack of Compactness

N


N 

∂ 2u
∂
∂  ∂u
∂u
(∇u · x) =
xi =
xi +
δij
∂xj
∂xj
∂xi
∂xj ∂xi
∂xi
i=1

=

N

i=1

i=1

∂ 2u
∂u
xi +
,
∂xj ∂xi
∂xj

so that

N

 ∂ 2u
∂u
∇u · ∇(∇u · x) =
xi +
∂xj
∂xj ∂xi
∂xj
j =1
i=1
 N 
 
N

∂ 1  ∂u 2
=
xi + |∇u|2
∂xi 2
∂xj
N

∂u

i=1

j =1





1 2
1 
1 
2
2
2
= ∇ |∇u| · x + |∇u| = ∇ |∇u| · ∇ |x| + |∇u|2 .
2
2
2
Using again the Green’s formula we obtain

∇u · ∇(∇u · x) dx







1 2
1
2
2
= |∇u| dx +
∇ |∇u| · ∇ |x| dx
2 
2






N
1
∂
1
= |∇u|2 dx +
|x|2 dσ −
|∇u|2
|∇u|2 dx
2 ∂
∂ν 2
2 



2−N
1
=
|∇u|2 dx +
|∇u|2 ν(x) · x dσ,
2
2 ∂


(3.31)

because ( 12 |x|2 ) = N .
Now we notice that since u = 0 on ∂, we have ∇u(x) = ∂u
∂ν (x)ν(x) for every
∂u
x ∈ ∂, so that |∇u| = | ∂u
|
and
∇u
·
x
=
ν(x)
·
x
on
∂.
Taking
this into account
∂ν
∂ν
and inserting (3.31) into (3.30) we see that



2−N
1
2
− u ∇u · x dx =
|∇u| dx +
|∇u|2 ν(x) · x dσ
2
2 ∂



∂u
−
∇u(x) · x dσ
∂ ∂ν

  2
∂u
2−N
1
=
|∇u|2 dx −
ν(x) · x dσ.
(3.32)
2
2 ∂ ∂ν

The treatment of the right-hand side is much easier. Indeed we have


1
f (u)∇u · x = ∇(F (u)) · x = ∇(F (u)) · ∇ |x|2 ,
2
so that by the Green’s formula,

3.4 Problems with Critical Exponent

139



1
∇(F (u)) · ∇ |x|2 dx
 2 


∂ 1 2
F (u)
=
|x| dσ − N F (u) dx
∂ν 2
∂ 

= −N F (u) dx,




f (u)∇u · x dx =


(3.33)



since F (u(x)) = F (0) = 0 on ∂. Putting together (3.32) and (3.33), we conclude
that multiplying the equation by ∇u · x yields

  2

∂u
N −2
2
|∇u| dx − N F (u) dx = −
ν(x) · x dσ,
2


∂ ∂ν


as we wanted to prove.

Proof of Theorem 3.4.25 Let u ∈ H01 () solve (3.27). By regularity results (see
[45]), we can assert that u ∈ C 2 (). Applying Theorem 3.4.26, with
1
∗
∗
f (u) = |u|2 −2 u and F (u) = ∗ |u|2
2
yields
  2


∂u
N
N −2
∗
|∇u|2 dx − ∗ |u|2 dx = −
ν(x) · x dσ.
2
2


∂ ∂ν
Multiplying the equation in (3.27) by u and integrating shows that


∗
2
|∇u| dx = |u|2 dx,




which we can insert in the preceding formula to obtain


  2
N −2 N
∂u
∗
− ∗
|u|2 dx = −
ν(x) · x dσ.
2
2

∂ ∂ν
But
N −2 N
− ∗ =0
2
2
by definition of 2∗ , so that
  2
∂u
ν(x) · x dσ = 0.
∂ ∂ν
Since  is strictly starshaped with respect to 0, we have ν(x) · x > 0 everywhere on
∂, and then, necessarily,
∂u
(x) = 0 ∀x ∈ ∂.
∂ν
We conclude by integrating the equation in (3.27) and using again the Green’s formula. We obtain 


∂u
2∗ −2
dσ = 0.
|u|
u dx = − u dx = −


∂ ∂ν
Since u is positive in , this is impossible.


140

3

Minimization Techniques: Lack of Compactness

Remark 3.4.27 What about non starshaped domains? This question has been the object of intense research starting in the eighties. Celebrated results (see the references
at the end of the chapter) first showed that if the set  is an annulus, or has a small
hole, then problem (3.27) has a solution. The most general result states that if 
has nontrivial topology in some appropriate sense, then the problem is still solvable.
So for a while it seemed that the relevant point was the topology of . But then
other results showed that the problem still has a solution when  has trivial topology (e.g., is contractible), but looks like a noncontractible domain, for example an
annulus with a thin radial slice removed. Summing up, the solvability of problems
with critical growth is a very delicate matter and depends subtly on the data of the
problem.

3.5 Exercises
1. Assume that N ≥ 3. Prove that there exists a constant C > 0 such that


u2
dx
≤
C
|∇u|2 dx ∀u ∈ D 1,2 (RN ).
2
RN |x|
RN

(3.34)

This is the celebrated Hardy inequality. Hint: assume first that u ∈ C0∞ (RN )
and notice that left-hand side is finite. Write, for λ > 0 and x ∈ RN ,
 +∞
 +∞
d 2
2
u (λx) dλ = −2
u(λx)∇u(λx) · x dλ.
u (x) = −
dλ
1
1
Then divide by |x|2 and integrate over RN setting y = λx. Conclude by density.
2. Use the Hardy inequality (3.34) to prove that the expression


1
(u|v) =
∇u · ∇v dx +
uv dx
2
RN
RN |x|
defines a scalar product in D 1,2 that induces a norm equivalent to the standard
one. Then
(a) Let u = (u|u)1/2 . For every u ∈ D 1,2 (RN ) and every λ > 0 define
N−2

uλ (x) = λ 2 u(λx).
Prove that uλ = u for every λ > 0.
(b) Define


∗
C = inf u 2 u ∈ D 1,2 (RN ), |u|2 = 1 .


Prove that C > 0.
3. Using the notation and the results of Exercise 2, find a radial non negative and
non trivial solution of the problem
⎧
⎪ −u + 1 u = |u|2∗ −2 u,
⎨
|x|2
⎪
⎩
u ∈ D 1,2 (RN ).

3.5 Exercises

141

Hint: define Dr = {u ∈ D 1,2 (RN ) | u is radial},


∗
R = inf u 2 u ∈ Dr , |u|2 = 1 ,


and adapt the lemmas and arguments of the proof of Theorem 3.4.1. In the
paper [47] the reader can find the complete classification of radial and positive
solutions of this problem.
4. Let f : R → R be a continuous function such that
∗

|f (t)| ≤ C |t|2 −1 ∀t ∈ R
t
for some C > 0. Define F (t) = 0 f (s)ds and J : D 1,2 (RN ) → R as

F (u) dx.
J (u) =
RN

(a) Prove that J is a differentiable functional with

f (u)v dx ∀u, v ∈ D 1,2 (RN ).
J  (u)v =
RN

(b) Define M = {u ∈ D 1,2 (RN ) |



m = inf{ u 2 | u ∈ M}, where

RN F (u) dx = 1}, assume M = ∅ and define
u is the norm in D 1,2 (RN ). Prove that

m > 0.
(c) Assume that there exists u ∈ M such that

u 2 = m and
f (u)u dx = 0.
RN

Prove that u is a weak solution of the nonlinear eigenvalue problem

−v = λf (v),
v ∈ D 1,2 (RN ).

Hint: define ϕ(s, t) = RN F (t (u + sv))dx, for (s, t) in a neighborhood of
(0, 1).

(d) For every σ > 0 define uσ (x) = u(x/σ ). Prove that if RN f (u)u dx > 0,
then there is a σ > 0 such that uσ is a solution of the problem

−v = f (v),
v ∈ D 1,2 (RN ).
5. Let 2 < p < 2∗ < q and define a continuous function f : R → R by
f (t) = min{t p−1 , t q−1 } for t ≥ 0,
f (−t) = −f (t) for t < 0.
t
Define F (t) = 0 f (s)ds.
∗
(a) Prove that |f (t)| ≤ |t|2 −1 for all t ∈ R, and compute F (t).
(b) Consider a sequence {uk } ⊂ Dr such that uk
u in Dr , and prove that


F (uk ) dx →
F (u) dx.
RN

RN

142

3

Minimization Techniques: Lack of Compactness
N−2

Hint: notice that both uk and u satisfy the inequality |v(x)| ≤ C/|x| 2 , for
a suitable C > 0. Hence you can fix R > 0 such that both uk and u satisfy
|v(x)| < 1 if |x| > R. Write



F (uk ) dx =
F (uk ) dx +
F (uk ) dx
RN

|x|≤R

|x|>R

and apply dominated convergence in the right-hand side integrals, noticing
p
also that |F (t)| ≤ a + b|t|
 for suitable a, b > 0 and all t.
(c) Define Mr = {u ∈ Dr | RN F (u) dx = 1}. Prove that Mr = ∅.
(d) Define


mr = inf u 2 | u ∈ Mr ,
where u is the norm in D 1,2 (RN ). Notice that, as in the previous exercise,
mr > 0. Show that there exists u ∈ Mr , u ≥ 0, such that u 2 = mr .
(e) Using the arguments of the previous exercise and of Sect. 3.4.2, prove that
there exists a non trivial and non negative solution of the problem

−v = f (v)
v ∈ Dr .
6. Let q : RN → R be continuous, strictly positive and such that
lim|x|→∞ q(x) = 0. For λ ≥ 0 and p ∈ (2, 2∗ ), consider the problems

−u + (1 + λq(x))u = |u|p−2 u,
u ∈ H 1 (RN ).
Weak solutions of these problems are, for example, critical points of the functionals Qλ : H 1 (RN ) \ {0} → R defined by


2
+ RN (1 + λq(x))u2 dx
RN |∇u| dx

Qλ (u) =
.
( RN |u|p dx)2/p
(a) Prove that for every λ > 0,
inf

u∈H 1 (RN )\{0}

Qλ (u) =

inf

u∈H 1 (RN )\{0}

Q0 (u).

(b) Prove that for every λ > 0, Qλ has no global minimum on H 1 (RN ) \ {0}.
2
. Prove that
7. Let p ∈ (2, 2∗ ) and let a : RN → R be the function a(x) = 1+|x|
2+|x|2
the functional Q : H 1 (RN ) \ {0} → R defined by


2
2
RN|∇u| dx + RN u dx
Q(u) =
( RN a(x)|u|p )2/p dx
has no global minimum.
8. Let U : RN → R, with N ≥ 3, be defined by
U (x) =

C
N−2

(1 + |x|2 ) 2

,

3.6 Bibliographical Notes

143

where C is a positive constant. Show that U ∈ D 1,2 (RN ) and that U solves
∗

−U = U 2 −1

in RN

(3.35)

N−2

if and only if C = (N (N −2)) 4 . Show that for every y ∈ RN and every λ > 0,
the scaled functions
N−2

Uλ,y (x) = λ 2 U (λ(x − y))
are all solutions of (3.35).
9. Assume that  is as in Theorem 3.4.25. Show that the problem

−u = |u|p−2 u in ,
u=0
on ∂
has no C 2 () solutions if p > 2∗ .
10. Assume that  is as in Theorem 3.4.25 and let q ∈ C 1 (). Show that the problem

∗
−u + q(x)u = |u|2 −2 u in ,
u=0
on ∂
has no C 2 () solutions if ∇q(x) · x + 2q(x) > 0 in .

3.6 Bibliographical Notes
• Section 3.1: The problems dealt with in the first three sections of this chapter
belong to the family of nonlinear Schrödinger equations, appearing for example
in nonlinear optics. This is an intense and active field of research at the time of
this writing. The reader who wishes to broaden his/her knowledge on these topics
is referred to Ambrosetti and Malchiodi [3], and to the references therein.
• Section 3.3: Problems like (3.6), and more generally subcritical problems on unbounded domains are studied extensively in Lions [31, 32], where the classical
tool of concentration–compactness was introduced. A book entirely devoted to
problems on unbounded domains is Kuzin and Pohožaev [27]. The type of equations described in this section contains the so called scalar field equations of
physics; a more complete treatment can be found in the papers by Berestycki
and Lions [9, 10].
• Section 3.4: The paper that more than any other motivated research on problems
with critical growth is Brezis and Nirenberg [14]. The interested reader can find
many other examples and results in Brezis [12, 13]. The effect of the topology of
the domain on the existence of solutions for problems with critical exponent is a
deep phenomenon. Cornerstones in this sense are the work by Coron [15] (existence on domains with a small hole), and the difficult Bahri and Coron [6] (existence when the topology of the domain is nontrivial). An example of a contractible
domain on which problem (3.26) admits a solution can be found in Dancer [16].

Chapter 4

Introduction to Minimax Methods

This chapter is an introduction to a broad class of methods that have been shown to
be extremely useful in a variety of contexts.
We confine ourselves to the simplest cases, but we will try to motivate the ideas
involved in the construction of the main tools, so that the interested reader can turn
to the study of more complex problems with a minimum of background.
In the preceding sections we have (almost) always looked for critical points of
a functional as minimum points, either on the whole space, or suitably restricting
the functional to sets where minima could be shown to exist. Roughly speaking,
minimax methods are devoted to the search of critical points that are not global
minima, for example saddle points. The procedure to do this is quite elaborate, and
we will introduce the main steps gradually.
We begin with the following example, which has been, historically, one of the
main motivations for the development of the theory.
Suppose that  is a bounded open set of RN , with N ≥ 3, and that we want to
find a solution u of the problem

−u + q(x)u = |u|p−2 u in ,
(4.1)
u=0
on ∂,
where q is continuous and nonnegative and p ∈ (2, 2∗ ). We know that solutions
arise as critical points of the functional



1
1
1
1
1 p
2
2
J (u) =
|∇u| dx +
q(x)u dx −
|u|p dx = u 2 − |u|p .
2 
2 
p 
2
p
Of course, we already know at least two methods that can be used to solve
Problem (4.1), and these are minimization on spheres or on the Nehari manifold
(both discussed in Sect. 2.3). These methods allow one to overcome the fact that
infH 1 () J = −∞ by constraining J on suitable sets where it becomes bounded
0
from below; at this point minimization arguments can be profitably used.
We now wish to take a different point of view, which consists in looking at J as
a free (unconstrained) functional on the whole space H01 ().
M. Badiale, E. Serra, Semilinear Elliptic Equations for Beginners, Universitext,
DOI 10.1007/978-0-85729-227-8_4, © Springer-Verlag London Limited 2011

145

146

4 Introduction to Minimax Methods

We start by noticing that since (4.1) admits the trivial solution u ≡ 0, the function
u ≡ 0 must be a critical point of J . What kind of critical point is it? Or, in other
words, what is the variational characterization of the trivial solution?
To answer these questions we recall that by the Sobolev inequalities and our
assumptions on p, there exists a constant C > 0 such that
|u|p ≤ C u ,

for every u ∈ H01 ().

Therefore,



Cp
1 p 1
Cp
1
2
2
p
2 1
p−2
.
u ≥ u
−
u
J (u) = u − |u|p ≥ u −
2
p
2
p
2
p

Since p > 2, this shows that if u is small enough, J (u) ≥ 0 = J (0) (strictly if
u = 0). Thus the trivial solution, seen as a critical point of J , is a strict local minimum.
The second remark is that since J is unbounded from below, there certainly exists
a point v, as far as we like from zero, where J (v) < 0.
Now if J were defined on a one-dimensional space, this would imply at once the
existence of at least a second critical point; to visualize it think of the real function
f (x) = x 2 − x 4 , with x ∈ R.
On an n-dimensional space the existence of a strict local minimum for a function
unbounded from below suggests the existence of a second critical point, although
this is in general false. As an example where everything works fine, we can consider
in the plane the function g(x, y) = x 2 + y 2 − x 4 .
The idea is to try to carry this “guess” to an infinite dimensional context. To
do this we will have to introduce a variety of concepts and to reason about the link
between the topological properties of certain sets and the existence of critical points.
These concepts will be introduced at a rather abstract level in the following section.

4.1 Deformations
We begin with a definition; we work for the moment in the context of Banach spaces,
while later, when we need more structure, we will turn to Hilbert spaces.
Definition 4.1.1 Let X be a Banach space and let J : X → R be a functional. For
a ∈ R, we define
J a = {u ∈ X | J (u) ≤ a}.
The sets J a are called the sublevel sets of J , or simply the sublevels of J . Any point
u ∈ J −1 (a) is said to be a point at level a.
In the sequel we will be interested in topological properties of the sublevel sets of
a functional and, mostly, in the relationships between topological properties of sublevels and presence of critical points. To make this clearer we consider an example
in dimension one.

4.1 Deformations

147

Example 4.1.2 Consider the function f : R → R defined by f (x) = x 3 − 3x. It has
two critical points, x = ±1 at the levels ∓2, respectively. For a > 2 or a < −2,
the sublevels f a are intervals of the type (−∞, x0 ] (x0 depends on a of course).
If, on the contrary, a ∈ (−2, 2), then f a is a set of the type (−∞, x1 ] ∪ [x2 , x3 ],
with x1 < x2 . So, for |a| > 2 the sublevels f a are connected, while for |a| < 2 they
are disconnected. This is expressed by saying that there is a change of topology in
the sublevels when a passes through ±2, which are exactly the levels of the critical
points of f .
On the other hand, it is easy to accept (visually, for smooth functions of one
variable) that if there are no critical points with levels in [a, b], then f a and f b
should “have the same topology”. This is because “nothing happens” to the graph
of f in the strip R × [a, b].
The previous example suggests that a change in the topology of the sublevel sets
of a function implies the presence of a critical point. Unfortunately, this elegant
principle is false.
Example 4.1.3 Draw the graph the real function f (x) = xe1−x . For a ∈ (0, 1) the
sublevels f a are all disconnected, while for a < 0 they are connected. Yet there is
no critical point at level zero.
Looking carefully at this example shows that actually there is some kind of critical point at level zero also in this case. Indeed there exists a sequence xk such that
f (xk ) → 0 and f  (xk ) → 0. The problem is that this sequence of “almost critical
points” escapes to +∞, namely it is divergent. One often says that there is a critical point at infinity, where the precise meaning of this term is the existence of a
sequence like xk .
This type of sequences are very important in Critical Point Theory, and they
deserve a name of their own.
Definition 4.1.4 Let X be a Banach space and let J : X → R be a differentiable
functional. A sequence {uk }k ⊆ X such that
{J (uk )}k

is bounded (in R) and



J (uk ) → 0 (in X  ) as k → ∞,
is called a Palais–Smale sequence for J .
Let c ∈ R. If
J (uk ) → c

(in R)

and

J  (uk ) → 0 (in X  ) as k → ∞,
then {uk }k is called a Palais–Smale sequence for J at level c. In this case c is called
a Palais–Smale level for J .

148

4 Introduction to Minimax Methods

Remark 4.1.5 In a Hilbert space H we can identify the differential with the gradient
via the scalar product. Therefore the second property of a Palais–Smale sequence
reads
∇J (uk ) → 0 in H.
We point out that the convergence takes place in the strong topology of H .
Example 4.1.6 Consider again the real function f (x) = xe1−x . It has only one critical point, x = 1 and its level is f (1) = 1.
The sequence xk = 1 − 1/k is a Palais–Smale sequence for f at level 1. It converges to the critical point x = 1. The sequence xk = k is a Palais–Smale sequence
for f at level zero. It diverges to +∞.
The convergence of Palais–Smale sequences is of course crucial, and is obviously
a property of the functional in question.
Definition 4.1.7 Let X be a Banach space and let J : X → R be a differentiable
functional. We say that J satisfies the Palais–Smale condition (shortly: J satisfies
(PS)) if every Palais–Smale sequence for J has a converging subsequence (in X).
We say that J satisfies the Palais–Smale condition at level c ∈ R (shortly: J satisfies (PS)c ) if every Palais–Smale sequence at level c has a converging subsequence
(in X).
The function f (x) = xe1−x satisfies (PS)1 , but not (PS)0 . We notice that a functional J satisfies the (PS) condition at a certain level also whenever there is no
Palais–Smale sequence at that level (there is nothing to check). With this agreement,
f (x) = xe1−x satisfies (PS)c if and only if c = 0.
The proof of the following lemma is obvious.
Lemma 4.1.8 Let X be a Banach space and let J : X → R be a C 1 functional.
If there exists a Palais–Smale sequence for J and J satisfies (PS), then J has a
critical point. If there exists a Palais–Smale sequence for J at level c and J satisfies
(PS)c , then J has a critical point at level c.
Remark 4.1.9 Although the preceding lemma is trivial, it is of a fundamental importance for what follows. Indeed it shows that the search for critical points can be
split into two independent parts: the existence of Palais–Smale sequences, which
will follow from topological reasons, and the convergence of this sequences, which
is a compactness problem. Moreover, as we will see, the two aspects are completely
unrelated.
We now concentrate on the existence of Palais–Smale sequences, by extending
and making rigorous the heuristic ideas involved in Example 4.1.2.
The first thing to do is to make clear the concept of change of topology, or rather
the converse, namely that two sets have the same topology. Of course this is presented in a form that is suited for our aims.

4.1 Deformations

149

Definition 4.1.10 Let X be a Banach space and let B ⊆ X be a subset. A deformation of B is a continuous function η : [0, 1] × B → B such that η(0, u) = u for all
u ∈ B.
Definition 4.1.11 Let X be a Banach space and let A ⊆ B ⊆ X be subsets. We say
that B is deformable in A if there exists a deformation η of B such that
η(t, u) ∈ A for all u ∈ A and all t ∈ [0, 1],

(4.2)

η(1, u) ∈ A

(4.3)

for all u ∈ B.

It is very useful to visualize the variable t as time and follow the evolution of a
point as time increases. At time zero, η(0, ·) is the identity on B. When t increases
some points start moving, and at t = 1 every point of B has moved to A.
In the previous definition, a most important point is (4.2), for it says that during
the deformation, the points of A can move but cannot leave A.
Example 4.1.12 In a Banach space X, for every r > 0, the ball B2r (0) is deformable
in the ball Br (0). An explicit deformation is η(t, u) = (1 − t/2)u. More generally,
any ball is deformable in any ball contained in it.
Example 4.1.13 Let X be a Banach space and let v satisfy v = 2. Set B = B4 (0),
and A = B1 (v) ∪ B1 (−v), so that A has two connected components. Then B is not
deformable in A. Indeed, since the points of A cannot leave A during the deformation, the set η(1, B) should be disconnected, which is impossible since it is the
image of the connected set B through the continuous function η(1, ·).
From now on we discuss the following problem: given a functional J on a Banach space X, and two real numbers a < b, when is J b deformable in J a ? Suppose that we can find a continuous function η : [0, 1] × J b such that the function
t → J (η(t, u)) is nonincreasing for every u. Such function automatically satisfies
η(t, u) ∈ J a for all u ∈ J a and all t, namely it satisfies (4.2). At first sight it seems
very difficult to find a function with this property. However, in Hilbert spaces there
is a very simple way to do it, through the flow associated to an autonomous differential equation. In a Banach space there are some technical questions to settle, but
essentially the same ideas work. In view of our applications, we limit ourselves to
the case of Hilbert spaces.
Theorem 4.1.14 Let H be a Hilbert space and let F : H → H be a locally Lipschitz
continuous function. Then, for every u ∈ H , the Cauchy problem
 
η = F (η),
(4.4)
η(0) = u
has a unique solution η, which is defined in an open interval I containing 0. It is
customary to think of η as a function of t and u, and write η(t, u). In this case,
η is continuous in (t, u). If F is bounded, i.e. if there is C such that F (u) ≤ C

150

4 Introduction to Minimax Methods

for all u ∈ H , then I = R. The function η(t, u) is called the flow associated to the
differential equation η = F (η), and the curves t → η(t, u) are called the flow lines.
A proof of this result can be found in [11].
Definition 4.1.15 Let H be a Hilbert space and let J : H → R be a functional.
We say that J ∈ C 1,1 (H ) if J ∈ C 1 (H ) and its gradient ∇J : H → H is locally
Lipschitz continuous on H .
By Theorem 4.1.14, if J ∈ C 1,1 (H ), the problem
 
η (t, u) = −∇J (η(t, u)),
η(0, u) = u

(4.5)

has a unique solution defined in an interval I and depending continuously on (t, u).
The flow η is called the (minus) gradient flow, or the steepest descent flow, since
at any time t the velocity η (t) points in the direction of −∇J (η(t)), the direction
along which J decreases the fastest. If η(t, u) is the solution of (4.5), it is easy to
see that the function γ (t) = J (η(t, u)) is strictly decreasing, unless u is a critical
point of J , in which case γ is constant. Indeed,




γ  (t) = ∇J (η(t, u)) | η (t) = − ∇J (η(t, u)) | ∇J (η(t, u))
= − ∇J (η(t, u)) 2 < 0,
if u is not a critical point of J .
Remark 4.1.16 The request that J be of class C 1,1 is used to guarantee the local
uniqueness of solutions to the Cauchy problem (4.5). It is the simplest technical assumption that guarantees this property, and is rather easy to check in many concrete
cases. However, the reader should keep in mind that the whole theory that we are describing can be carried out by assuming only J ∈ C 1 (H ). Moreover the same theory
is not confined to Hilbert spaces, but can be extended quite easily to Banach spaces,
and even Banach manifolds. In all these cases one replaces ∇J with a so-called
pseudo-gradient vector field in the Cauchy problem. The use of a pseudo-gradient
vector field yields both uniqueness in (4.5) and the possibility to work without the
Hilbert structure. We prefer to work in C 1,1 because the construction of a pseudogradient vector field is quite technical and can be considered as a more advanced
topic. The interest reader will find this construction in many texts, for instance
[2, 26, 42, 45].
We can now state and prove the main result of this section. It is the rigorous
formalization of the heuristic ideas discussed in the first part of this section.
Lemma 4.1.17 (Deformation Lemma) Assume that H is a Hilbert space, and let
J ∈ C 1,1 (H ). Let a, b ∈ R, with a < b. Assume that in [a, b] there is no Palais–
Smale level for J , that is, for all c ∈ [a, b] there is no Palais–Smale sequence for J
at level c. Then J b is deformable in J a .

4.1 Deformations

151

Proof We construct a deformation using a variant of (4.5) to have the flow lines
defined for all times. We solve the problem
⎧
⎨ η (t, u) = − ∇J (η(t, u)) ,
1 + ∇J (η(t, u))
(4.6)
⎩
η(0, u) = u,
where η denotes differentiation with respect to t.
If we call F (η) the right-hand side of (4.6), we see that F : H → H is locally
Lipschitz, because ∇J is so, and of course F (u) ≤ 1 for all u. We can then apply
Theorem 4.1.14 to obtain a solution η(t, u) of problem (4.6) defined in all of R.
By definition we have η(0, u) = u for all u, and since


d
∇J (η(t, u)) 2
J (η(t, u)) = ∇J (η(t, u)) η (t, u) = −
≤ 0,
dt
1 + ∇J (η(t, u))
the fact that u is in some J c implies η(t, u) ∈ J c for all t ≥ 0.
We now want to prove that η can be used to construct a deformation of J b in J a .
For every u ∈ J b \J a , we define
T (u) = sup{t ≥ 0 | η(t, u) ∈ J b \J a }.
This could be infinite for some u, in case the flow line η(·, u) never enters J a .
Notice that, by continuity, T (u) > 0 for every u ∈ J b \J a , and for every number
t ∈ [0, T (u)), we have η(t, u) ∈ J b \ J a .
We claim that T (u) is not only finite for every u, but also uniformly bounded, in
the sense that
sup{T (u) | u ∈ J b \ J a } < +∞.

(4.7)

To see this, we first notice that
there exists δ > 0 such that

∇J (u) ≥ δ

for all u ∈ J b \J a .

(4.8)

⊂ J b \J a such that

Indeed, if (4.8) were false, then there would be a sequence {uk }k
∇J (uk ) ≤ 1/k. Passing to a subsequence, we would get J (uk ) → c ∈ [a, b] and
∇J (uk ) → 0; so {uk } would be a Palais–Smale sequence at level c ∈ [a, b], and this
is impossible by assumption.
To go back to the proof of (4.7), fix u ∈ J b \J a and take t ∈ [0, T (u)). Then for
every s ∈ [0, t] there results η(s, u) ∈ J b \J a , so that
∇J (η(s, u)) ≥ δ

for all s ∈ [0, t].

x2
Since the function x → − 1+x
is decreasing for x ≥ 0, this implies
δ2
∇J (η(s, u)) 2

≤−
,
1 + ∇J (η(s, u))
1+δ
and this holds for every s ∈ [0, t]. Hence

 t
 t
∇J (η) 2
d
−
J (η(s, u)) ds =
ds
J (η(t, u)) − J (η(0, u)) ≤
1 + ∇J (η)
0 ds
0

 t
δ2
δ2
≤
−
ds = −t
.
1+δ
1+δ
0
−

152

4 Introduction to Minimax Methods

So, for every t ∈ [0, T (u)),
a < J (η(t, u)) ≤ J (η(0, u)) − t

δ2
δ2
δ2
= J (u) − t
≤b−t
,
1+δ
1+δ
1+δ

namely,
t<

b−a
(1 + δ).
δ2

Setting μ = b−a
(1 + δ), we have proved that for every t ∈ [0, T (u)), there results
δ2
t < μ, which of course implies T (u) ≤ μ, and this holds for all u ∈ J b \J a . Property
(4.7) is proved.
Notice also that, by continuity, J (η(T (u), u)) = a.
We now define η̃ : [0, 1] × J b → J b by
η̃(t, u) = η(μt, u).
From the previous discussion η̃ enjoys the following properties:
• η̃(0, u) = η(0, u) = u for all u ∈ J b .
• η̃(t, u) = η(μt, u) ∈ J a for all u ∈ J a .
• J (η̃(1, u)) = J (η(μ, u)) ≤ J (η(T (u), u)) ≤ a for all u ∈ J b .
As η̃ is continuous, η̃ is a deformation of J b that deforms J b in J a .



In most of the applications we will need a “local” version of the preceding result.
Local here means that we only look at the functional around a certain level set.
Lemma 4.1.18 Assume that H is a Hilbert space, let J ∈ C 1,1 (H ), and let c ∈ R.
Assume that there is no Palais–Smale sequence at level c. Then for every ε > 0 small
enough, the set J c+ε is deformable in J c−ε with a deformation that fixes J c−2ε .
Proof We have to find a continuous η : [0, 1] × H → H such that
• η(0, u) = u for all u,
• η(t, u) = u for all u ∈ J c−2ε and for all t,
• η(t, u) ∈ J c−ε for all u ∈ J c−ε and for all t,
• η(1, u) ∈ J c−ε for all u ∈ J c+ε .
To prove all this, we start by claiming that
there exist ε0 > 0 and δ > 0 such that
∇J (u) ≥ δ

for every u ∈ J c+ε0 \ J c−ε0 .

Indeed, if this is false then we can find positive numbers εk → 0, δk → 0 and a
sequence uk ∈ J c+εk \ J c−εk such that ∇J (u) ≤ δk . In other words, the sequence
{uk } satisfies
J (uk ) → c

and ∇J (uk ) → 0 in H,

namely it is a Palais-sequence at level c, which is impossible by assumption.
We now pick ε ∈ (0, ε0 ), and take a “cut-off” function ψ ∈ C ∞ (R) such that

4.2 The Minimax Principle

153

• 0 ≤ ψ(s) ≤ 1 for all s,
• ψ(s) = 0 in (−∞, c − 2ε],
• ψ(s) = 1 in [c − ε, c + ε].
We then solve the problem
⎧
⎨ η (t, u) = −ψ(J (η(t, u))) ∇J (η(t, u)) ,
1 + ∇J (η(t, u))
⎩
η(0, u) = u.

(4.9)

Once again, the right-hand side of (4.9), is a locally Lipschitz continuous function
of η and is uniformly bounded on H . Then the flow η is well defined and continuous
in R × H .
Noticing that ψ(J (u)) = 0 in J c−2ε , we have that η(t, u) = u for all u ∈ J c−2ε
and all t, namely η fixes J c−2ε .
The other properties can be deduced observing that ψ(J (u)) = 1 whenever
c − ε ≤ J (u) ≤ c + ε, so that one can use Lemma 4.1.17 with a and b replaced
by c − ε and c + ε respectively.

The previous lemma shows that the following alternative holds: either there is
a Palais–Smale sequence at level c, or for every ε > 0 small enough, the sublevel
J c+ε is deformable in J c−ε (and moreover with a deformation that “fixes” J c−2ε ).
Remark 4.1.19 There are many versions of deformations lemmas in the literature,
including some very precise ones, see for example [43, 45]. For our purposes, the
two above lemmas are sufficient, and are simpler than the general results.
Remark 4.1.20 In many textbooks the assumptions of the previous lemma are stated
in the following equivalent form: assume that there are no critical points at level c
and that (PS)c holds. We prefer the statement of Lemma 4.1.18 because it highlights
the central role of Palais–Smale sequences. One can then summarize the principle
by saying that the only obstruction to deformations is the presence of Palais–Smale
sequences.

4.2 The Minimax Principle
We now introduce the minimax procedure, namely the main object of this chapter.
We will do it at a rather abstract level, which has the advantage of producing a very
flexible tool which can be adapted to a variety of situations, even beyond the aims
of this book.
We begin with some definitions.
Definition 4.2.1 Let H be a Hilbert space and let η : [0, 1] × H → H be a deformation of H . A family  of subsets of H is said to be invariant for η if
for every A ∈  and every t ∈ [0, 1],

there results η(t, A) ∈ .

154

4 Introduction to Minimax Methods

Definition 4.2.2 Let H be a Hilbert space and let J : H → R be a functional.
A family  of subsets of H is called a minimax class. The value
c = inf sup J (u)
A∈ u∈A

is called the minimax level associated to ; we also say that  works at level c.
Notice that it may happen that c = +∞ or c = −∞.
Finally we have
Definition 4.2.3 Let H be a Hilbert space, J : H → R a functional,  a minimax
class, and c its minimax level. We say that  is admissible with respect to J if
1. c ∈ R,
2. for every ε > 0 small enough,  is invariant for all deformations that fix J c−2ε .
This last definition contains a rather subtle point. Indeed the deformations for
which a class  should be invariant depend on c, which depends on .
So the deformations for which a class  should be invariant depend on the class
itself. This seems at first rather confusing, but we will see in the applications that
the difficulty disappears as soon as the number c is determined by good topological
properties. The second request in Definition 4.2.3 is extremely useful, because it
reduces the number of deformations for which  must be invariant.
For the moment we go on at an abstract level with the main result of Critical
Point Theory.
Theorem 4.2.4 (Minimax principle) Let H be a Hilbert space and let J ∈ C 1,1 (H ).
Let  be an admissible minimax class at level c. Then there exists a Palais–Smale
sequence for J at level c. If J satisfies (PS)c , then there exists a critical point for J
at level c.
Proof Assume that there is no Palais–Smale sequence at level c. Then we can
choose ε > 0 so small that Lemma 4.1.18 and 2. of Definition 4.2.3 simultaneously
apply. This means that J c+ε is deformable in J c−ε with a deformation η that fixes
J c−2ε and that  is invariant for this η.
By definition of minimax level, there exists a set A ∈  such that
sup J (u) ≤ c + ε,
u∈A

that is, A ⊆ J c+ε . Applying the deformation η to A we obtain
η(1, A) ⊂ η(1, J c+ε ) ⊂ J c−ε ,
which implies
sup J (u) ≤ c − ε.
u∈η(1,A)

4.3 Two Classical Theorems

155

On the other hand, as  is invariant for η, we have that η(1, A) ∈ , so that by
definition of c,
sup J (u) ≥ c.
u∈η(1,A)

This contradiction proves that there must be a Palais–Smale sequence at level c. The
second part of the theorem is obvious, see Lemma 4.1.8.

We will see some classical and particular cases of this principle in the next sections. We just point out that this principle is quite general and unifies different particular approaches that appeared separately in the literature.
Even in “trivial” contexts, it yields some nontrivial consequences, as the next
example shows.
Example 4.2.5 Let H be a Hilbert space and let J ∈ C 1,1 (H ). We consider the
“trivial” minimax class


 = {u} | u ∈ H ,
namely the class of subsets of H consisting of a single point. This class is obviously
invariant for every deformation η, since η(t, {u}) is a singleton for every t, and
hence it still belongs to . Thus the class  is admissible if and only if its minimax
level c is finite. But
c = inf sup J (u) = inf sup J (u) = inf J (u),
{u}∈ u∈{u}

A∈ u∈A

u∈H

so that the class is admissible if and only if J is bounded from below.
The new, often very important information provided by the minimax principle,
is the existence not only of a minimizing sequence, but of a Palais–Smale sequence
at level c = infH J . Thus, from now on, whenever a C 1,1 functional J is bounded
from below, we can conclude that there exists a minimizing sequence {uk }k with the
further noteworthy property that
∇J (uk ) → 0 in H.
This property has a nontrivial proof even for real functions of one variable.

4.3 Two Classical Theorems
In this section we present the two most celebrated results of Critical Point Theory.
We will see how they both fit into the framework given by the minimax principle.
These two results have been generalized in all possible directions, but are still used
very much in their original form.
Theorem 4.3.1 (Mountain Pass Theorem [5]) Let H be a Hilbert space, and let
J ∈ C 1,1 (H ) satisfy J (0) = 0. Assume that there exist positive numbers ρ and α
such that

156

4 Introduction to Minimax Methods

1. J (u) ≥ α if u = ρ;
2. There exists v ∈ H such that v > ρ and J (v) < α.
Then there exists a Palais–Smale sequence for J at a level c ≥ α. If J satisfies (PS)c ,
then there exists a critical point at level c.
Proof We define the minimax class
 = {γ ([0, 1]) | γ : [0, 1] → H is continuous, γ (0) = 0, γ (1) = v}
and the corresponding minimax level
c=

inf

sup

γ ([0,1])∈ u∈γ ([0,1])

J (u) = inf max J (γ (t)).
γ ∈ t∈[0,1]

The sets in  are thus the continuous paths that connect the origin with the point v.
In the last equality we identify γ and γ ([0, 1]), with some abuse of notation, as is
customary to do.
If we prove that  is admissible, we apply the minimax principle, and the proof
is done.
It is obvious that c < +∞, since we maximize a continuous functional on a
compact set. We have to prove that c > −∞. To see this, we notice that every γ ∈ 
satisfies γ (0) = 0 and γ (1) = v > ρ. Since γ is continuous, there exists
tγ ∈ [0, 1] such that γ (tγ ) = ρ. This implies, by assumption 1,
max J (γ (t)) ≥ J (γ (tγ )) ≥ α.

t∈[0,1]

As this holds for every γ ∈ , we can take the infimum with respect to γ ∈  to
obtain
c ≥ α > 0.
We now have to prove that for every ε > 0 small enough,  is invariant for all
deformations that fix J c−2ε .
For this, we take any ε > 0 so small that
J (0) < c − 2ε

and J (v) < c − 2ε,

which is possible because max{J (0), J (v)} = max{0, J (v)} < α ≤ c.
Let now η be a deformation that fixes J c−2ε and take γ ∈ . We have to prove
that, for all t ∈ [0, 1],
η(t, γ ([0, 1])) ∈ ,
which means that η(t, γ ([0, 1])) = γ̃ ([0, 1]) for some γ̃ ∈ . To this aim we define
γ̃ : [0, 1] → H

as γ̃ (s) = η(t, γ (s)).

Of course γ̃ is continuous. Since 0 and v belong to J c−2ε , and η fixes this set, we
have
γ̃ (0) = η(t, γ (0)) = η(t, 0) = 0

4.3 Two Classical Theorems

157

and
γ̃ (1) = η(t, γ (1)) = η(t, v) = v.
Hence γ̃ ([0, 1]) ∈ , and  is an admissible class. We then apply Theorem 4.2.4
and we conclude the proof.

Some comments and remarks are in order.
Remark 4.3.2 The term “mountain pass” is justified by the geometrical properties of
the graph of J . Indeed, it is customary to think of the points 0 and v as two villages.
The assumptions of Theorem 4.3.1 imply that the two villages are separated by a
mountain range: to go from 0 to v one must climb at least at a height α, which is
strictly larger than the heights J (0) and J (v). The minimax class used in the proof
is constructed exactly on this observation: one tries every possible road γ between
0 and v, measures the maximal height reached by the road (maxt∈[0,1] J (γ (t))), and
tries to minimize the maximal height. At the maximal height of the “optimal” road
is located a (mountain) pass.
Remark 4.3.3 In the first part of this chapter, the attention was concentrated on
the change of topology of different sublevels. In the Mountain Pass Theorem, this
change is very simple to detect, and it is exactly what the assumptions describe: there
is a sublevel which is not path-connected. Indeed, take a continuous path γ between
0 and v; this will lie in a sublevel J b , where, for example b = maxt∈[0,1] J (γ (t)).
This means that 0 and v are in the same connected component of J b . On the contrary, 0 and v are not in the same (arcwise) connected component of J a , for every
a < c. Thus J b cannot be deformed into J a .
Example 4.3.4 A functional that satisfies the assumptions of Theorem 4.3.1 is said
to have a “mountain pass geometry”. The functional associated to Problem (4.1),
which we used as a motivation for this discussion, has a mountain pass geometry.
− p

− 2p

Indeed, J (0) = 0, and one can take for example ρ = C p−2 , α = ( 12 − p1 )C p−2 ,
and v any function for which v > ρ and J (v) is negative; there are plenty of these
functions since J (λu) → −∞ as λ → +∞, for every u ≡ 0.
A large number of functionals J associated with superlinear problems have a
mountain pass geometry. This is due to the fact that (i) 0 is a strict local minimum and J behaves well enough to prove that 1. in Theorem 4.3.1 is satisfied and
(ii) limλ→+∞ J (λu) = −∞, which is guaranteed by superlinearity, implies 2.
Remark 4.3.5 As a final consideration, we wish to highlight the use of deformations
that fix certain sets in the proof of Theorem 4.3.1. In view of the minimax principle,
the proof of Theorem 4.3.1 reduces to the construction of an admissible minimax
class. Now the class  is defined by three requirements: every γ is continuous and
such that γ (0) = 0 and γ (1) = v. Of course every deformation, being continuous,
preserves the continuity of γ , so the real condition to satisfy is the fact that the
endpoints of γ should be held fixed during the deformations. We have obtained

158

4 Introduction to Minimax Methods

this by the use of deformations that fix a certain sublevel J c−2ε where the points
0 and v lie. Of course we do not want that these deformations fix also the sublevel
J c , otherwise the main argument of the minimax principle breaks down. Summing
up, the reason why the class  is admissible comes from a separation property:
the interesting level c is strictly larger than the levels that have to be kept fixed
during the deformation, which are the levels J (0) = 0 and J (v) < α. This aspect
is present in almost every construction of concrete minimax classes. We will see
another example of this kind in the Saddle Point Theorem below.
The Mountain Pass Theorem has been used an enormous amount of times in the
literature to produce Palais–Smale sequence. Of course its use depends on the fact
that the functional under study possesses the right geometry.
For functionals that do not have the mountain pass geometry, other minimax
classes can be tried. One of the most popular results, that has also been generalized
in many directions, is the Saddle Point Theorem. Roughly speaking, it works for
functionals where the nonlinearity is not superlinear, but “asymptotically” linear at
infinity. We postpone the examples to the next sections.
The proof of the Saddle Point Theorem requires a classical fixed point result, that
we do not prove (for a proof see [2, 17], or [18]).
Theorem 4.3.6 (Brouwer) Let BR = {x ∈ RN | |x| ≤ R} and let ψ : BR → BR be
a continuous function. Then ψ has a fixed point.
We are going to use the following equivalent form of the Brouwer Theorem.
Theorem 4.3.7 Let BR = {x ∈ RN | |x| ≤ R} and let ϕ : BR → RN be a continuous
function such that ϕ(x) = x if |x| = R (ϕ is the identity on ∂BR ). Then there exists
x ∈ BR such that ϕ(x) = 0.
Proof We define a map ψ : BR → BR as

x − ϕ(x)
ψ(x) =
R
|x−ϕ(x)| (x − ϕ(x))

if |x − ϕ(x)| ≤ R,
if |x − ϕ(x)| > R.

(4.10)

Clearly, the map ψ is well-defined, continuous and ψ(BR ) ⊆ BR . By the Brouwer
Theorem there exists x ∈ BR such that ψ(x) = x. If |x − ϕ(x)| > R, then
x=

R
(x − ϕ(x)),
|x − ϕ(x)|

and hence |x| = R. This implies ϕ(x) = x, so that |x − ϕ(x)| = 0, a contradiction.
So it must be |x − ϕ(x)| ≤ R, and x = ψ(x) then implies x = x − ϕ(x), namely
ϕ(x) = 0.

Remark 4.3.8 A linear n-dimensional subspace of a Hilbert space is isomorphic
to Rn . Therefore the preceding results holds in finite dimensional subspaces of
Hilbert spaces. This is the form that we are going to use.

4.3 Two Classical Theorems

159

Theorem 4.3.9 (Saddle Point Theorem [42]) Let H be a Hilbert space and assume
that J ∈ C 1,1 (H ). Let En ⊂ H be a n-dimensional linear subspace of H and call
V ⊂ H its orthogonal complement in H , so that H = En ⊕ V . For R > 0 let BRn
be the closed ball in En with center at the origin and radius R, and let ∂BRn be its
boundary in En . Assume that for some R > 0,
max J (u) < inf J (u).

u∈∂BRn

u∈V

(4.11)

Then there exists a Palais–Smale sequence for J at a level c ≥ infV J . If J satisfies
(PS)c , then there exists a critical point at level c.
Proof We define the minimax class


 = ϕ(BRn ) | ϕ : BRn → H is continuous, ϕ(u) = u ∀u ∈ ∂BRn
and the corresponding minimax level
c = inf maxn J (ϕ(u)).
ϕ∈ u∈BR

The sets in  are continuous n-dimensional surfaces of boundary ∂BRn ⊂ En .
As in Theorem 4.3.1, the proof amounts to showing that  is admissible. It is
clear that c < +∞; the interesting part is to check that c > −∞.
Let P : H → En be the orthogonal projection on En , so that, u ∈ V if and only
if P (u) = 0 and P (u) = u if and only if u ∈ En . Take a generic ϕ ∈  and define
ψ : BRn → En

as ψ(u) = P (ϕ(u)).

The map ψ is of course continuous, and since ϕ is the identity on ∂BRn ,
for every u ∈ ∂BRn ,

ψ(u) = P (ϕ(u)) = P (u) = u.

So ψ is a continuous map from BRn to En that is the identity on ∂BRn . By Theorem 4.3.7, there exists uϕ ∈ BRn such that ψ(uϕ ) = 0, that is P (ϕ(uϕ )) = 0, which
means ϕ(uϕ ) ∈ V . Therefore,
max J (ϕ(u)) ≥ J (ϕ(uϕ )) ≥ inf J (u) > maxn J (u) > −∞.

u∈BRn

u∈V

u∈∂BR

As this holds for every ϕ ∈ , taking the infimum over  yields
c ≥ inf J (u) > maxn J (u) > −∞.
u∈V

u∈∂BR

Now we have to prove that  satisfies the invariance properties of Definition 4.2.3.
Let ε > 0 be any number so small that
J,
inf J − 2ε > max
n
V

∂BR

and take a deformation η that fixes J c−2ε .
We want to prove that if A = ϕ(BRn ) ∈ , then η(t, A) ∈  for all t ∈ [0, 1]. To
this aim we define
ϕ : BRn → H

as

ϕ(u) = η(t, ϕ(u)).

160

4 Introduction to Minimax Methods

Of course ϕ is continuous. We have to check that ϕ(u) = u for all u ∈ ∂BRn . For this,
take u ∈ ∂BRn . By definition, ϕ(u) = u, and since
J (u) ≤ max
J < inf J − 2ε ≤ c − 2ε,
n
∂BR

V

η(t, u) = u for all t. Therefore
ϕ(u) = η(t, ϕ(u)) = η(t, u) = u,
which shows that ϕ is the identity on ∂BRn . The class  is admissible and the application of Theorem 4.2.4 concludes the proof.

Remark 4.3.10 The preceding proof is identical in its structure to the proof of the
Mountain Pass Theorem. In particular, also in the Saddle Point Theorem the key
property is the separation of the minimax level from the levels that have to be kept
fixed by the deformations. This is the scope of assumption (4.11): the minimax level
c is greater than or equal to infV J , which is strictly greater than α = max∂BRn J .
Thus we can construct a deformation that fixes J α , where ∂BRn lies, and this is
ultimately what makes  admissible.

4.4 Some Applications
We now illustrate the use of the previous theorems by some applications. We have
chosen the simplest cases, but the reader should keep in mind that a very large
number of problems coming from physics, mechanics or geometry can be dealt with
the two results of the preceding section.
The structure of the following results is suggested by that of the Mountain Pass
Theorem and of the Saddle Point Theorem: one checks that the Palais–Smale condition holds, and, separately, that the “geometry” of the functionals involved fits into
the abstract requirements of the mentioned theorems.

4.4.1 Superlinear Problems
We begin with some superlinear nonlinearities, for which the Mountain Pass Theorem is tailored.
Consider the following problem: given a bounded open set  ⊂ RN , N ≥ 3, and
a nonnegative L∞ function q defined on , find u such that

−u + q(x)u = f (u) in ,
(4.12)
u=0
on ∂.
A problem of this form has already been discussed in Sect. 2.5. We will now weaken
the assumptions, maintaining
the validity of the result.
t
We set F (t) = 0 f (s) ds and we consider the following set of assumptions.

4.4 Some Applications

161

(f6 ) There exist p ∈ (2, 2∗ ) and C > 0 such that for all s, t ∈ R,
|f (t) − f (s)| ≤ C|t − s| (|s| + |t| + 1)p−2 .
(f7 ) limt→0 f (t)
t = 0.
(f8 ) There exist M > 0 and μ > 2 such that f (t)t ≥ μF (t) when |t| ≥ M.
(f9 ) There exists t0 ∈ R with |t0 | ≥ M such that F (t0 ) > 0.
Remark 4.4.1 The meaning of assumption (f6 ) is twofold. First of all, it is a growth
condition: setting s = 0 one sees that (f6 ) implies
|f (t)| ≤ K(|t|p−1 + 1)

(4.13)

for all t and for a suitable positive constant K.
Next, (f6 ) implies that f is locally Lipschitz continuous on R. These two facts
allow one to prove that the functional G : H01 () → R defined by

G(u) =
F (u) dx
is of class C 1,1 and G (u)v =





1
 f (u)v dx for all v ∈ H0 ().
Also, assumption (f8 ) means that the function t → F|t|(t)
μ is increasing for t ≥ M

and decreasing for t ≤ −M, as one can immediately see by differentiation.

Remark 4.4.2 Problem (4.1), which we used as a motivation for the construction of
the minimax methods, is a particular case of Problem (4.12).
If, as usual, we equip H01 () with the norm

u 2 = |∇u|2 + q(x)u2 dx,

(4.14)



we can say that weak solutions of Problem (4.12) are critical points of the functional
J : H01 () → R defined as


1
1
J (u) =
|∇u|2 + q(x)u2 dx − F (u) dx = u 2 − G(u),
2 
2

which is in C 1 (H01 ()).
We will prove the following theorem, where assumption (h1 ) is the one introduced at the beginning of Sect. 2.1 (recall also Remark 2.1.1).
Theorem 4.4.3 Assume that (h1 ) and (f6 )–(f9 ) hold. Then Problem (4.12) has at
least one non trivial solution.
In view of Remark 4.1.16, the abstract minimax principle of Sect. 4.2 holds by
merely assuming J of class C 1 , and so do the Mountain Pass and Saddle Point
theorems. Therefore, in the previous result, assumption (f6 ) could be replaced by
the continuity of f and (4.13).

162

4 Introduction to Minimax Methods

Remark 4.4.4 Theorem 4.4.3 gives a stronger result than those we proved in
Sect. 2.5. Indeed, it is easy to see that hypotheses (f1 )–(f4 ) imply (f6 )–(f9 ) (with
t0 > M); therefore Theorem 2.5.2 is a special case of Theorem 4.4.3, except for the
positivity of the solution. However, if t0 > M this can be recovered by the method
of Example 1.7.10 after extending f to zero for negative arguments. Moreover, the
minimax method allows one to drop the hypothesis of C 1 nonlinearities and the
assumption (f4 ). Also the hypotheses of Theorem 2.5.11 imply (f6 )–(f9 ).
We are going to show that the Mountain Pass Theorem is applicable. First, a technical result.
Lemma 4.4.5 The functional J is in C 1,1 (H01 ()).
Proof We already know that J is C 1 ; of course, since the differential of the
quadratic term is (globally) Lipschitz continuous, we only have to check the local
Lipschitz continuity for the differential of the functional G(u).
To this aim, fix R > 0 and take u1 , u2 ∈ H01 () such that u1 , u2 ≤ R. Then,
for all v ∈ H01 () we have, by (f6 ),

(f (u1 ) − f (u2 ))v dx
|(G (u1 ) − G (u2 ))v| =




p

≤

f (u1 ) − f (u2 ) p−1 dx

 p−1 
p






≤C

1/p
|v|p dx

|u1 − u2 |

p
p−1

(1 + |u1 | + |u2 |)

p(p−2)
p−1

 p−1
p

dx

v .



Applying the Hölder inequality with exponents p − 1 and p−1
p−2 we obtain

p
p(p−2)
|u1 − u2 | p−1 (1 + |u1 | + |u2 |) p−1 dx


 1 


|u1 − u2 | dx

≤

p

p−1



 p−2
(1 + |u1 | + |u2 |) dx
p

p−1



≤ u1 − u2

p
p−1

K(R),

where K(R) depends on R but not on u1 , u2 . This shows that
p−1

|(G (u1 ) − G (u2 ))v| ≤ u1 − u2 K(R) p

v ,

and therefore, maximizing over all v = 1,
G (u1 ) − G (u2 ) ≤ C(R) u1 − u2 ,
where C(R) is a constant depending on R. So we have proved that G (and hence J )
is locally Lipschitz continuous.

Now we turn to the compactness properties of J .

4.4 Some Applications

163

Lemma 4.4.6 The functional J satisfies (PS)c for every c ∈ R.
Proof Take c ∈ R and assume that {uk } is a Palais–Smale sequence at level c,
namely such that
J (uk ) → c

and J  (uk ) → 0

(in (H01 ()) ).

This implies of course that there is a constant C > 0 such that
|J (uk )| ≤ C

and |J  (uk )uk | ≤ C uk

(4.15)

for every k. The following is a standard trick in superlinear problems to show that
Palais–Smale sequences are bounded, and is the main motivation for the use of
assumption (f8 ). By (4.15) we can write
1
C(1 + uk ) ≥ J (uk ) − J  (uk )uk
μ



 
1
1
1
−
uk 2 +
f (uk )uk − F (uk ) dx.
=
2 μ
 μ
Then from (f8 ) we obtain




 
1
1
f (uk )uk − F (uk ) dx =
f (uk )uk − F (uk ) dx
 μ
{|uk |≤M} μ



1
f (uk )uk − F (uk ) dx
+
{|uk |>M} μ



1
f (uk )uk − F (uk ) dx ≥ −C1 ,
≥
{|uk |≤M} μ
and hence


C(1 + uk ) ≥

1
1
−
2 μ


uk 2 − C1 ,

which of course implies that {uk } is bounded.
By usual arguments we can assume that, up to a subsequence, there exists
u ∈ H01 () such that
• uk
u in H01 (),
• uk → u in Lq () for all q ∈ [2, 2∗ ),
• uk (x) → u(x) for almost every x ∈ .
We now show that the convergence of uk to u is strong, and this is a consequence
of the fact that p < 2∗ .
First of all, from the above convergence properties, we obtain by usual arguments,




f (uk )uk dx →
f (u)u dx and
f (uk )u dx →
f (u)u dx. (4.16)








As J  (uk ) → 0 and uk
u, we also have J  (uk )(uk − u) → 0 and obviously

J (u)(uk − u) → 0. Then, as k → ∞,

164

4 Introduction to Minimax Methods



o(1) = J  (uk ) − J  (u) (uk − u) = uk − u 2 −





f (uk ) − f (u) (uk − u) dx



= uk − u

2

+ o(1)

by (4.16). This shows that uk → u in H01 (), and proves that J satisfies (PS)c for
every c ∈ R.

End of the proof of Theorem 4.4.3 We just have to check that the geometrical assumptions of the Mountain Pass Theorem are satisfied.
First of all, as F (0) = 0, we have J (0) = 0. We now prove that hypothesis 1 of
Theorem 4.3.1 holds.
Let λ1 > 0 be the first eigenvalue of the operator − + q on . Fix ε > 0 so
small that
ε
1
1
−
≥ .
2 λ1 4
By (f7 ) we have limt→0 Ft(t)
2 = 0, and therefore there exists δ > 0 such that
F (t) ≤ εt 2
if |t| ≤ δ. By (f6 ), as we remarked above, we deduce that there are a, b > 0 such
∗
that |f (t)| ≤ a + b|t|2 −1 , and then also
∗

|F (t)| ≤ ã + b̃|t|2

for some positive ã, b̃ and all t ∈ R. Collecting these inequalities, it is not difficult
to see that there is a constant Cε > 0 such that
∗

|F (t)| ≤ εt 2 + Cε |t|2
for all t. Hence




1
1
∗
u 2−
F (u) dx ≥ u 2 − ε |u|2 dx − Cε
|u|2 dx
2
2



ε
1
1
∗
∗
u 2−C u 2 ≥ u 2−C u 2 ,
≥ u 2−
2
λ1
4

J (u) =

from which the assumption 1. of Theorem 4.3.1 easily follows, for example taking
∗
as ρ any number so small that 14 ρ 2 − Cρ 2 is positive.
To check that assumption 2 also holds, we notice that it is easy, using the same
arguments of Lemma 2.5.3, to show that there is a constant C > 0 such that F (t) ≥
C|t|μ for all t ≥ t0 , if t0 > M, and for all t ≤ t0 , if t0 < −M. To proceed, we assume
that t0 ≥ M (the other case being similar). Take ϕ ∈ C0∞ () such that ϕ(x) ≥ 0 for
all x ∈  and ϕ(x) ≥ 1 on some ball B = Br (x0 ) ⊂ . Then
tϕ(x) ≥ t0 ,

and hence F (tϕ(x)) ≥ Ct μ ϕ μ (x)

while |F (tϕ)| ≤ C if 0 ≤ tϕ(x) ≤ t0 . So we obtain

for all t ≥ t0 and all x ∈ B,

4.4 Some Applications

165




F (tϕ) dx =




F (tϕ) dx +
F (tϕ) dx
{tϕ>t0 }

≥ −C + C
t μ ϕ μ dx
{tϕ>t0 }

≥ −C + C t μ ϕ μ dx ≥ −C + Ct μ ,
{0≤tϕ≤t0 }

B

and then
t2
ϕ 2−
J (tϕ) =
2


F (tϕ) dx ≤ t 2 C1 + C − Ct μ .


As μ > 2, it is now obvious that for large t we have J (tϕ) < 0, so also assumption 2
is proved. We then apply Theorem 4.3.1 to obtain a critical point at level c. As c > 0,
this critical point cannot be zero, and therefore the solution of Problem (4.12) is
nontrivial.

We now give another application of the Mountain Pass Theorem. On a bounded
open set  ⊂ RN , we look for a solution u of

−u + q(x)u = λu + |u|p−2 u in ,
(4.17)
u=0
on ∂,
with λ ∈ R. As usual, q is bounded and nonnegative on , and we assume
2 < p < 2∗ . Weak solutions of (4.17) are critical points of the differentiable functional J : H01 () → R defined by


1
λ
1
2
2
J (u) = u −
u dx −
|u|p dx,
2
2 
p 
where the norm of u is the one defined in (4.14).
Remark 4.4.7 It is easy to see that if we define f (u) = λu+|u|p−2 u, then f satisfies
(f6 ), (f8 ), (f9 ), but not (f7 ). Therefore we cannot use directly Theorem 4.4.3 to
solve Problem (4.17). Actually one could reenter in the frame of Theorem 4.4.3 by
assuming that λ1 (− + q(x) − λ) > 0 and use as an equivalent norm in H01 () the
first two terms of J . We prefer not do so because in the applications one encounters
frequently problems written as (4.17).
We are going to prove the following result; in its statement we denote by λ1 (q)
the first eigenvalue of the operator − + q(x).
Theorem 4.4.8 Assume that (h1 ) holds and that 2 < p < 2∗ . If λ < λ1 (q), then
Problem (4.17) has at least one non trivial solution.
Proof The argument is essentially the same as that of the previous theorem. The
nonlinearity f (u) = λu + |u|p−2 u in (4.17) is C 1 and satisfies (f6 ), so the proof of
Lemma 4.4.5 works in the same way and we obtain that J ∈ C 1,1 (H01 ()).

166

4 Introduction to Minimax Methods

Let us check that the Palais–Smale condition holds at every level. Let {uk } be a
sequence such that
J (uk ) → c

and J  (uk ) → 0.

As in the previous theorem, this implies that there is a constant C > 0 such that
1
C(1 + uk ) ≥ J (uk ) − J  (uk )uk
p





1 1
λ λ
1
2
2
−
uk −
−
=
u dx −
|uk |p dx
2 p
2 p  k
p 

1
|uk |p dx
+
p 




1 1
1 1
−
uk 2 − λ
−
=
u2 dx
2 p
2 p  k




1 1
λ
1 1
2
−
uk −
−
uk 2
≥
2 p
λ1 (q) 2 p



λ
1 1
−
1−
uk 2 .
=
2 p
λ1 (q)
Since λ < λ1 (q), this implies that {uk } is bounded and, as in the previous theorem,
we deduce that there is u ∈ H01 () such that
• uk
u in H01 (),
• uk → u in Lq () for all q ∈ [2, 2∗ ),
• uk (x) → u(x) for almost all x ∈ .
Then we easily see that as k → ∞,

|uk |p−2 uk (uk − u) dx = o(1).


We conclude by computing


o(1) = J  (uk ) − J  (u) (uk − u)




|uk |p−2 uk − |u|p−2 u (uk − u) dx
= uk − u 2 − λ |uk − u|2 dx −




= uk − u 2 + o(1),
which shows that uk → u strongly. Condition (PS)c holds for every c.
Finally we check that the geometric assumptions of Theorem 4.3.1 are satisfied.
It is obvious that J (0) = 0. For every u ∈ H01 () we have


λ
1
1
u2 dx −
|u|p dx
J (u) = u 2 −
2
2 
p 


λ
1
λ
1
1−
u 2 − C u p.
≥ u 2−
u 2−C u p =
2
2λ1 (q)
2
λ1 (q)

4.4 Some Applications

167

As λ < λ1 (q) and p > 2, it is enough to choose any positive number ρ so small that
1
λ
2
p
2 (1 − λ1 (q) )ρ − Cρ > 0. Hypothesis 1 of Theorem 4.3.1 is satisfied.
Finally for every u ∈ H01 ()\{0} and t > 0 we have


t2
λt 2
tp
u2 dx −
|u|p dx
u 2−
2
2 
p 




tp
t2
2
2
u − λ u dx −
|u|p dx.
=
2
p 


J (tu) =

Therefore J (tu) → −∞ as t → +∞, and we can certainly find v such that v ≥ ρ
and J (v) < 0. The mountain Pass Theorem then yields the existence of a critical
point u for J at a positive level. This critical point is then a nontrivial solution of
Problem (4.17).

Remark 4.4.9 If λ ≥ λ1 (q), the Mountain Pass Theorem cannot be applied, because
the “geometry around zero” is lost, in the sense that zero is no longer a local minimum for J . To see this, let ϕ1 be the eigenfunction associated to λ1 (q). For every
t = 0 we have
J (tϕ1 ) =

t2
λt 2
ϕ1 2 −
2
2


ϕ12 dx −



λ1 (q)t 2

|t|p
p



|ϕ1 |p dx


|t|p
ϕ12 dx −
|ϕ1 |p dx
p



t2
ϕ1 2 −
2
2

p
|t|
=−
|ϕ1 |p dx < 0,
p 
≤

and J is strictly negative on all the line tϕ1 , except t = 0.

4.4.2 Asymptotically Linear Problems
We now present some applications of the Saddle Point Theorem. The most frequent
situation where this theorem is applicable is that of asymptotically linear problems,
namely those where the nonlinearity grows linearly at infinity.
To illustrate the method, we consider an open and bounded subset  of RN , and
we look for a solution of

−u + q(x)u = λu + f (u) + h(x) in ,
(4.18)
u=0
on ∂.
Throughout this section, in addition to (h1 ) and (h2 ), we will use the following
assumption:
∗

(f10 ) f ∈ C 1 (R), f is bounded and |f  (t)| ≤ C(1 + |t|2 −2 ).

168

4 Introduction to Minimax Methods

The requirement that f be C 1 can be weakened, and we use it only to avoid some
technicalities (for example we could take f bounded and satisfying (f6 )). If we
define
f˜ :  × R → R as f˜(x, t) = λt + f (t) + h(x),
we see that
lim

t→±∞

f˜(t, x)
=λ
t

almost everywhere in . Thus f˜ grows linearly in t at infinity, and this characterizes
(4.18) as an asymptotically linear problem.
Once H01 () is equipped with the usual norm defined by (4.14), the weak solutions of (4.18) are the critical points of the functional J : H01 () → R defined
by



1
λ
2
2
J (u) = u −
u dx −
F (u) dx − hu dx,
2
2 


t
where of course F (t) = 0 f (s) ds. Due to (f10 ), repeating the arguments of
Lemma 4.4.5, the functional J is readily seen to be in C 1,1 (H01 ()), and we will
not discuss this point anymore.
Let 0 < λ1 < λ2 ≤ · · · be the usual sequence of the eigenvalues of the operator
− + q(x). The solvability of Problem (4.18) strongly depends on the location of
λ with respect to the eigenvalues λk .
Definition 4.4.10 If λ = λk for every k, Problem (4.18) is said to be nonresonant. If
λ = λk for some k, the problem is said to be resonant or at resonance with the k-th
eigenvalue.
Resonant problems are much more difficult to solve, and it may happen that they
do not have any solution at all, even in the linear case (compare with Theorem 1.7.8).
So, to illustrate the method we first consider a nonresonant problem.
Theorem 4.4.11 Assume that (h1 ), (h2 ) and (f10 ) hold. If λ = λk for every k, then
Problem (4.18) has at least one solution.
If λ < λ1 , the functional J is coercive and can be shown to have a global minimum, with the methods of Sect. 2.1. The interesting case is thus λ > λ1 , and we
define n ∈ N to be the number such that
λn < λ < λn+1 .

(4.19)

In this case we are going to show that the functional J satisfies the assumptions of
the Saddle Point Theorem. As usual we split the problem in two parts: compactness
and geometric assumptions.
In what follows, we always take for granted the assumptions of Theorem 4.4.11
and (4.19).

4.4 Some Applications

169

Lemma 4.4.12 The functional J satisfies (PS)c for every c ∈ R.
Proof Let {uk } be a sequence such that
J (uk ) → c

and J  (uk ) → 0.

We first prove that {uk } is bounded.
Assume for contradiction that, up to a subsequence, uk → +∞. Since
J  (uk ) → 0, for every v ∈ H01 () we can write J  (uk )v = o(1) v , namely



f (uk )v dx − hv dx = o(1) v .
(4.20)
(uk |v) − λ uk v dx −






uk
uk

Define ψk =
. Of course the sequence {ψk } is bounded in H01 (), so we can
assume ψk
ψ ∈ H01 (). Dividing by uk the equation above we obtain



1
1
v
.
f (uk )v dx −
hv dx = o(1)
(ψk |v) − λ ψk v dx −
uk 
uk 
uk

As f is bounded, passing to the limit we get

(ψ|v) − λ ψv dx = 0.

(4.21)



Let us now prove that ψ ≡ 0. Assume instead that ψ = 0. If this is the case, by
J  (uk )ψk = o(1) we first obtain



f (uk )ψk dx − hψk dx = o(1),
(uk |ψk ) − λ uk ψk dx −




and then, dividing by uk ,




ψk

2

−λ


ψk2 dx = o(1).

We know that ψk
0 in H01 (), which implies ψk → 0 in L2 (). Therefore we
obtain ψk → 0, a contradiction. So we have constructed a non zero function ψ
satisfying (4.21) for all v ∈ H01 (), namely a weak solution of

−ψ + q(x)ψ = λψ in ,
(4.22)
ψ =0
on ∂.
But this says that λ is an eigenvalue of − + q(x), which contradicts the nonresonance assumption.
u in H01 ()
This proves that {uk } is a bounded sequence, so we can assume uk
2
and uk → u in L (). From this we obtain easily with the usual arguments


o(1) = J  (uk ) − J  (u) (uk − u)

2
2
= uk − u − λ (uk − u) dx − (f (uk ) − f (u)) (uk − u) dx



− h(uk − u)


= uk − u 2 + o(1),
which shows that uk → u in H01 ; the functional J satisfies (PS)c for all c ∈ R.



170

4 Introduction to Minimax Methods

End of the proof of Theorem 4.4.11 We just have to check that J satisfies the geometric assumption of the Saddle Point Theorem. Let {ϕk }k be the sequence of the
eigenfunctions of − + q(x) (orthonormal in L2 ()), each associated to an eigenvalue λk . Define
En = span{ϕ1 , . . . , ϕn },

and V = En⊥ = cl{span{ϕk | k ≥ n + 1}}.

These two subspaces are nothing else than the spaces X1 and X2 introduced in (2.8).
We recall from Lemma 2.2.5 that
u 2 ≤ λn |u|22

∀u ∈ En

and

u 2 ≥ λn+1 |u|22

∀u ∈ V .

(4.23)

From this we deduce, for every u ∈ En ,


1
λ 2
2
J (u) = u − |u|2 −
F (u) dx − hu dx
2
2




λ
1
λ
1
2
2
u 2+C u .
1−
≤ u −
u +C u =
2
2λn
2
λn
Denoting by BRn the ball in En of center zero and radius R, the last inequality shows
that for every u ∈ ∂BRn ,


λ
1
1−
R 2 + CR.
J (u) ≤
2
λn
Since λ/λn > 1, we have proved that
max J (u) → −∞

u∈∂BRn

if R → ∞.
We now prove that J is bounded from below on V . Still from (4.23), for every
u ∈ V we have


λ 2
1
2
F (u) dx − hu dx
J (u) = u − |u|2 −
2
2


1
λ
u 2−
u 2−C u
2
2λn+1


λ
1
u 2−C u .
1−
=
2
λn+1
≥

Since λ/λn+1 < 1, this implies infV J > −∞. Hence for R large enough we can
guarantee that
max J (u) < inf J (u).

u∈∂BRn

u∈V

All the assumptions of the Saddle Point Theorem are satisfied and we apply it to
conclude.


4.4 Some Applications

171

Remark 4.4.13 It is interesting to compare this result with the similar one of
Sect. 2.2. In Theorem 2.2.3 a global assumption on the derivative of f was made,
namely (2.7). In Theorem 4.4.11 there is no assumption on f  , except of course a
natural requirement on its growth.
Example 4.4.14 Whenever f and f  are bounded on R (and λ is not an eigenvalue),
the assumptions of Theorem 4.4.11 are satisfied. Thus, on an open and bounded
 ⊂ RN the homogeneous Dirichlet problem for equations like
−u + q(x)u = λu + arctan(u) + h(x)
or
−u + q(x)u = λu +

u
+ h(x)
1 + u2

always admits a solution, for every h ∈ L2 ().

4.4.3 A Problem at Resonance
The Saddle Point Theorem is still applicable for certain problems of type (4.18) in
presence of resonance, namely when λ coincides with one of the eigenvalues of
− + q. These problems are generally harder to solve, and one does not expect
solutions without imposing further conditions on the data of the problem.
In the literature these assumptions are normally expressed as follows: one imposes some conditions on f , which determine the type of nonlinearity under study,
and then tries to understand for which types of h the problem is solvable.
In this section we consider, on a bounded open set , the problem

−u = λu + f (u) + h(x) in ,
(4.24)
u=0
on ∂.
We assume here that q ≡ 0, to simplify notation, but everything would work just
as well replacing − with − + q(x), with q satisfying (h1 ) (possibly replacing
the sign condition by (2.3)).
The characteristic features of the problem are described by the following set of
assumptions. The function f satisfies (f10 ) and the limits
fl = lim f (t)
t→−∞

and fr = lim f (t)
t→+∞

exist, are finite and are different; to fix ideas we suppose that
fl > fr ,

(4.25)

but the other case would work as well, with some modifications in the main argument. This specifies a class of nonlinearities.

172

4 Introduction to Minimax Methods

Remark 4.4.15 Problem (4.24) can be seen as a nonlinear generalization of a nonhomogeneous linear problem, such as

−u = λu + h(x) in ,
(4.26)
u=0
on ∂
discussed in Sect. 1.7. When λ is an eigenvalue of the Laplacian, Theorem 1.7.8
says that the existence of solutions is guaranteed provided h is orthogonal to the
eigenspace relative to λ. Adding a nonlinear term f (u) in the equation obviously
alters significantly the simple structure of the linear problem, and the search of conditions on h that ensure the existence of solutions becomes highly nontrivial. In this
section we describe one of these conditions.
Denoting as usual by λ1 < λ2 ≤ · · · the sequence of the eigenvalues of − in
H01 (), we assume that for some n and k,
λn < λn+1 = · · · = λn+k < λn+k+1
and we suppose that
λ = λn+1 = · · · = λn+k .

(4.27)

So, assumptions (f10 ) and (4.27) say that Problem (4.24) is at resonance (with a
multiple eigenvalue, if k ≥ 2).
The hypotheses made so far are not sufficient to prove the existence of a solution.
We now describe one type of conditions that guarantee the solvability of (4.24) for
certain h ∈ L2 ().
These were first introduced in [28], so that they are called the Landesman–Lazer
conditions. To state them, let
E = span{ϕn+1 , . . . , ϕn+k }

(4.28)

be the k-dimensional subspace of H01 () made of all the solutions of −ϕ = λϕ.
The Landesman–Lazer conditions are the following: for every ϕ ∈ E \ {0},





(LL)
fr ϕ − dx − fl ϕ + dx < hϕ dx < fl ϕ − dx − fr ϕ + dx,










where of course ϕ + and ϕ − denote the positive and negative part of ϕ.
We notice that since ϕ ∈ E implies that −ϕ ∈ E, any of the two inequalities in
(LL) implies the other one.
Remark 4.4.16 To understand the meaning of these inequalities, it is convenient to
visualize the case fl = −fr , with fr < 0. In this case (LL) becomes





−
+
−
−fl ϕ dx − fl ϕ dx < hϕ dx < fl ϕ dx + fl ϕ + dx,




and, recalling that ϕ + + ϕ − = |ϕ|,


−fl









|ϕ| dx <


|ϕ| dx.

hϕ dx < fl






4.4 Some Applications

173

This is a sort of generalized orthogonality condition: the (L2 ) scalar product between h and ϕ must not be too large, compared to the limits of f at ±∞. Note
also that if h is orthogonal to E, then the preceding inequality is always satisfied.
Compare with Remark 4.4.15.
As in the preceding section, weak solutions of (4.24) are critical points of the
functional




1
λ
2
2
J (u) =
|∇u| −
u dx −
F (u) dx − hu dx,
2 
2 


t
where F (t) = 0 f (s) ds. Again, due to (f10 ), the functional J is in C 1,1 (H01 ()).
We are going to prove the following result.
Theorem 4.4.17 Let  ⊂ RN be open and bounded. Assume that (f10 ) holds and
that the limits fl and fr exist and satisfy (4.25). Let λ be as in (4.27). Then for every
h ∈ L2 () satisfying (LL), Problem (4.24) admits at least one weak solution.
We are going to prove this theorem by an application of the Saddle Point Theorem.
It is remarkable that the proof of this result as it appeared in the original paper
[28] is considerably different and more complicated than the one we give here. This
is because at the time of [28] the Saddle Point Theorem was not yet available.
As usual we divide the proof in two problems: the analysis of the compactness
properties of J and the verification of the required geometrical assumptions. It is
interesting to remark that the resonance assumption affects both problems, making
proofs more difficult.
We start with the analysis of compactness. Recalling (4.28), we split
H01 () = E ⊕ E ⊥
and we write u ∈ H01 () as u = w + v, with w ∈ E and v ∈ E ⊥ .
Lemma 4.4.18 The functional J satisfies (P S)c for every c ∈ R.
Proof A part of the proof works exactly as that of Lemma 4.4.12, and we will not
repeat all the computations.
Let {uk } be a Palais–Smale sequence at level c ∈ R, namely,
J (uk ) → c

and J  (uk ) → 0.

If {uk } is bounded, then, up to subsequences, it converges strongly in H01 (), exactly
as at the end of the proof of Lemma 4.4.12. So the proof reduces to showing that uk
is bounded. Now if we write uk = wk + vk , with wk ∈ E and vk ∈ E ⊥ , we have of
course


∇wk · ∇z dx − λ wk z dx = 0




174

4 Introduction to Minimax Methods

for all z ∈ H01 (), by definition of λ and E. Therefore the condition J  (uk ) → 0
reads




∇vk · ∇z dx − λ vk z dx − f (uk )z dx − hz dx = o(1) z
(4.29)








for every z ∈ H01 (). This is the form that (4.20) takes in the resonance case. Repeating step by step the computations that follow (4.20), one shows that vk is bounded

(if vk → ∞, then as in Lemma 4.4.12 one shows that vk / vk converges to an
eigenfunction relative to λ in E ⊥ , which is impossible).
Thus the real problem is to show that wk is bounded. In the proof of
Lemma 4.4.12, this problem is not present because E = {0}.
So we assume for contradiction that wk → ∞. The sequence wk / wk is
bounded and, up to subsequences, it converges strongly in H01 () (because E has
finite dimension) and almost everywhere in  to some ϕ ∈ E. Since the convergence
is strong, ϕ ≡ 0.
Since vk is bounded in H01 (), we can assume that up to subsequences, it converges to some v a.e. in . Then we see that

wk (x)
+∞ if ϕ(x) > 0,
+ vk (x) →
uk (x) = wk
a.e. in .
(4.30)
−∞ if ϕ(x) < 0,
wk
In the preceding relation we have used the fact that ϕ, being an eigenfunction, is
almost everywhere different from zero, as we stated in Theorem 1.7.3. Define a
function f∞ :  → R as

f if ϕ(x) > 0,
f∞ (x) = r
(4.31)
fl if ϕ(x) < 0.
Then from (4.30) we see that
f (uk (x)) → f∞ (x)

a.e. in ,

and since f is bounded, by dominated convergence we have
f (uk ) → f∞
in every Lp () with p finite.
Now we choose z = ϕ in (4.29) and we let k → ∞: we obtain


− f∞ ϕ dx − hϕ dx = 0,


namely




hϕ dx = −







f∞ ϕ dx = fl



ϕ − dx − fr



ϕ + dx.



This contradicts (LL), and shows that also wk must be bounded. The proof is complete.

Now we check that the geometrical assumptions of the Saddle Point Theorem
hold.

4.4 Some Applications

175

To this aim we set, as in the nonresonant case,
and V = En⊥ = cl{span{ϕk | k ≥ n + 1}}.

En = span{ϕ1 , . . . , ϕn },

(4.32)

Notice that the space E used in the previous lemma is now part of V ; this is what
makes the estimates more complex.
First the easy part. Since the inequality
u 2 ≤ λn |u|22

∀u ∈ En

still holds (see (4.23)), denoting by BRn the ball in En of center zero and radius R,
one can prove exactly as in the nonresonant case, that
max J (u) → −∞

u∈∂BRn

if R → ∞.
Now we turn to the hard part, the estimate from below on V .
Lemma 4.4.19 We have
inf J (u) > −∞.

u∈V

Proof We write V as
V = E ⊕ F,
where E is the subspace defined in (4.28), and F = cl{span{ϕj | j ≥ n + k + 1}}.
Notice that F is the orthogonal complement of E in V . Accordingly, we write each
u ∈ V as
u = w + v,
where w ∈ E and v ∈ F . Recall that w and v are orthogonal both in H01 () and in
L2 (). Also,
v 2 ≥ λn+k+1 |v|22

∀v ∈ F,

see (4.23).
Bearing all this in mind, we see that for every u ∈ V ,




1
λ
2
2
J (u) =
|∇u| −
u dx −
F (u) dx − hu dx
2 
2 






λ
1
2
1−
|∇v| dx −
F (u) dx − hu dx
≥
2
λn+k+1 




2
=μ v −
F (u) dx − hu dx,


(4.33)



with μ > 0.
Since f is bounded, |F (t)| ≤ b|t| for every t ∈ R and for some constant b. Therefore from the preceding inequality we obtain
J (u) ≥ μ v 2 − C u − |h|2 |u|2 ≥ μ v 2 − C v − C w ,

(4.34)

176

4 Introduction to Minimax Methods

for some positive constant C independent of u.
Assume for contradiction that there exists a sequence uk = wk + vk ∈ V such
that
J (uk ) → −∞

(4.35)

as k → ∞. Then we claim that
wk
→ +∞.
(4.36)
vk
We assume here that vk = 0; if this is not the case the proof is simpler and we
omit the details. To check (4.36), notice that from (4.34) and (4.35), we have
μ vk 2 − C vk − C wk → −∞,
so that necessarily wk → ∞. If vk is bounded, we are done. If vk → ∞, then
writing the preceding relation as


wk
→ −∞
vk μ vk − C − C
vk
shows that (4.36) must be true.
Now, as in the preceding lemma, we can assume that there exist ϕ ∈ E \ {0} and
v ∈ F such that (up to subsequences),
wk (x)
→ ϕ(x)
wk

and

vk (x)
→ v(x)
vk

almost everywhere in . Note that ϕ(x) ≡ 0, since the convergence of wk / wk is
strong, as above. Therefore, by (4.36),


wk (x)
vk vk (x)
uk (x) = wk
+
wk
wk v k

+∞ if ϕ(x) > 0,
→
a.e. in .
(4.37)
−∞ if ϕ(x) < 0,
Next we claim that
1
F (uk (x)) → f∞ ϕ(x) a.e. in ,
wk
where f∞ is the function defined in (4.31). To see this note first that

(4.38)

F (t)
F (t)
= fl and
= fr ,
lim
t→+∞ t
t
by the de l’Hôpital Theorem. Now for almost every x in the set where ϕ(x) > 0, we
have, for all k large,


1
vk (x) wk (x) F (uk (x))
uk (x) F (uk (x))
F (uk (x)) =
=
+
.
wk
wk
uk (x)
wk
wk
uk (x)
lim

t→−∞

When k → ∞, from the preceding discussions we see that
vk (x)
vk vk (x)
=
→ 0,
wk
wk v k

wk (x)
→ ϕ(x),
wk

F (uk (x))
→ fr
uk (x)

4.4 Some Applications

177

almost everywhere where ϕ(x) > 0. The last limit of course is fl a.e. in the set
where ϕ(x) < 0. Then (4.38) is proved.
Now we check that the convergence in (4.38) actually holds in L1 ().
The function uk / uk is bounded in H01 (), and therefore, up to subsequences,
it converges strongly in L1 (), and there exists u ∈ L1 () such that
|uk (x)|
≤ u(x)
uk

a.e. in .

Then
|F (uk (x))|
|uk (x)|
uk |uk (x)|
≤b
=b
≤ C + Cu(x) ∈ L1 ()
wk
wk
wk
uk
a.e. in , because by (4.36) the coefficient uk / wk is bounded independently
of k. Then by dominated convergence,
F (uk )
→ f∞ ϕ
wk

in L1 ().

We are now ready to conclude. Since uk / wk is bounded, up to subsequences it
converges weakly in H01 () and strongly in L2 (); by (4.37), it must be
uk
→ ϕ.
wk
Then from (4.33) we see that


J (uk ) ≥ μ vk 2 − F (uk ) dx − huk dx






1
uk
2
dx
= μ v k − wk
F (uk ) dx + h
wk 
wk




f∞ ϕ dx + hϕ dx + o(1)
≥ − wk


 



= − wk fr ϕ + dx − fl ϕ − dx + hϕ dx + o(1) .






By (LL), the quantity in the round bracket is strictly negative for large k, so that we
obtain
J (uk ) → +∞
as k → ∞, contradicting (4.35). The proof is complete.



End of the proof of Theorem 4.4.17 The functional J satisfies the Palais–Smale condition at every level and the geometrical assumptions of the Saddle Point Theorem
if we choose En and V as in (4.32). Then J has a critical point, namely Problem
(4.24) has a weak solution.

Remark 4.4.20 The Landesman–Lazer conditions (LL) may seem a bit mysterious
at first glance. However they arise naturally as necessary conditions for the existence

178

4 Introduction to Minimax Methods

of a solution to (4.24), under a slightly stronger assumption. Indeed, if on f we also
assume that
fr < f (t) < fl

∀t ∈ R,

(4.39)

then we can prove that the existence of a solution to (4.24) implies (LL). To see
this, let u be a solution of Problem (4.24). Then for every ϕ ∈ E,




0 = ∇u · ∇ϕ dx − λ uϕ dx = f (u)ϕ dx + hϕ dx,


so that






hϕ dx = −







f (u)ϕ − dx −

f (u)ϕ dx =








f (u)ϕ + dx.



By (4.39),





hϕ dx = f (u)ϕ − dx − f (u)ϕ + dx < fl ϕ − dx − fr ϕ + dx










and, similarly,





−
+
−
hϕ dx = f (u)ϕ dx − f (u)ϕ dx > fr ϕ dx − fl ϕ + dx,










and these are the Landesman–Lazer conditions.

4.5 Problems with a Parameter
In many mathematical problems deriving from applications the presence of one parameter (or more) is a relevant feature, and the study of how solutions depend on
parameters is an important topic. Most of the work on such questions uses tools
different from those explained in this book, such as bifurcation theory; we refer for
example to [2, 4] for a more extensive treatment of this matters. However some interesting results can be obtained also in a variational framework, and in this section
we give some examples.
We start with a very simple model case where an insight on the problem is obtained by elementary computations. Consider the problem

−u + q(x)u = λ|u|p−2 u in ,
(4.40)
u=0
on ∂,
with the usual hypotheses:  is a bounded open set, q ∈ L∞ () and q ≥ 0,
p ∈ (2, 2∗ ). We know, by the theorems of Sects. 2.3 or 4.3, that (4.40) admits a
nonnegative and nontrivial solution for all λ > 0. Let u be a solution for λ = 1. It
−

1

is then immediate to see that uλ = λ p−2 u is a solution of (4.40). Hence we have
a family {uλ }λ of solutions such that uλ → 0 when λ → +∞ and uλ → +∞
when λ → 0+ . We now want to show that a similar result holds in a more general
framework. So we consider the nonlinear eigenvalue problem

−u + q(x)u = λf (u) in ,
(4.41)
u=0
on ∂.

4.5 Problems with a Parameter

179

t
Denoting as usual F (t) = 0 f (s) ds, we can prove the following result. In its statement, and in all the statements of the next theorems, the positivity of q in assumption
(h1 ) can of course be replaced by (2.3).
Theorem 4.5.1 Assume that (h1 ), (f3 ), (f6 ) and (f7 ) hold. Then the following statements hold.
(i) If there exist r > 2, M1 > 0 and t1 > 0 such that f (t) ≥ M1 t r−1 for t ∈ [0, t1 ],
then for every λ > 0 there exists a nonnegative and non trivial solution uλ of
(4.41) such that uλ → 0 as λ → +∞.
(ii) If F (t) > 0 for all t > 0 then for every λ > 0 there exists a nonnegative and non
trivial solution uλ of (4.41) such that uλ → +∞ as λ → 0+ .
Proof As we are interested in nonnegative solutions, we can assume that
f (t) = 0 for all t ≤ 0 (recall Example 1.7.10). The existence result is a consequence
of the Mountain Pass Theorem 4.3.1 applied to the functional

1
Jλ (u) = u 2 − λ F (u) dx.
2

Arguing as we have done in the proof of Theorem 4.4.3, it is easy to see that Jλ is a
C 1,1 functional over H01 () satisfying (PS). Moreover, the assumptions of the theorem imply (f6 )–(f9 ), so that we can apply Theorem 4.4.3 and obtain a nontrivial and
nonnegative solution. All we have to do is to show that we can choose a mountain
pass solution satisfying the requested asymptotic properties. This will be done by
constructing some particular minimax classes separately for statements (i) and (ii).
(i) We study the case λ → +∞. Without loss of generality we can assume that
F (t) ≥ M1 t r for all t ∈ [0, t1 ]. Also recall that F (t) = 0 for all t ≤ 0. Now fix a
function ψ ∈ H01 ()\{0} such that 0 ≤ ψ(x) ≤ t1 for all x ∈ . We have

1
2
Jλ (ψ) ≤ ψ − λM1 ψ r dx,
2

so that there exists λ > 0 such that Jλ (ψ) < 0 for all λ ≥ λ. Let us now investigate
what happens close to zero. Arguing as in the proof of Theorem 4.4.3, we see that


1
1
∗
∗
Jλ (u) ≥ u 2 − Cλ u 2 = u 2
− Cλ u 2 −2 ,
4
4
where C does not depend on u nor on λ. We define
 ∗1

2 −2
1
ρλ =
8Cλ
and we notice that, for large λ, we certainly have ρλ < ψ . Clearly, when
u = ρλ ,
Jλ (u) ≥

ρλ2
> 0.
8

180

4 Introduction to Minimax Methods
ρ2

Setting αλ = 8λ , we have obtained some particular values for which the geometrical
hypotheses of the Mountain Pass Theorem are satisfied. So for large λ we can define
 = {γ ([0, 1]) | γ : [0, 1] → H01 () continuous, γ (0) = 0, γ (1) = ψ}
and
cλ = inf max Jλ (γ (t)),
γ ∈ t∈[0,1]

and we obtain that cλ > 0 is a critical value for Jλ . Let uλ be a critical point of Jλ at
level cλ (that is, a solution of (4.41)) such that Jλ (uλ ) = cλ . We claim that cλ → 0
as λ → +∞. To see this, we first notice that
cλ ≤ max Jλ (tψ),
t∈[0,1]

and, for t ∈ [0, 1],
Jλ (tψ) = t

2 1

2


ψ

2

−λ

F (tψ) dx ≤ t

2 1

2



Consider the real function
η(t) = t 2

1
ψ 2 − λM1 t r
2


ψ

2

− λM1 t

r

ψ r dx.



ψ r dx,


on the interval [0, 1]. By elementary computations we see that η attains its maximum
at the point
 1

r−2
ψ 2
,
tλ =
r
λrM1 |ψ|r
and that the value of this maximum is

1
1
1
η(tλ ) = tλ2 ψ 2 − λM1 tλr
ψ r dx = a 2 − b 2 ,
2

λ r−2
λ r−2
where a, b are positive constants depending on ψ . This implies that
max Jλ (tψ) ≤ max η(t) = (a − b)

t∈[0,1]

t∈[0,1]

1
2

,

λ r−2

and hence
0 < cλ ≤ (a − b)

1

,
2
λ r−2
so that cλ → 0 as λ → ∞, as we claimed. From this it is easy to deduce that
uλ → 0. Indeed, we have

1
2
cλ = Jλ (uλ ) = uλ − λ F (uλ ) dx
2

and
1
λ
1
uλ 2 −
0 = Jλ (uλ )uλ =
μ
μ
μ


f (uλ )uλ .


4.5 Problems with a Parameter

181

Subtracting and using (f3 ), we see that





 
1
1
1
1
1
−
uλ 2 + λ
f (uλ )uλ − F (uλ ) dx ≥
−
uλ 2 .
cλ =
2 μ
μ
2
μ

This shows that uλ → 0 as λ → +∞.
(ii) We now study the case λ → 0+ . From (f6 ) and (f7 ) we deduce that there are
constants M2 , M3 such that
F (t) ≤ M3 t 2 + M2 t p
for all t ≥ 0. Also, from (f3 ) and that fact that F (t) > 0, we see that F (t) ≥ Ct μ for
all t > 0, and of course μ ≤ p. Let us fix ψ ∈ H01 ()\{0} such that ψ(x) ≥ 0 for all
x ∈ . We have, for every t ≥ 0,

21
2
μ
ψ − λCt
ψ μ dx.
Jλ (tψ) ≤ t
2

For every fixed λ we want to choose tλ such that Jλ (tλ ψ) < 0. From the above
computations we easily see that we can choose any t such that

  1
 1
μ−2
ψ 2
1 μ−2

t>
=
a1 ,
λ
2λC  ψ μ dx
where a1 > 0 is a constant depending on ψ . To fix ideas, we choose
  1
1 μ−2
a1 .
tλ = 2
λ
Then we have
1
Jλ (tλ ψ) < 0 and tλ ψ = 1 a2 ,
λ μ−2
where a2 does not depend on λ, and of course tλ ψ → +∞ as λ → 0+ . As in case
(i) we estimate


1
1
∗
∗
− Cλ u 2 −2 ,
Jλ (u) ≥ u 2 − Cλ u 2 = u 2
4
4
so Jλ (u) ≥ 18 for small λ and u = 1. If we choose ρ = 1 and α = 18 , for small
λ we obtain tλ ψ > ρ and we have again some particular values for which the
geometrical hypotheses of Mountain Pass Theorem are satisfied. So we define, for
every λ > 0,
λ = {γ ([0, 1]) | γ : [0, 1] → H01 () continuous, γ (0) = 0, γ (1) = tλ ψ}
and
cλ = inf max Jλ (γ (t)),
γ ∈λ t∈[0,1]

and we obtain a critical point uλ of Jλ at level cλ . We claim now that cλ → +∞ as
λ → 0+ . To see this, let ε ∈ (0, 1) to be fixed later. By continuity, for every γ ∈ λ
there exists t˜ ∈ [0, 1] such that
ε
γ (t˜) = ε tλ ψ = 1 a2 .
λ μ−2

182

4 Introduction to Minimax Methods

Setting v = γ (t˜) we estimate


1
v 2 − λ F (v) dx
2



ε2
≥ 2 a3 − λM3 v 2 dx − λM2 |v|p dx


λ μ−2
2
ε
≥ 2 a3 − λC v 2 − λC v p
λ μ−2
ε2
ε2
εp
= 2 a3 − λ 2 a4 − λ p a5 ,
λ μ−2
λ μ−2
λ μ−2

Jλ (γ (t˜)) =

where ai are positive and independent of λ, i = 3, 4, 5. Noticing that 0 ≤ p−μ
p−2 < 1,
we take


p−μ
,1
α∈
p−2
and for every 0 < λ < 1 we choose a particular value for ε, namely
α

ε = λ μ−2 .
By elementary computations we obtain
1

Jλ (γ (t˜)) ≥
λ

2−2α
μ−2

1

a3 −
λ

2−2α
μ−2 −1

1

a4 −
λ

p−pα
μ−2 −1

a5 =: b(λ),

so that
max Jλ (γ (t)) ≥ b(λ).

t∈[0,1]

Since this holds for every γ ∈ λ , we deduce that
cλ ≥ b(λ).
On the other hand, as α < 1, we have
2 − 2α
> 0,
μ−2
while α > p−μ
p−2 implies
2 − 2α p − pα
>
− 1.
μ−2
μ−2
Therefore b(λ) → +∞ as λ → 0+ , which implies that cλ → +∞ as λ → 0+ , and
the claim is proved.
To conclude the proof of part (ii), let {λk }k be a sequence such that λk → 0+ as
k → +∞. Assume for contradiction that { uλk }k is bounded. It is then easy to see
that also Jλk (uλk ) is bounded, a contradiction. We deduce that for every sequence
{λk }k such that λk → 0+ , the sequence { uλk }k is unbounded. This means that

uλ → +∞ as λ → 0+ .

4.5 Problems with a Parameter

183

Remark 4.5.2 If 2 < p < r < 2∗ the function f defined by f (t) = t p−1 + t r−1 for
t > 0 and f (t) = 0 for t ≤ 0 satisfies all the hypotheses of the preceding theorem.
For such a nonlinearity we then have a family {uλ } of non negative mountain pass
solutions of (4.41) such that uλ → 0 as λ → +∞ and uλ → +∞ as λ → 0+ .
This f is not homogeneous, so the simple scaling argument that we used at the
beginning of the section for the nonlinearity f (t) = t p−1 does not work.
We now consider Problem (4.41) with a different nonlinearity f , exhibiting a
different power-like behavior near zero and near infinity. We consider 1 < r < 2 < s
and we define a function f : R → R as
⎧ s−1
if t ∈ [0, 1],
⎨t
f (t) = t r−1 if t ≥ 1,
(4.42)
⎩
0
if t ≤ 0.
t
As usual we set F (t) = 0 f (s)ds, so that
⎧1 s
if t ∈ [0, 1],
⎪
⎨ st
1
1
1
r
F (t) = r t − r + s if t ≥ 1,
(4.43)
⎪
⎩
0
if t ≤ 0.
Notice that 0 ≤ f (t) ≤ |t| for all t, so the usual arguments show that the functional

u →
F (u) dx


is well defined in H01 () and its differential is locally Lipschitz continuous. We
want to study existence, multiplicity and asymptotic behavior of nonnegative non
trivial solutions of (4.41), for λ > 0. We will look for critical points of the C 1,1
functional

1
(4.44)
Jλ (u) = u 2 − λ F (u) dx.
2

The functional Jλ is coercive (see below the proof of Theorem 4.5.4), and from this
it is easy to see that it satisfies the (PS) condition (see Exercise 10).
First we give a “negative result”.
Proposition 4.5.3 Assume that (h1 ) holds. Then for all λ ∈ [0, λ1 ] the only nonnegative solution of (4.41) is the trivial one.
Proof If Jλ (u) = 0 and u is nonnegative, then


λ
2
u = λ f (u)u dx ≤ λ u2 dx ≤
u 2
λ
1


by the Poincaré inequality. Therefore λ ≥ λ1 . The case λ = λ1 is impossible because
the preceding inequality would become an equality, and so u ≡ tϕ1 for some t ∈ R.
But tϕ1 solves the equation only if t = 0. Therefore the existence of a nontrivial

nonnegative solution implies λ > λ1 .

184

4 Introduction to Minimax Methods

Now we show that a first nontrivial solution exists provided λ is large enough.
Theorem 4.5.4 Assume that (h1 ) holds. Then there exists λ∗ > 0 such that for every
λ > λ∗ there exists a nonnegative solution vλ to (4.41) such that
Jλ (vλ ) = min Jλ (u) < 0.
u∈H01 ()

Proof Choose any v ∈ H01 ()\{0} such that v ≥ 0. It is then obvious that
Jλ (v) → −∞ as λ → +∞,
so that also
inf

u∈H01 ()

Jλ (u) → −∞ as λ → +∞.

Hence we can fix λ∗ > 0 such that infu∈H 1 () Jλ (u) < 0 for all λ > λ∗ .
0
On the other hand, for every fixed λ, Jλ is bounded from below. Indeed, for all
u ∈ H01 () we have

1
2
Jλ (u) = u − λ F (u) dx
2




λ
λ
1 1
1
2
−
{u ≥ 1}
us dx −
ur dx − λ
= u −
2
s {0≤u≤1}
r {1≤u}
s
r

1
λ
1
≥ u 2 − λC −
|u|r dx ≥ u 2 − λC − λC u r ,
2
r 
2
which implies that Jλ is coercive because r < 2. By the usual arguments of Chap. 2,
we obtain that Jλ has a minimum value which is attained by some vλ .
For λ > λ∗ of course
Jλ (vλ ) =

inf

u∈H01 ()

Jλ (u) < 0,

and so vλ is not identically zero. Since vλ is a solution of (4.41), then vλ ≥ 0, because f (t) = 0 for t ≤ 0 (see Proposition 1.7.9).

To find a second nontrivial solution we show that Jλ satisfies the assumption of
the Mountain Pass Theorem near zero. Precisely, we fix a function ψ ∈ H01 ()\{0}
such that 0 ≤ ψ ≤ 1. For large λ’s we have Jλ (ψ) < 0. We now show that we can
find a second solution by a mountain pass procedure on the paths joining 0 to ψ.
Lemma 4.5.5 For large λ’s there exist αλ , ρλ > 0 such that
u = ρλ

implies Jλ (u) ≥ αλ .

Moreover ψ > ρλ .
Proof Setting p = min{s, 2∗ } we have 2 < p ≤ 2∗ and 0 ≤ f (t) ≤ |t|p−1 for all t,
so that

4.5 Problems with a Parameter

185





1 1
1
λ
λ
{u ≥ 1}
us dx −
ur dx − λ
u 2−
−
2
s {0≤u≤1}
r {1≤u}
s
r


1
λ
λ
≥ u 2−
up dx −
up dx
2
s {0≤u≤1}
r {1≤u}


1 1
1
1
+
|u|p dx ≥ u 2 − λC u p
≥ u 2−λ
2
s
r
2



1
− λC u p−2 .
= u 2
2

Jλ (u) =

If we choose

ρλ =

1
4λC

 1

1
and αλ = ρλ2 ,
4

p−2

then we obtain that Jλ (u) ≥ αλ > 0 when u = ρλ , and ψ > ρλ for large λ’s. 
Theorem 4.5.6 Assume that (h1 ) holds. Then for large λ’s the functional Jλ has
two non trivial non negative critical points, a minimum vλ and a mountain pass
critical point uλ .
Proof Thanks to the preceding lemma it is easy to prove that Jλ satisfies all the
hypotheses of the Mountain Pass Theorem. The critical point corresponding to the
global minimum is given by Theorem 4.5.4. The two solutions are different because

J (v ) < 0 < α ≤ J (u ).
λ

λ

λ

λ

λ

Theorem 4.5.7 As λ → +∞ there results vλ → +∞ and uλ → 0.
Proof We first consider the minimum point vλ . Assume for contradiction that the
claim is not true. Then there would be a sequence λk → ∞ such that vλk is
bounded. Let us write vk = vλk . We already know that
Jλk (vk ) → −∞
On the other hand we have


2
f (vk )vk dx = λk
v k = λk


as k → ∞.

(4.45)


{0≤vk ≤1}

vks dx + λk

By assumption, vk is bounded and therefore, if we define


s
ak = λk
vk dx and bk = λk
{0≤vk ≤1}

{1≤vk }

{1≤vk }

vkr dx.

vkr dx,

{ak }k and {bk }k are bounded sequences too. If we set
ck = λk {vk ≥ 1} ,
we obtain 0 ≤ ck ≤ bk , which shows that also {ck }k is bounded. We can then compute

186

4 Introduction to Minimax Methods



1
v k 2 − λk
F (vk ) dx
2

λk
1
v s dx
= vk 2 −
2
s {0≤vk ≤1} k



1 1
λk
r
−
{vk ≥ 1}
v dx − λk
−
r {1≤vk } k
s
r


1
1
1
1 1
= v k 2 − ak − bk −
−
ck .
2
s
r
s
r

Jλk (vk ) =

This gives that Jλk (vk ) is bounded, contradicting (4.45); thus vλ cannot be
bounded as λ → 0.
As far as uλ is concerned, we recall that this solution is obtained by a minimax
procedure on the paths joining u = 0 with a fixed function ψ ∈ H01 ()\{0} such that
0 ≤ ψ ≤ 1. Hence, if cλ is the mountain pass critical level,
0 < cλ ≤ max Jλ (tψ).
t∈[0,1]

For t ∈ [0, 1] we have
Jλ (tψ) =

t2
ts
ψ 2−λ
2
s


ψ s dx,


and the argument is now exactly the same as that of Theorem 4.5.1.



4.6 Exercises
1. Let H be a Hilbert space and let J ∈ C 1 (H ). Prove that if J satisfies (PS)c ,
then the set of critical points at level c, namely
Kc = {u ∈ H | J (u) = c, J  (u) = 0}
is compact.
2. Let H be a Hilbert space and let K : H → R be C 1 and such that ∇K : H → H
sends bounded sets into precompact sets. Consider the functional J : H → R
defined by
1
u 2 + K(u).
2
Show that J satisfies the Palais–Smale condition if and only if every Palais–
Smale sequence is bounded.
3. Let p ∈ (2, 2∗ ) and consider, on H 1 (RN ), the functional



1
1
1
|∇u|2 dx +
u2 dx −
|u|p dx.
I (u) =
2 RN
2 RN
p RN
J (u) =

(a) Show that uk is a sequence that tends to 0 (strongly in H 1 (RN )) if and only
if uk is a Palais–Smale sequence at level 0.

4.6 Exercises

187

(b) Show that the Palais–Smale condition does not hold at any level c = 0.
1
4. Let B be the unit ball centered at zero in RN , with N ≥ 3, and let H0,rad
be the

space of radial functions in H01 (B), with norm u 2 = B |∇u|2 dx. Let α > 0.
(a) Use Lemma 3.1.2 to show that there exists C > 0 such that



2α
p
α
p
∗
1
|u| |x| dx ≤ C u
∀p ∈ 2, 2 +
.
, ∀u ∈ H0,rad
N −2
B
1
(b) Prove that if uk tends to u weakly in H0,rad
, then, for every exponent
2α
∗
p ∈ (2, 2 + N −2 ),

|uk − u|p |x|α dx → 0.
B
2α
∗
Hint: take q ∈ (p, 2 + N −2 ), so that p = 2θ + (1 − θ )q for some θ ∈ (0, 1)

and write

|uk − u|p |x|α = |uk − u|2θ |x|θα |uk − u|(1−θ)q |x|(1−θ)α .
Use the Hölder inequality and the Sobolev embeddings to conclude.
5. Using the notation and the results of the previous exercise, prove that the Hénon
equation

−u = |x|α |u|p−2 u in B,
u=0

on ∂B,

1
for every p ∈ (2, 2∗ + N2α
has at least one solution in H0,rad
−2 ) and every α > 0
by
(i) applying the Mountain Pass Theorem to the functional


1
1
I (u) =
|∇u|2 dx −
|u|p |x|α dx
2 B
p B
(ii) minimizing the functional

|∇u|2 dx
Q(u) =  B p α
.
( B |u| |x| dx)2/p

This problem has been solved in [37].
6. Assume that  ⊂ RN is open and bounded, and let f : [0, +∞) → [0, +∞) be
continuous and satisfy
∗

f (t) ≤ a + bt 2 −1

∀t ≥ 0 and

for some a, b ≥ 0. Prove that the problem
⎧
⎪
⎨ −u = λf (u)
u>0
⎪
⎩
u=0

inf

t≥0

f (t)
= γ > 0,
t

in ,
in ,
on ∂,

has no solutions (e.g. in H01 ()) if λ > λγ1 . Hint: multiply by ϕ1 .

188

4 Introduction to Minimax Methods

7. Let f : R → R satisfy f (0) = 0 and assume that there exist p ∈ (2, 2∗ ] and
C > 0 such that
t

|f (t) − f (s)| ≤ C|t − s|(|t| + |s|)p−2

∀t, s ∈ R.

Set F (t) = 0 f (s) ds. Prove that the functional J : H 1 (RN ) → R defined by



1
1
J (u) =
|∇u|2 dx +
u2 dx −
F (u) dx
2 RN
2 RN
RN
is in C 1,1 (H 1 (RN )).
8. Let J be the functional of the preceding exercise, but assume in addition that
p ∈ (2, 2∗ ) and that there exists μ > 2 such that
f (t)t ≥ μF (t)

∀t ∈ R.

Prove that if J is considered not on all of H 1 (RN ) but on the subspace Hr
of radial functions, then J satisfies the Palais–Smale condition. (Hint: use the
compactness of the embedding of Hr in Lp (RN ) for p ∈ (2, 2∗ )).
9. Assume that f satisfies all the assumptions of the preceding exercise, and moreover that there exists t0 > 0 such that F (t0 ) > 0. Using the result of the previous
two exercises, prove that the problem

−u + u = f (u),
u ∈ Hr
admits a nontrivial and nonnegative solution via the Mountain Pass Theorem.
10. Prove that the functional Jλ defined in (4.44) satisfies the Palais–Smale condition.

4.7 Bibliographical Notes
• Section 4.1: The Palais–Smale compactness condition was introduced in infinite
dimensional Critical Point Theory in a series of works by Palais and Smale, in
a slightly different form, see [40]. Our definition is the most used in the literature. For more precise, quantitative versions of the Deformation Lemma, see for
example the books by Rabinowitz [43] and Struwe [45].
• Section 4.2: A most general form of the minimax principle can be found in the
work of Palais [38]. The books [2, 26, 35, 43, 45, 48] all work extensively with
minimax classes and should be consulted to see how the theory presented in these
notes evolves. The original paper by Ambrosetti and Rabinowitz [5], already contains different examples, including “dual” minimax classes.
• Section 4.3: The Mountain Pass and Saddle Point theorems admit many variants
and extensions. Particularly useful are the versions that deal with even functionals
(i.e. such that I (−u) = I (u)). In this setting the functional is likely to possess
infinitely many distinct critical points; see [43] or [45]. These kind of results are

4.7 Bibliographical Notes

189

particular cases of theories dealing with functionals invariant under the action of
some compact group of transformations (index theories). The interested reader
can consult the quoted books [43, 45] for readable expositions of a subject that
soon evolves towards algebraic topology.
• Section 4.4: The Mountain Pass Theorem applies of course to more general problems than the ones presented in these notes, for instance those where the nonlinearity also depends on x. The proofs are more technical, but up to a certain
point nothing new appears. Check [43] or [8] for more examples of this kind.
The functionals associated to many problems with critical growth also satisfy the
geometrical assumptions of the Mountain Pass Theorem; it is the Palais–Smale
condition that fails. Struwe [46] (reported in [45]) characterized all the levels at
which the Palais–Smale condition is not satisfied for problem (4.17), with p = 2∗
(and q(x) ≡ 0).
Asymptotically linear problems: the Landesman–Lazer conditions are just an
example of a sufficient condition for the existence of a solution in a resonant
problem; the paper [28] was the first to consider resonance. Other resonant problems that can be treated include cases where, roughly, f tends to zero at infinity
and F tends to infinity (see Ahmad, Lazer and Paul [1]), or F tends to a constant
(“strong resonance”, see Bartolo, Benci, and Fortunato [7]), or cases where f is
periodic (Solimini [44]).
• Section 4.5: Problems with parameters are studied intensively, by means of variational techniques or bifurcation methods, or a combination of the two. An introductory exposition, with many examples, can be found in [2, 4], together with an
ample bibliography.

Index of the Main Assumptions

In this book we use many different hypotheses on the data of the problem currently
under study. Some of them differ from each other only slightly, for technical reasons. It may happen that some assumptions apply to different problems, and in this
case they are invoked many pages after they had been originally stated. For the convenience of the reader we provide here an index of all the assumptions that are used
in this book so that these can be quickly looked up in this page.
(f1 )
(f2 )
(f3 )
(f4 )
(f5 )
(f6 )

f : R → R is of class C 1 and is odd.
 (t)|
f  (0) = 0 and there exists p ∈ (2, 2∗ ) such that lim supt→+∞ |ft p−2
< +∞.
There exists μ > 2 such that f (t)t ≥ μF (t) for all t ∈ R.
For every t ∈ (0, +∞) there results f  (t)t > f (t).
The inequality f  (t)t ≥ (μ − 1)f (t) > 0 holds for every t ∈ (0, +∞).
There exist p ∈ (2, 2∗ ) and C > 0 such that for all s, t ∈ R,
|f (t) − f (s)| ≤ C|t − s| (|s| + |t| + 1)p−2 .

(f7 ) limt→0 f (t)
t = 0.
(f8 ) There exist M > 0 and μ > 2 such that f (t)t ≥ μF (t) when |t| ≥ M.
(f9 ) There exists t0 ∈ R with |t0 | ≥ M such that F (t0 ) > 0.
∗
(f10 ) f ∈ C 1 (R), f is bounded and |f  (t)| ≤ C(1 + |t|2 −2 ).
(g1 ) g : R → R is of class C 1 and is odd.
 (t)|
(g2 ) g  (0) = 0 and there exists θ ∈ (2, μ) such that lim supt→+∞ |gt θ−2
< +∞.

(g3 ) The inequalities g(t) ≥ 0 and g (t)t ≤ (μ−1)g(t) hold for every t ∈ (0, +∞).
(h1 )  ⊂ RN is bounded and open, q ∈ L∞ () and q(x) ≥ 0 a.e. in .
(h2 ) h ∈ L2 ().
(h3 ) f : R → R is continuous and bounded.
(h4 ) f : R → R is continuous and there exist σ ∈ (0, 1) and a, b > 0 such that
|f (t)| ≤ a + b|t|σ

∀t ∈ R.

(h5 ) f : R → R is continuous and there exist a > 0 and b ∈ (0, λ1 ) such that
|f (t)| ≤ a + b|t|

∀t ∈ R.

M. Badiale, E. Serra, Semilinear Elliptic Equations for Beginners, Universitext,
DOI 10.1007/978-0-85729-227-8, © Springer-Verlag London Limited 2011

191

192

Index of the Main Assumptions

(h6 ) f : R → R is continuous and there exist a, b > 0 such that
∗

|f (t)| ≤ a + b|t|2 −1

∀t ∈ R.

Moreover
f (s)s ≤ 0 ∀s ∈ R.
(h7 ) There exist an integer ν ≥ 1 and α, β ∈ R such that
f (s) − f (t)
≤ β < λν+1 ∀s, t ∈ R.
s−t
(q1 ) infx∈RN q(x) > 0 and lim|x|→+∞ q(x) = +∞.
(q2 ) q is continuous and 0 < δ := infRN q < supRN q =: α < +∞.
(q3 ) lim|x|→+∞ q(x) = α.
λν < α ≤

References

1. S. Ahmad, A.C. Lazer, J.L. Paul, Elementary critical point theory and perturbations of elliptic
boundary value problems at resonance. Indiana Univ. Math. J. 25(10), 933–944 (1976)
2. A. Ambrosetti, A. Malchiodi, Nonlinear Analysis and Semilinear Elliptic Problems. Cambridge Studies in Advanced Mathematics, vol. 104 (Cambridge University Press, Cambridge,
2007)
3. A. Ambrosetti, A. Malchiodi, Perturbation Methods and Semilinear Elliptic Problems on Rn .
Progress in Mathematics, vol. 240 (Birkhäuser, Basel, 2006)
4. A. Ambrosetti, G. Prodi, A Primer of Nonlinear Analysis. Cambridge Studies in Advanced
Mathematics, vol. 34 (Cambridge University Press, Cambridge, 1995). Corrected reprint of
the 1993 original
5. A. Ambrosetti, P.H. Rabinowitz, Dual variational methods in critical point theory and applications. J. Funct. Anal. 14, 349–381 (1973)
6. A. Bahri, J.-M. Coron, On a nonlinear elliptic equation involving the critical Sobolev exponent: the effect of the topology of the domain. Commun. Pure Appl. Math. 41(3), 253–294
(1988)
7. P. Bartolo, V. Benci, D. Fortunato, Abstract critical point theorems and applications to some
nonlinear problems with “strong” resonance at infinity. Nonlinear Anal. 7(9), 981–1012
(1983)
8. T. Bartsch, Z.-Q. Wang, M. Willem, The Dirichlet problem for superlinear elliptic equations, in Stationary Partial Differential Equations. Handbook of Differential Equations, vol.
II (Elsevier/North-Holland, Amsterdam, 2005), pp. 1–55
9. H. Berestycki, P.-L. Lions, Nonlinear scalar field equations. I. Existence of a ground state.
Arch. Ration. Mech. Anal. 82(4), 313–345 (1983)
10. H. Berestycki, P.-L. Lions, Nonlinear scalar field equations. II. Existence of infinitely many
solutions. Arch. Ration. Mech. Anal. 82(4), 347–375 (1983)
11. H. Brezis, Analyse fonctionnelle. Théorie et applications. Collection Mathématiques Appliquées pour la Maîtrise (Masson, Paris, 1983)
12. H. Brezis, Some variational problems with lack of compactness, in Nonlinear Functional
Analysis and Its Applications, Part 1, Berkeley, CA, 1983. Proceedings of Symposium in
Pure Mathematics, Part 1, vol. 45 (American Mathematical Society, Providence, 1986), pp.
165–201
13. H. Brezis, Elliptic equations with limiting Sobolev exponents—the impact of topology. Commun. Pure Appl. Math. 39(S1), S17–S39 (1986)
14. H. Brezis, L. Nirenberg, Positive solutions of nonlinear elliptic equations involving critical
Sobolev exponents. Commun. Pure Appl. Math. 36(4), 437–477 (1983)
15. J.-M. Coron, Topologie et cas limite des injections de Sobolev. C. R. Acad. Sci. Paris Sér. I
Math. 299(7), 209–212 (1984)
M. Badiale, E. Serra, Semilinear Elliptic Equations for Beginners, Universitext,
DOI 10.1007/978-0-85729-227-8, © Springer-Verlag London Limited 2011

193

194

References

16. N.E. Dancer, A note on an equation with critical exponent. Bull. Lond. Math. Soc. 20(6),
600–602 (1988)
17. K. Deimling, Nonlinear Functional Analysis (Springer, Berlin, 1985)
18. L.C. Evans, Partial Differential Equations. Graduate Studies in Mathematics, vol. 19 (American Mathematical Society, Providence, 1998)
19. I. Ekeland, R. Temam, Analyse convexe et problèmes variationnels. Collection Etudes Mathématiques (Dunod/Gauthier-Villars, Paris, 1974)
20. J.P. Garcia Azorero, I. Peral Alonso, Existence and nonuniqueness for the p-Laplacian: nonlinear eigenvalues. Commun. Partial Differ. Equ. 12(12), 1389–1430 (1987)
21. E. Giusti, Direct Methods in the Calculus of Variations (World Scientific, River Edge, 2003)
22. D. Gilbarg, N.S. Trudinger, Elliptic Partial Differential Equations of Second Order. Classics
in Mathematics (Springer, Berlin, 2001). Reprint of the 1998 edition
23. H.H. Goldstine, A History of the Calculus of Variations from the 17th Through the 19th Century. Studies in the History of Mathematics and Physical Sciences, vol. 5 (Springer, New York,
1980)
24. Q. Han, F. Lin, Elliptic Partial Differential Equations. Courant Lecture Notes in Mathematics,
vol. 1 (American Mathematical Society, Providence, 1997)
25. S. Hildebrandt, A. Tromba, The Parsimonious Universe. Shape and Form in the Natural World
(Copernicus, New York, 1996)
26. O. Kavian, Introduction à la théorie des points critiques et applications aux problèmes elliptiques. Mathématiques & Applications, vol. 13 (Springer, Paris, 1993)
27. I. Kuzin, S. Pohozaev, Entire Solutions of Semilinear Elliptic Equations. Progress in Nonlinear
Differential Equations and Their Applications, vol. 33 (Birkhäuser, Basel, 1997)
28. E.M. Landesman, A.C. Lazer, Nonlinear perturbations of linear elliptic boundary value problems at resonance. J. Math. Mech. 19, 609–623 (1969/1970)
29. E.H. Lieb, M. Loss, Analysis, 2nd edn. Graduate Studies in Mathematics, vol. 14 (American
Mathematical Society, Providence, 2001)
30. P. Lindqvist, Notes on the p-Laplace equation, Report, University of Jyväskylä, Department
of Mathematics and Statistics, 102 (2006)
31. P.-L. Lions, The concentration-compactness principle in the calculus of variations. The locally
compact case. I. Ann. Inst. H. Poincaré Anal. Non Linéaire 1(2), 109–145 (1984)
32. P.-L. Lions, The concentration-compactness principle in the calculus of variations. The locally
compact case. II. Ann. Inst. H. Poincaré Anal. Non Linéaire 1(4), 223–283 (1984)
33. P.-L. Lions, The concentration-compactness principle in the calculus of variations. The limit
case. I. Rev. Mat. Iberoam. 1(1), 145–201 (1985)
34. P.-L. Lions, The concentration-compactness principle in the calculus of variations. The limit
case. II. Rev. Mat. Iberoam. 1(2), 45–121 (1985)
35. J. Mawhin, M. Willem, Critical Point Theory and Hamiltonian Systems. Applied Mathematical Sciences, vol. 74 (Springer, New York, 1989)
36. Z. Nehari, Characteristic values associated with a class of non-linear second-order differential
equations. Acta Math. 105, 141–175 (1961)
37. W.-M. Ni, A nonlinear Dirichlet problem on the unit ball and its applications. Indiana Univ.
Math. J. 31(6), 801–807 (1982)
38. R. S Palais, The principle of symmetric criticality. Commun. Math. Phys. 69(1), 19–30 (1979)
39. S. Pohožaev, Eigenfunctions of the equation u + λf (u) = 0. Sov. Math. Dokl. 6, 1408–1411
(1965)
40. R.S. Palais, S. Smale, A generalized Morse theory. Bull. Am. Math. Soc. 70, 165–172 (1964)
41. M.H. Protter, H.F. Weinberger, Maximum Principles in Differential Equations (Springer, New
York, 1984). Corrected reprint of the 1967 original
42. P.H. Rabinowitz, Some minimax theorems and applications to nonlinear partial differential
equations, in Nonlinear Analysis (Collection of Papers in Honor of Erich H. Rothe) (Academic
Press, New York, 1978), pp. 161–177
43. P.H. Rabinowitz, Minimax Methods in Critical Point Theory with Applications to Differential
Equations. CBMS Regional Conference Series in Mathematics, vol. 65 (American Mathematical Society, Providence, 1986)

References

195

44. S. Solimini, On the solvability of some elliptic partial differential equations with the linear
part at resonance. J. Math. Anal. Appl. 117(1), 138–152 (1986)
45. M. Struwe, Variational Methods. Applications to Nonlinear Partial Differential Equations and
Hamiltonian Systems, 4th edn. Ergebnisse der Mathematik und ihrer Grenzgebiete, 3. Folge
[Results in Mathematics and Related Areas, 3rd Series. A Series of Modern Surveys in Mathematics], vol. 34 (Springer, Berlin, 2008)
46. M. Struwe, A global compactness result for elliptic boundary value problems involving limiting nonlinearities. Math. Z. 187(4), 511–517 (1984)
47. S. Terracini, On positive entire solutions to a class of equations with a singular coefficient and
critical exponent. Adv. Differ. Equ. 1(2), 241–264 (1996)
48. M. Willem, Minimax Theorems. Progress in Nonlinear Differential Equations and Their Applications, vol. 24 (Birkhäuser, Boston, 1996)

Index

A
Admissible minimax class, 154–157, 159
Anticoercive functional, 27
Asymptotically linear problems, 167–178, 189
B
Banach–Alaoglu Theorem, 10
Bernoulli
Jakob, 3
Johann, 3
Best Sobolev constant, 29, 121
Bose–Einstein condensates, 2
Brouwer Theorem, 158
C
Calculus of Variations, 3, 27, 37, 96
Cauchy Problem, 149
Change of topology, 4, 147, 148, 157
Classical solutions, 23–25, 90
Coercive
functional, 27, 31
problem, 39–45
Concentration, 120
Concentration–compactness Principle, 110,
143
Constrained minimization, 55–63, 96, 101
Convex functional, 25–31
Critical
level, 15
point, 15
Critical exponent, 7, 18, 87, 89, 119–140, 143
Critical Point Theory, 4, 154, 155, 188
D
De L’Hôpital, Guillaume François Antoine, 3
Deformable set, 149, 150, 152, 154

Deformation, 146–154, 157
Deformation Lemma, 150, 152, 188
Derivative
Fréchet, 12
Gâteaux, 14
Differential
Fréchet, 12, 15–22
Gâteaux, 14, 19, 21
Direct methods of the Calculus of Variations,
4, 27, 37, 96
Dirichlet
principle, 3
problem, 22, 31
Dominated convergence, see Lebesgue
Theorem
Dual of a Banach Space, 11
E
Eigenfunctions, 31–35
Eigenvalues, 31–35
Elliptic operator, 8
Embedding
compact, 7
continuous, 7
of Banach spaces, 7, 8
Energy functional, 4, 24
Entry, 1
subentry, 1
Euler, Leonhard, 3
Euler equation, 4, 15
Euler–Lagrange equation, 4, 15
F
First eigenfunction, 34
First eigenvalue, 33–35
variational characterization of, 33

M. Badiale, E. Serra, Semilinear Elliptic Equations for Beginners, Universitext,
DOI 10.1007/978-0-85729-227-8, © Springer-Verlag London Limited 2011

197

198

Index

Flow, 150
gradient, 150
steepest descent, 150
Flow lines, 150, 151
Fourier coefficients, 33
Fredholm alternative, 34
Fully nonlinear equations, 2
Functional
linear, 11
of class C 1 , 12
of class C 1,1 , 150

Min–max, see Ky Fan–Von Neumann Theorem
Minimax
class, 154
level, 154
principle, 153–155
Monge–Ampère equations, 2
Morse, Marston, 4
Mountain Pass
geometry, 157
Theorem, 4, 155, 157, 160
applications of, 160–167

G
Gradient
of a function, 5
of a functional, 13
Gross–Pitaevskii equation, 2

N
Natural constraint, 63
Nehari manifold, 60
Newton, Isaac, 3
Nonexistence, 136
Nonlinear eigenvalue problem, 91–93, 141,
178
Nonlinear Schrödinger equation, 2, 143
Nonresonance, 168

H
Hardy inequality, 140
Heat equation, 1
Hénon equation, 187
I
Invariance
under rotations, 98, 130
under scalings, 120
under translations, 121
K
Ky Fan–Von Neumann Theorem, 46, 96
L
Lagrange
multiplier, 59
Theorem, 58
Lagrange, Joseph-Louis, 3
Landesman–Lazer conditions, 172, 177, 189
Laplace operator, see Laplacian
Laplacian, 9, 22
Least action principle, 3
Lebesgue
measure, 5
Theorem, 9
Lebesgue, Henri, 3
Leibniz, Gottfried Wilhelm von, 3
Ljusternik, Lazar Aronovich, 4
M
Maupertuis, Pierre-Louis Moreau de, 3
Maximum principle, 34, 35
strong, 35

P
p-Laplacian, 2, 86–93, 95
Palais, Richard Sheldon, 4, 134, 188
Palais–Smale
condition, 148
level, 147
sequence, 147
Pohožaev identity, 137
Poincaré inequality, 10
best constant in, 36
for W 1,p , 87
Principal eigenvalue, see First eigenvalue
Principle of symmetric criticality, 134
Pseudo-gradient vector field, 150
Q
Quasilinear equations, 2, 86–93
R
Rayleigh quotient, 33
Resonance, 168
Riemann, Georg Friedrich Bernhard, 3
Riesz
isomorphism, 10, 12
Theorem, 10, 91
S
Saddle point, 51
Saddle Point Theorem, 4, 159, 160
applications of, 167–178

Index
Scalar field equations, 2, 143
Schnirelman, Lev Genrikhovich, 4
Schwarz symmetrization, 100
Simple eigenvalue, 33
Sine-Gordon equation, 2
Sobolev
embeddings, 7, 87
inequalities, 8
spaces, 5, 86
Starshaped set, 136, 137, 140
Subcritical growth, 55, 57, 143
Sublevel set, 4, 146
Sublinear
growth, 42
problems, 39–45

199
Superlinear
growth, 96
problems, 55–85, 160–167
Support, 5
Symmetrization, see Schwarz symmetrization
W
Wave equation, 1
Weak lower semicontinuity, 26, 27
Weak solutions, 22–25
Weierstrass, Karl Theodor Wilhelm, 3
Weierstrass Theorem, 27, 41
Y
Yamabe problem, 2

